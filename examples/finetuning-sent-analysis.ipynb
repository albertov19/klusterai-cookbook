{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7",
   "metadata": {
    "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7"
   },
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a77d9",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kluster-ai/klusterai-cookbook/blob/main/examples/.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e867bee8-9173-473d-84c4-48c10b38cc2e",
   "metadata": {},
   "source": [
    "## Setting up your environment\n",
    "\n",
    "### API key configuration\n",
    "To get started with this tutorial, you'll need a kluster.ai API key. If you don't have one yet, follow these steps:\n",
    "1. Visit the <a href=\"https://platform.kluster.ai/signup\" target=\"_blank\">kluster.ai</a> to create an account.\n",
    "2. Generate your API key\n",
    "\n",
    "Once you have your API key, we'll use it to authenticate our requests to the kluster.ai API.\n",
    "\n",
    "### Important note\n",
    "Keep your API key secure and never share it publicly. In this notebook, we'll use Python's getpass module to safely input the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f2171bb-2b89-4fd4-a7f0-37f2d076466a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your kluster.ai API key:  ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "# Enter you personal kluster.ai API key (make sure in advance it has no blank spaces)\n",
    "api_key = getpass(\"Enter your kluster.ai API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad68612f-82f7-4519-823a-407e4e51e504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6af45325-7087-49fe-b32b-0ff1d6537af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import json\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', 1000, 'display.width', 1000, 'display.max_rows',1000, 'display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a6f805-1c74-48a5-8572-0a5fb2c48286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the client\n",
    "client_prod = OpenAI(\n",
    "    base_url=\"https://api.kluster.ai/v1\",\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e1f91fa-ec0f-4843-852e-56a720b7e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key_stg = os.getenv(\"KLUSTER_API_KEY_STG\")\n",
    "base_url = os.getenv(\"KLUSTER_BASE_URL\", \"https://api-r.klusterai.dev/v1\")\n",
    "\n",
    "if not api_key_stg:\n",
    "    raise ValueError(\"KLUSTER_API_KEY environment variable is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e599b93-d419-4690-a295-1038d3286115",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_stg = OpenAI(\n",
    "    api_key=api_key_stg,\n",
    "    base_url=base_url\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b403f9b-d71d-4e8a-8eab-93f7f11e6ae5",
   "metadata": {},
   "source": [
    "## Building our evaluation pipeline\n",
    "\n",
    "### Understanding the helper functions\n",
    "In this section, we'll create several utility functions that will help us:\n",
    "1. Prepare our data for batch processing\n",
    "2. Send requests to the kluster.ai API\n",
    "3. Monitor the progress of our evaluation\n",
    "4. Collect and analyze results\n",
    "\n",
    "These functions will make our evaluation process more efficient and organized. Let's go through each one and understand its purpose.\n",
    "\n",
    "1. `create_tasks()` - formats our data for the API\n",
    "2. `save_tasks()` - prepares batch files for processing\n",
    "3. `monitor_job_status()` - tracks evaluation progress\n",
    "4. `get_results()` - collects and processes model outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a911164b-b165-4535-9443-7d74624b048a",
   "metadata": {},
   "source": [
    "## Creating and managing batch files\n",
    "\n",
    "### What is a batch file?\n",
    "A batch file in our context is a collection of requests that we'll send to our models for evaluation. Think of it as a organized list of tasks we want our models to complete.\n",
    "\n",
    "### Step-by-Step process\n",
    "1. **Creating tasks** - we'll convert each movie description into a format LLMs can process\n",
    "2. **Organizing data** -we'll add necessary metadata and instructions for each task\n",
    "3. **Saving files** - we'll store these tasks in a structured format (JSONL) for processing\n",
    "\n",
    "### Understanding the code\n",
    "Let's break down the key components of our batch file creation:\n",
    "- `custom_id` - helps us track individual requests\n",
    "- `system_prompt` - provides instructions to the model\n",
    "- `content` - the actual text we want to classify\n",
    "\n",
    "This structured approach allows us to efficiently process multiple requests in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69056203-cd06-4f9c-8ed4-172f4a529d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tasks(df, task_type, system_prompt, model, content_column):\n",
    "    tasks = []\n",
    "    for index, row in df.iterrows():\n",
    "        content = row[content_column]\n",
    "        \n",
    "        task = {\n",
    "            \"custom_id\": f\"{task_type}-{index}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": model,\n",
    "                \"temperature\": 0,\n",
    "                \"max_completion_tokens\": 100,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": content},\n",
    "                ],\n",
    "            }\n",
    "        }\n",
    "        tasks.append(task)\n",
    "    return tasks\n",
    "\n",
    "def save_tasks(tasks, task_type):\n",
    "    filename = f\"batch_tasks_{task_type}.jsonl\"\n",
    "    with open(filename, 'w') as file:\n",
    "        for task in tasks:\n",
    "            file.write(json.dumps(task) + '\\n')\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05889ec-fdf1-4593-9061-97449ccf3b28",
   "metadata": {},
   "source": [
    "## Uploading files to kluster.ai\n",
    "\n",
    "### The upload process\n",
    "Now that we've prepared our batch files, we'll upload them to the <a href=\"https://platform.kluster.ai/\" target=\"_blank\">kluster.ai</a>  platform for batch inference. This step is crucial for:\n",
    "1. Getting our data to the models\n",
    "2. Setting up the processing queue\n",
    "3. Preparing for inference\n",
    "\n",
    "### What happens next?\n",
    "After upload:\n",
    "1. The platform queues our requests\n",
    "2. Models process them efficiently\n",
    "3. Results are made available for collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc64b4f6-fe29-407b-8bbe-7f37cefd3e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_job(file_name, client):\n",
    "    print(f\"Creating batch job for {file_name}\")\n",
    "    batch_file = client.files.create(\n",
    "        file=open(file_name, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "    batch_job = client.batches.create(\n",
    "        input_file_id=batch_file.id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\"\n",
    "    )\n",
    "\n",
    "    return batch_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ecb01-a501-469b-bcf5-8c1e5a4e607d",
   "metadata": {
    "id": "e-ujphILqepu"
   },
   "source": [
    "#### Check job progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a978c8-b236-4858-8a25-ec616650c111",
   "metadata": {},
   "source": [
    " This function provides real-time monitoring of batch job progress:\n",
    " - Continuously checks job status via the kluster.ai API\n",
    "- Displays current completion count (completed/total requests)\n",
    "- Updates status every 10 seconds until job is finished\n",
    "- Automatically clears previous output for clean progress tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4477d413-5843-4cf5-bb53-aa9a494121ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_objects(data_string):\n",
    "    if isinstance(data_string, bytes):\n",
    "        data_string = data_string.decode('utf-8')\n",
    "\n",
    "    json_strings = data_string.strip().split('\\n')\n",
    "    json_objects = []\n",
    "\n",
    "    for json_str in json_strings:\n",
    "        try:\n",
    "            json_obj = json.loads(json_str)\n",
    "            json_objects.append(json_obj)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON: {e}\")\n",
    "\n",
    "    return json_objects\n",
    "\n",
    "def monitor_job_status(client, job_id, task_type):\n",
    "    all_completed = False\n",
    "\n",
    "    while not all_completed:\n",
    "        all_completed = True\n",
    "        output_lines = []\n",
    "\n",
    "        updated_job = client.batches.retrieve(job_id)\n",
    "\n",
    "        if updated_job.status.lower() != \"completed\":\n",
    "            all_completed = False\n",
    "            completed = updated_job.request_counts.completed\n",
    "            total = updated_job.request_counts.total\n",
    "            output_lines.append(f\"{task_type.capitalize()} job status: {updated_job.status} - Progress: {completed}/{total}\")\n",
    "        else:\n",
    "            output_lines.append(f\"{task_type.capitalize()} job completed!\")\n",
    "\n",
    "        # Clear the output and display updated status\n",
    "        clear_output(wait=True)\n",
    "        for line in output_lines:\n",
    "            display(line)\n",
    "\n",
    "        if not all_completed:\n",
    "            time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0280b786-d37e-4da8-a5d3-4dfd533b753a",
   "metadata": {},
   "source": [
    "### Collecting and processing results\n",
    "\n",
    "#### Understanding the format\n",
    " The get_results() function below:\n",
    " 1. Retrieves the completed batch job results\n",
    " 2. Extracts the model's response content from each result\n",
    " 3. Returns a list of all model responses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aaa7d52-9a38-4001-98ae-b4e8e3f0ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(client, job_id):\n",
    "    batch_job = client.batches.retrieve(job_id)\n",
    "    result_file_id = batch_job.output_file_id\n",
    "    result = client.files.content(result_file_id).content\n",
    "    results = parse_json_objects(result)\n",
    "    answers = []\n",
    "    \n",
    "    for res in results:\n",
    "        result = res['response']['body']['choices'][0]['message']['content']\n",
    "        answers.append(result)\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8c5014-5b0c-43c2-a238-073dbde2d90a",
   "metadata": {
    "id": "udPtLfTaisSw"
   },
   "source": [
    "## Prepare a real dataset for batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b9ad42-cc58-4054-a510-af09a8592635",
   "metadata": {},
   "source": [
    "Now that we have covered the core general functions and workflow used for batch inference, in this guide, we’ll be using the IMDb Top 1000 dataset, which contains information about top-rated movies, including their descriptions and genres. Let's download it and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "yC9wJlV4rwOh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                                                                                                                                                                                                                  text\n",
       "0   neutral                                                                                                       According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\n",
       "1   neutral                                        Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .\n",
       "2  negative  The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported ."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "#url = \"https://raw.githubusercontent.com/kluster-ai/klusterai-cookbook/refs/heads/main/data/imdb_top_1000.csv\"\n",
    "#urllib.request.urlretrieve(url,filename='imdb_top_1000.csv')\n",
    "\n",
    "# Load and process the dataset based on URL content\n",
    "df = pd.read_csv('all-data.csv', encoding = \"ISO-8859-1\",header=None, names=[\"sentiment\", \"text\"])\n",
    "df = df.iloc[:1000]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a03d805-0d59-42ce-ac2a-4f9beacd639b",
   "metadata": {},
   "source": [
    "#### Train-test split for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de8b2580-43ba-438f-8aab-4916a4c1fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.9, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb5b6d85-aea0-4c77-97d5-a8cb007fa43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebefac4-cb4c-4e75-af96-c827b5668188",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4903010-b32f-47d0-9a01-6be8e0938328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate JSONLines file\n",
    "with open(\"finetuning/data/sentiment.jsonl\", \"w\") as f:\n",
    "    for _, row in train_df.iterrows():\n",
    "        # Create the message structure\n",
    "        messages = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": row['text']},\n",
    "                {\"role\": \"assistant\", \"content\": row[\"sentiment\"]}\n",
    "            ]\n",
    "        }\n",
    "        # Write to the file as a single JSON object per line\n",
    "        f.write(json.dumps(messages) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "653ff10c-59bb-443d-b031-c6678744bdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully. File ID: 678a92129865c142b39dab99\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'finetuning/data/sentiment.jsonl'\n",
    "\n",
    "with open(data_dir, 'rb') as file:\n",
    "    upload_response = client_stg.files.create(\n",
    "        file=file,\n",
    "        purpose=\"fine-tune\"\n",
    "    )\n",
    "    file_id = upload_response.id\n",
    "    print(f\"File uploaded successfully. File ID: {file_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c4bcef6-aee7-4d3e-9161-9465ac6656db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning job created:\n",
      "{\n",
      "  \"id\": \"678a9216da5fe6a8dc4dfd52\",\n",
      "  \"created_at\": 1737134614,\n",
      "  \"error\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"finished_at\": null,\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": \"auto\",\n",
      "    \"batch_size\": \"auto\",\n",
      "    \"learning_rate_multiplier\": \"auto\"\n",
      "  },\n",
      "  \"model\": \"klusterai/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": null,\n",
      "  \"result_files\": [],\n",
      "  \"seed\": null,\n",
      "  \"status\": \"queued\",\n",
      "  \"trained_tokens\": null,\n",
      "  \"training_file\": \"678a92129865c142b39dab99\",\n",
      "  \"validation_file\": null,\n",
      "  \"estimated_finish\": null,\n",
      "  \"integrations\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job = client_stg.fine_tuning.jobs.create(\n",
    "    training_file=file_id,\n",
    "    model=\"klusterai/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "    #hyperparameters={\n",
    "    #    \"batch_size\": 4,\n",
    "    #    \"n_epochs\": 2,\n",
    "    #    \"learning_rate_multiplier\": 1\n",
    "    #}\n",
    ")\n",
    "print(\"\\nFine-tuning job created:\")\n",
    "print(json.dumps(job.model_dump(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "419c1ad3-617c-4d5f-aa57-86f7f48cec05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935332c62f8a365f64b8\",\n",
      "    \"created_at\": 1737134930,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 214/270: training loss=0.2851610481739044\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9355853dcb9e256b9624\",\n",
      "    \"created_at\": 1737134932,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 215/270: training loss=0.2181839793920517\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935632c62f8a365f64bb\",\n",
      "    \"created_at\": 1737134933,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 216/270: training loss=0.2576529383659363\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9357853dcb9e256b9627\",\n",
      "    \"created_at\": 1737134934,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 217/270: training loss=0.1464187502861023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935932c62f8a365f64be\",\n",
      "    \"created_at\": 1737134936,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 218/270: training loss=0.2709529399871826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935a853dcb9e256b962a\",\n",
      "    \"created_at\": 1737134937,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 219/270: training loss=0.2246333807706833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c32c62f8a365f64c1\",\n",
      "    \"created_at\": 1737134938,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 220/270: training loss=0.15977168083190918\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c853dcb9e256b962d\",\n",
      "    \"created_at\": 1737134940,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 221/270: training loss=0.43252938985824585\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935e32c62f8a365f64c4\",\n",
      "    \"created_at\": 1737134941,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 222/270: training loss=0.18377262353897095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935f853dcb9e256b9630\",\n",
      "    \"created_at\": 1737134942,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 223/270: training loss=0.13245829939842224\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935332c62f8a365f64b8\",\n",
      "    \"created_at\": 1737134930,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 214/270: training loss=0.2851610481739044\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9355853dcb9e256b9624\",\n",
      "    \"created_at\": 1737134932,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 215/270: training loss=0.2181839793920517\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935632c62f8a365f64bb\",\n",
      "    \"created_at\": 1737134933,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 216/270: training loss=0.2576529383659363\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9357853dcb9e256b9627\",\n",
      "    \"created_at\": 1737134934,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 217/270: training loss=0.1464187502861023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935932c62f8a365f64be\",\n",
      "    \"created_at\": 1737134936,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 218/270: training loss=0.2709529399871826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935a853dcb9e256b962a\",\n",
      "    \"created_at\": 1737134937,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 219/270: training loss=0.2246333807706833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c32c62f8a365f64c1\",\n",
      "    \"created_at\": 1737134938,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 220/270: training loss=0.15977168083190918\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c853dcb9e256b962d\",\n",
      "    \"created_at\": 1737134940,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 221/270: training loss=0.43252938985824585\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935e32c62f8a365f64c4\",\n",
      "    \"created_at\": 1737134941,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 222/270: training loss=0.18377262353897095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935f853dcb9e256b9630\",\n",
      "    \"created_at\": 1737134942,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 223/270: training loss=0.13245829939842224\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936132c62f8a365f64c7\",\n",
      "    \"created_at\": 1737134944,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 224/270: training loss=0.15940974652767181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9363853dcb9e256b9633\",\n",
      "    \"created_at\": 1737134946,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 225/270: training loss=0.22354091703891754, validation loss=0.9361454093765594, full validation loss=0.9361454093765594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9368853dcb9e256b9636\",\n",
      "    \"created_at\": 1737134950,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 226/270: training loss=0.06987695395946503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936932c62f8a365f64ca\",\n",
      "    \"created_at\": 1737134952,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 227/270: training loss=0.16204065084457397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936a853dcb9e256b9639\",\n",
      "    \"created_at\": 1737134953,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 228/270: training loss=0.10014106333255768\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936c32c62f8a365f64cd\",\n",
      "    \"created_at\": 1737134955,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 229/270: training loss=0.1414417028427124\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936d853dcb9e256b963c\",\n",
      "    \"created_at\": 1737134956,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 230/270: training loss=0.16190625727176666\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936e32c62f8a365f64d0\",\n",
      "    \"created_at\": 1737134957,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 231/270: training loss=0.07265762984752655\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936f853dcb9e256b963f\",\n",
      "    \"created_at\": 1737134958,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 232/270: training loss=0.12164939194917679\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937132c62f8a365f64d3\",\n",
      "    \"created_at\": 1737134960,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 233/270: training loss=0.19458816945552826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9372853dcb9e256b9642\",\n",
      "    \"created_at\": 1737134961,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 234/270: training loss=0.10454107075929642\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937332c62f8a365f64d6\",\n",
      "    \"created_at\": 1737134962,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 235/270: training loss=0.10439317673444748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9375853dcb9e256b9645\",\n",
      "    \"created_at\": 1737134964,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 236/270: training loss=0.11629471182823181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937632c62f8a365f64d9\",\n",
      "    \"created_at\": 1737134965,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 237/270: training loss=0.10698636621236801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9378853dcb9e256b9648\",\n",
      "    \"created_at\": 1737134966,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 238/270: training loss=0.08717890828847885\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937832c62f8a365f64dc\",\n",
      "    \"created_at\": 1737134968,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 239/270: training loss=0.08939964324235916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935332c62f8a365f64b8\",\n",
      "    \"created_at\": 1737134930,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 214/270: training loss=0.2851610481739044\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9355853dcb9e256b9624\",\n",
      "    \"created_at\": 1737134932,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 215/270: training loss=0.2181839793920517\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935632c62f8a365f64bb\",\n",
      "    \"created_at\": 1737134933,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 216/270: training loss=0.2576529383659363\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9357853dcb9e256b9627\",\n",
      "    \"created_at\": 1737134934,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 217/270: training loss=0.1464187502861023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935932c62f8a365f64be\",\n",
      "    \"created_at\": 1737134936,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 218/270: training loss=0.2709529399871826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935a853dcb9e256b962a\",\n",
      "    \"created_at\": 1737134937,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 219/270: training loss=0.2246333807706833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c32c62f8a365f64c1\",\n",
      "    \"created_at\": 1737134938,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 220/270: training loss=0.15977168083190918\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c853dcb9e256b962d\",\n",
      "    \"created_at\": 1737134940,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 221/270: training loss=0.43252938985824585\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935e32c62f8a365f64c4\",\n",
      "    \"created_at\": 1737134941,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 222/270: training loss=0.18377262353897095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935f853dcb9e256b9630\",\n",
      "    \"created_at\": 1737134942,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 223/270: training loss=0.13245829939842224\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936132c62f8a365f64c7\",\n",
      "    \"created_at\": 1737134944,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 224/270: training loss=0.15940974652767181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9363853dcb9e256b9633\",\n",
      "    \"created_at\": 1737134946,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 225/270: training loss=0.22354091703891754, validation loss=0.9361454093765594, full validation loss=0.9361454093765594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9368853dcb9e256b9636\",\n",
      "    \"created_at\": 1737134950,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 226/270: training loss=0.06987695395946503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936932c62f8a365f64ca\",\n",
      "    \"created_at\": 1737134952,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 227/270: training loss=0.16204065084457397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936a853dcb9e256b9639\",\n",
      "    \"created_at\": 1737134953,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 228/270: training loss=0.10014106333255768\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936c32c62f8a365f64cd\",\n",
      "    \"created_at\": 1737134955,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 229/270: training loss=0.1414417028427124\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936d853dcb9e256b963c\",\n",
      "    \"created_at\": 1737134956,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 230/270: training loss=0.16190625727176666\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936e32c62f8a365f64d0\",\n",
      "    \"created_at\": 1737134957,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 231/270: training loss=0.07265762984752655\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936f853dcb9e256b963f\",\n",
      "    \"created_at\": 1737134958,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 232/270: training loss=0.12164939194917679\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937132c62f8a365f64d3\",\n",
      "    \"created_at\": 1737134960,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 233/270: training loss=0.19458816945552826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9372853dcb9e256b9642\",\n",
      "    \"created_at\": 1737134961,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 234/270: training loss=0.10454107075929642\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937332c62f8a365f64d6\",\n",
      "    \"created_at\": 1737134962,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 235/270: training loss=0.10439317673444748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9375853dcb9e256b9645\",\n",
      "    \"created_at\": 1737134964,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 236/270: training loss=0.11629471182823181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937632c62f8a365f64d9\",\n",
      "    \"created_at\": 1737134965,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 237/270: training loss=0.10698636621236801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9378853dcb9e256b9648\",\n",
      "    \"created_at\": 1737134966,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 238/270: training loss=0.08717890828847885\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937832c62f8a365f64dc\",\n",
      "    \"created_at\": 1737134968,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 239/270: training loss=0.08939964324235916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937a853dcb9e256b964b\",\n",
      "    \"created_at\": 1737134969,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 240/270: training loss=0.07499294728040695\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937b32c62f8a365f64df\",\n",
      "    \"created_at\": 1737134970,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 241/270: training loss=0.1073426753282547\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937d853dcb9e256b964e\",\n",
      "    \"created_at\": 1737134972,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 242/270: training loss=0.13548344373703003\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937e32c62f8a365f64e2\",\n",
      "    \"created_at\": 1737134973,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 243/270: training loss=0.07782375812530518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937f853dcb9e256b9651\",\n",
      "    \"created_at\": 1737134974,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 244/270: training loss=0.1626926064491272\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938132c62f8a365f64e5\",\n",
      "    \"created_at\": 1737134976,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 245/270: training loss=0.12877827882766724\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9382853dcb9e256b9654\",\n",
      "    \"created_at\": 1737134977,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 246/270: training loss=0.1313783973455429\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938432c62f8a365f64e8\",\n",
      "    \"created_at\": 1737134978,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 247/270: training loss=0.09170598536729813\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9384853dcb9e256b9657\",\n",
      "    \"created_at\": 1737134980,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 248/270: training loss=0.21569176018238068\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938632c62f8a365f64eb\",\n",
      "    \"created_at\": 1737134981,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 249/270: training loss=0.16949859261512756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9387853dcb9e256b965a\",\n",
      "    \"created_at\": 1737134982,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 250/270: training loss=0.09198608994483948\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935332c62f8a365f64b8\",\n",
      "    \"created_at\": 1737134930,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 214/270: training loss=0.2851610481739044\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9355853dcb9e256b9624\",\n",
      "    \"created_at\": 1737134932,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 215/270: training loss=0.2181839793920517\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935632c62f8a365f64bb\",\n",
      "    \"created_at\": 1737134933,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 216/270: training loss=0.2576529383659363\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9357853dcb9e256b9627\",\n",
      "    \"created_at\": 1737134934,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 217/270: training loss=0.1464187502861023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935932c62f8a365f64be\",\n",
      "    \"created_at\": 1737134936,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 218/270: training loss=0.2709529399871826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935a853dcb9e256b962a\",\n",
      "    \"created_at\": 1737134937,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 219/270: training loss=0.2246333807706833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c32c62f8a365f64c1\",\n",
      "    \"created_at\": 1737134938,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 220/270: training loss=0.15977168083190918\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c853dcb9e256b962d\",\n",
      "    \"created_at\": 1737134940,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 221/270: training loss=0.43252938985824585\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935e32c62f8a365f64c4\",\n",
      "    \"created_at\": 1737134941,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 222/270: training loss=0.18377262353897095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935f853dcb9e256b9630\",\n",
      "    \"created_at\": 1737134942,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 223/270: training loss=0.13245829939842224\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936132c62f8a365f64c7\",\n",
      "    \"created_at\": 1737134944,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 224/270: training loss=0.15940974652767181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9363853dcb9e256b9633\",\n",
      "    \"created_at\": 1737134946,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 225/270: training loss=0.22354091703891754, validation loss=0.9361454093765594, full validation loss=0.9361454093765594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9368853dcb9e256b9636\",\n",
      "    \"created_at\": 1737134950,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 226/270: training loss=0.06987695395946503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936932c62f8a365f64ca\",\n",
      "    \"created_at\": 1737134952,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 227/270: training loss=0.16204065084457397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936a853dcb9e256b9639\",\n",
      "    \"created_at\": 1737134953,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 228/270: training loss=0.10014106333255768\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936c32c62f8a365f64cd\",\n",
      "    \"created_at\": 1737134955,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 229/270: training loss=0.1414417028427124\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936d853dcb9e256b963c\",\n",
      "    \"created_at\": 1737134956,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 230/270: training loss=0.16190625727176666\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936e32c62f8a365f64d0\",\n",
      "    \"created_at\": 1737134957,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 231/270: training loss=0.07265762984752655\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936f853dcb9e256b963f\",\n",
      "    \"created_at\": 1737134958,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 232/270: training loss=0.12164939194917679\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937132c62f8a365f64d3\",\n",
      "    \"created_at\": 1737134960,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 233/270: training loss=0.19458816945552826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9372853dcb9e256b9642\",\n",
      "    \"created_at\": 1737134961,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 234/270: training loss=0.10454107075929642\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937332c62f8a365f64d6\",\n",
      "    \"created_at\": 1737134962,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 235/270: training loss=0.10439317673444748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9375853dcb9e256b9645\",\n",
      "    \"created_at\": 1737134964,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 236/270: training loss=0.11629471182823181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937632c62f8a365f64d9\",\n",
      "    \"created_at\": 1737134965,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 237/270: training loss=0.10698636621236801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9378853dcb9e256b9648\",\n",
      "    \"created_at\": 1737134966,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 238/270: training loss=0.08717890828847885\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937832c62f8a365f64dc\",\n",
      "    \"created_at\": 1737134968,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 239/270: training loss=0.08939964324235916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937a853dcb9e256b964b\",\n",
      "    \"created_at\": 1737134969,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 240/270: training loss=0.07499294728040695\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937b32c62f8a365f64df\",\n",
      "    \"created_at\": 1737134970,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 241/270: training loss=0.1073426753282547\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937d853dcb9e256b964e\",\n",
      "    \"created_at\": 1737134972,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 242/270: training loss=0.13548344373703003\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937e32c62f8a365f64e2\",\n",
      "    \"created_at\": 1737134973,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 243/270: training loss=0.07782375812530518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937f853dcb9e256b9651\",\n",
      "    \"created_at\": 1737134974,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 244/270: training loss=0.1626926064491272\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938132c62f8a365f64e5\",\n",
      "    \"created_at\": 1737134976,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 245/270: training loss=0.12877827882766724\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9382853dcb9e256b9654\",\n",
      "    \"created_at\": 1737134977,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 246/270: training loss=0.1313783973455429\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938432c62f8a365f64e8\",\n",
      "    \"created_at\": 1737134978,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 247/270: training loss=0.09170598536729813\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9384853dcb9e256b9657\",\n",
      "    \"created_at\": 1737134980,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 248/270: training loss=0.21569176018238068\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938632c62f8a365f64eb\",\n",
      "    \"created_at\": 1737134981,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 249/270: training loss=0.16949859261512756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9387853dcb9e256b965a\",\n",
      "    \"created_at\": 1737134982,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 250/270: training loss=0.09198608994483948\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938932c62f8a365f64ee\",\n",
      "    \"created_at\": 1737134984,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 251/270: training loss=0.1752678006887436\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938a853dcb9e256b965d\",\n",
      "    \"created_at\": 1737134985,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 252/270: training loss=0.2655774652957916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938b32c62f8a365f64f1\",\n",
      "    \"created_at\": 1737134986,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 253/270: training loss=0.11848416924476624\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938d853dcb9e256b9660\",\n",
      "    \"created_at\": 1737134988,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 254/270: training loss=0.17658597230911255\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938e32c62f8a365f64f4\",\n",
      "    \"created_at\": 1737134989,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 255/270: training loss=0.11616112291812897\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938f853dcb9e256b9663\",\n",
      "    \"created_at\": 1737134990,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 256/270: training loss=0.11873071640729904\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939032c62f8a365f64f7\",\n",
      "    \"created_at\": 1737134992,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 257/270: training loss=0.13619545102119446\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9392853dcb9e256b9666\",\n",
      "    \"created_at\": 1737134993,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 258/270: training loss=0.14970344305038452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939432c62f8a365f64fa\",\n",
      "    \"created_at\": 1737134994,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 259/270: training loss=0.1752220243215561\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9395853dcb9e256b9669\",\n",
      "    \"created_at\": 1737134996,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 260/270: training loss=0.10681001842021942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939632c62f8a365f64fd\",\n",
      "    \"created_at\": 1737134997,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 261/270: training loss=0.13466989994049072\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9397853dcb9e256b966c\",\n",
      "    \"created_at\": 1737134999,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 262/270: training loss=0.08956924825906754\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939932c62f8a365f6500\",\n",
      "    \"created_at\": 1737135000,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 263/270: training loss=0.13542675971984863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b853dcb9e256b966f\",\n",
      "    \"created_at\": 1737135001,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 264/270: training loss=0.1931263953447342\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b32c62f8a365f6503\",\n",
      "    \"created_at\": 1737135003,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 265/270: training loss=0.20059852302074432\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935332c62f8a365f64b8\",\n",
      "    \"created_at\": 1737134930,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 214/270: training loss=0.2851610481739044\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9355853dcb9e256b9624\",\n",
      "    \"created_at\": 1737134932,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 215/270: training loss=0.2181839793920517\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935632c62f8a365f64bb\",\n",
      "    \"created_at\": 1737134933,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 216/270: training loss=0.2576529383659363\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9357853dcb9e256b9627\",\n",
      "    \"created_at\": 1737134934,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 217/270: training loss=0.1464187502861023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935932c62f8a365f64be\",\n",
      "    \"created_at\": 1737134936,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 218/270: training loss=0.2709529399871826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935a853dcb9e256b962a\",\n",
      "    \"created_at\": 1737134937,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 219/270: training loss=0.2246333807706833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c32c62f8a365f64c1\",\n",
      "    \"created_at\": 1737134938,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 220/270: training loss=0.15977168083190918\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c853dcb9e256b962d\",\n",
      "    \"created_at\": 1737134940,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 221/270: training loss=0.43252938985824585\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935e32c62f8a365f64c4\",\n",
      "    \"created_at\": 1737134941,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 222/270: training loss=0.18377262353897095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935f853dcb9e256b9630\",\n",
      "    \"created_at\": 1737134942,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 223/270: training loss=0.13245829939842224\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936132c62f8a365f64c7\",\n",
      "    \"created_at\": 1737134944,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 224/270: training loss=0.15940974652767181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9363853dcb9e256b9633\",\n",
      "    \"created_at\": 1737134946,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 225/270: training loss=0.22354091703891754, validation loss=0.9361454093765594, full validation loss=0.9361454093765594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9368853dcb9e256b9636\",\n",
      "    \"created_at\": 1737134950,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 226/270: training loss=0.06987695395946503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936932c62f8a365f64ca\",\n",
      "    \"created_at\": 1737134952,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 227/270: training loss=0.16204065084457397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936a853dcb9e256b9639\",\n",
      "    \"created_at\": 1737134953,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 228/270: training loss=0.10014106333255768\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936c32c62f8a365f64cd\",\n",
      "    \"created_at\": 1737134955,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 229/270: training loss=0.1414417028427124\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936d853dcb9e256b963c\",\n",
      "    \"created_at\": 1737134956,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 230/270: training loss=0.16190625727176666\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936e32c62f8a365f64d0\",\n",
      "    \"created_at\": 1737134957,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 231/270: training loss=0.07265762984752655\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936f853dcb9e256b963f\",\n",
      "    \"created_at\": 1737134958,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 232/270: training loss=0.12164939194917679\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937132c62f8a365f64d3\",\n",
      "    \"created_at\": 1737134960,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 233/270: training loss=0.19458816945552826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9372853dcb9e256b9642\",\n",
      "    \"created_at\": 1737134961,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 234/270: training loss=0.10454107075929642\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937332c62f8a365f64d6\",\n",
      "    \"created_at\": 1737134962,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 235/270: training loss=0.10439317673444748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9375853dcb9e256b9645\",\n",
      "    \"created_at\": 1737134964,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 236/270: training loss=0.11629471182823181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937632c62f8a365f64d9\",\n",
      "    \"created_at\": 1737134965,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 237/270: training loss=0.10698636621236801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9378853dcb9e256b9648\",\n",
      "    \"created_at\": 1737134966,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 238/270: training loss=0.08717890828847885\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937832c62f8a365f64dc\",\n",
      "    \"created_at\": 1737134968,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 239/270: training loss=0.08939964324235916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937a853dcb9e256b964b\",\n",
      "    \"created_at\": 1737134969,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 240/270: training loss=0.07499294728040695\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937b32c62f8a365f64df\",\n",
      "    \"created_at\": 1737134970,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 241/270: training loss=0.1073426753282547\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937d853dcb9e256b964e\",\n",
      "    \"created_at\": 1737134972,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 242/270: training loss=0.13548344373703003\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937e32c62f8a365f64e2\",\n",
      "    \"created_at\": 1737134973,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 243/270: training loss=0.07782375812530518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937f853dcb9e256b9651\",\n",
      "    \"created_at\": 1737134974,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 244/270: training loss=0.1626926064491272\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938132c62f8a365f64e5\",\n",
      "    \"created_at\": 1737134976,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 245/270: training loss=0.12877827882766724\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9382853dcb9e256b9654\",\n",
      "    \"created_at\": 1737134977,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 246/270: training loss=0.1313783973455429\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938432c62f8a365f64e8\",\n",
      "    \"created_at\": 1737134978,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 247/270: training loss=0.09170598536729813\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9384853dcb9e256b9657\",\n",
      "    \"created_at\": 1737134980,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 248/270: training loss=0.21569176018238068\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938632c62f8a365f64eb\",\n",
      "    \"created_at\": 1737134981,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 249/270: training loss=0.16949859261512756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9387853dcb9e256b965a\",\n",
      "    \"created_at\": 1737134982,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 250/270: training loss=0.09198608994483948\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938932c62f8a365f64ee\",\n",
      "    \"created_at\": 1737134984,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 251/270: training loss=0.1752678006887436\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938a853dcb9e256b965d\",\n",
      "    \"created_at\": 1737134985,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 252/270: training loss=0.2655774652957916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938b32c62f8a365f64f1\",\n",
      "    \"created_at\": 1737134986,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 253/270: training loss=0.11848416924476624\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938d853dcb9e256b9660\",\n",
      "    \"created_at\": 1737134988,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 254/270: training loss=0.17658597230911255\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938e32c62f8a365f64f4\",\n",
      "    \"created_at\": 1737134989,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 255/270: training loss=0.11616112291812897\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938f853dcb9e256b9663\",\n",
      "    \"created_at\": 1737134990,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 256/270: training loss=0.11873071640729904\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939032c62f8a365f64f7\",\n",
      "    \"created_at\": 1737134992,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 257/270: training loss=0.13619545102119446\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9392853dcb9e256b9666\",\n",
      "    \"created_at\": 1737134993,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 258/270: training loss=0.14970344305038452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939432c62f8a365f64fa\",\n",
      "    \"created_at\": 1737134994,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 259/270: training loss=0.1752220243215561\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9395853dcb9e256b9669\",\n",
      "    \"created_at\": 1737134996,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 260/270: training loss=0.10681001842021942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939632c62f8a365f64fd\",\n",
      "    \"created_at\": 1737134997,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 261/270: training loss=0.13466989994049072\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9397853dcb9e256b966c\",\n",
      "    \"created_at\": 1737134999,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 262/270: training loss=0.08956924825906754\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939932c62f8a365f6500\",\n",
      "    \"created_at\": 1737135000,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 263/270: training loss=0.13542675971984863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b853dcb9e256b966f\",\n",
      "    \"created_at\": 1737135001,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 264/270: training loss=0.1931263953447342\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b32c62f8a365f6503\",\n",
      "    \"created_at\": 1737135003,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 265/270: training loss=0.20059852302074432\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939d853dcb9e256b9672\",\n",
      "    \"created_at\": 1737135004,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 266/270: training loss=0.12496009469032288\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939e32c62f8a365f6506\",\n",
      "    \"created_at\": 1737135005,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 267/270: training loss=0.2031680792570114\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a0853dcb9e256b9675\",\n",
      "    \"created_at\": 1737135006,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 268/270: training loss=0.1637314110994339\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a132c62f8a365f6509\",\n",
      "    \"created_at\": 1737135008,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 269/270: training loss=0.10068610310554504\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a3853dcb9e256b9678\",\n",
      "    \"created_at\": 1737135010,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 270/270: training loss=0.23182962834835052, validation loss=0.9913114444938248, full validation loss=0.9913114444938248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935332c62f8a365f64b8\",\n",
      "    \"created_at\": 1737134930,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 214/270: training loss=0.2851610481739044\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9355853dcb9e256b9624\",\n",
      "    \"created_at\": 1737134932,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 215/270: training loss=0.2181839793920517\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935632c62f8a365f64bb\",\n",
      "    \"created_at\": 1737134933,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 216/270: training loss=0.2576529383659363\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9357853dcb9e256b9627\",\n",
      "    \"created_at\": 1737134934,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 217/270: training loss=0.1464187502861023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935932c62f8a365f64be\",\n",
      "    \"created_at\": 1737134936,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 218/270: training loss=0.2709529399871826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935a853dcb9e256b962a\",\n",
      "    \"created_at\": 1737134937,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 219/270: training loss=0.2246333807706833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c32c62f8a365f64c1\",\n",
      "    \"created_at\": 1737134938,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 220/270: training loss=0.15977168083190918\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c853dcb9e256b962d\",\n",
      "    \"created_at\": 1737134940,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 221/270: training loss=0.43252938985824585\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935e32c62f8a365f64c4\",\n",
      "    \"created_at\": 1737134941,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 222/270: training loss=0.18377262353897095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935f853dcb9e256b9630\",\n",
      "    \"created_at\": 1737134942,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 223/270: training loss=0.13245829939842224\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936132c62f8a365f64c7\",\n",
      "    \"created_at\": 1737134944,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 224/270: training loss=0.15940974652767181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9363853dcb9e256b9633\",\n",
      "    \"created_at\": 1737134946,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 225/270: training loss=0.22354091703891754, validation loss=0.9361454093765594, full validation loss=0.9361454093765594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9368853dcb9e256b9636\",\n",
      "    \"created_at\": 1737134950,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 226/270: training loss=0.06987695395946503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936932c62f8a365f64ca\",\n",
      "    \"created_at\": 1737134952,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 227/270: training loss=0.16204065084457397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936a853dcb9e256b9639\",\n",
      "    \"created_at\": 1737134953,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 228/270: training loss=0.10014106333255768\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936c32c62f8a365f64cd\",\n",
      "    \"created_at\": 1737134955,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 229/270: training loss=0.1414417028427124\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936d853dcb9e256b963c\",\n",
      "    \"created_at\": 1737134956,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 230/270: training loss=0.16190625727176666\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936e32c62f8a365f64d0\",\n",
      "    \"created_at\": 1737134957,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 231/270: training loss=0.07265762984752655\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936f853dcb9e256b963f\",\n",
      "    \"created_at\": 1737134958,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 232/270: training loss=0.12164939194917679\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937132c62f8a365f64d3\",\n",
      "    \"created_at\": 1737134960,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 233/270: training loss=0.19458816945552826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9372853dcb9e256b9642\",\n",
      "    \"created_at\": 1737134961,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 234/270: training loss=0.10454107075929642\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937332c62f8a365f64d6\",\n",
      "    \"created_at\": 1737134962,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 235/270: training loss=0.10439317673444748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9375853dcb9e256b9645\",\n",
      "    \"created_at\": 1737134964,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 236/270: training loss=0.11629471182823181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937632c62f8a365f64d9\",\n",
      "    \"created_at\": 1737134965,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 237/270: training loss=0.10698636621236801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9378853dcb9e256b9648\",\n",
      "    \"created_at\": 1737134966,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 238/270: training loss=0.08717890828847885\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937832c62f8a365f64dc\",\n",
      "    \"created_at\": 1737134968,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 239/270: training loss=0.08939964324235916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937a853dcb9e256b964b\",\n",
      "    \"created_at\": 1737134969,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 240/270: training loss=0.07499294728040695\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937b32c62f8a365f64df\",\n",
      "    \"created_at\": 1737134970,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 241/270: training loss=0.1073426753282547\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937d853dcb9e256b964e\",\n",
      "    \"created_at\": 1737134972,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 242/270: training loss=0.13548344373703003\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937e32c62f8a365f64e2\",\n",
      "    \"created_at\": 1737134973,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 243/270: training loss=0.07782375812530518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937f853dcb9e256b9651\",\n",
      "    \"created_at\": 1737134974,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 244/270: training loss=0.1626926064491272\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938132c62f8a365f64e5\",\n",
      "    \"created_at\": 1737134976,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 245/270: training loss=0.12877827882766724\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9382853dcb9e256b9654\",\n",
      "    \"created_at\": 1737134977,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 246/270: training loss=0.1313783973455429\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938432c62f8a365f64e8\",\n",
      "    \"created_at\": 1737134978,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 247/270: training loss=0.09170598536729813\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9384853dcb9e256b9657\",\n",
      "    \"created_at\": 1737134980,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 248/270: training loss=0.21569176018238068\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938632c62f8a365f64eb\",\n",
      "    \"created_at\": 1737134981,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 249/270: training loss=0.16949859261512756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9387853dcb9e256b965a\",\n",
      "    \"created_at\": 1737134982,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 250/270: training loss=0.09198608994483948\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938932c62f8a365f64ee\",\n",
      "    \"created_at\": 1737134984,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 251/270: training loss=0.1752678006887436\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938a853dcb9e256b965d\",\n",
      "    \"created_at\": 1737134985,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 252/270: training loss=0.2655774652957916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938b32c62f8a365f64f1\",\n",
      "    \"created_at\": 1737134986,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 253/270: training loss=0.11848416924476624\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938d853dcb9e256b9660\",\n",
      "    \"created_at\": 1737134988,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 254/270: training loss=0.17658597230911255\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938e32c62f8a365f64f4\",\n",
      "    \"created_at\": 1737134989,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 255/270: training loss=0.11616112291812897\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938f853dcb9e256b9663\",\n",
      "    \"created_at\": 1737134990,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 256/270: training loss=0.11873071640729904\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939032c62f8a365f64f7\",\n",
      "    \"created_at\": 1737134992,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 257/270: training loss=0.13619545102119446\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9392853dcb9e256b9666\",\n",
      "    \"created_at\": 1737134993,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 258/270: training loss=0.14970344305038452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939432c62f8a365f64fa\",\n",
      "    \"created_at\": 1737134994,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 259/270: training loss=0.1752220243215561\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9395853dcb9e256b9669\",\n",
      "    \"created_at\": 1737134996,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 260/270: training loss=0.10681001842021942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939632c62f8a365f64fd\",\n",
      "    \"created_at\": 1737134997,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 261/270: training loss=0.13466989994049072\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9397853dcb9e256b966c\",\n",
      "    \"created_at\": 1737134999,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 262/270: training loss=0.08956924825906754\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939932c62f8a365f6500\",\n",
      "    \"created_at\": 1737135000,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 263/270: training loss=0.13542675971984863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b853dcb9e256b966f\",\n",
      "    \"created_at\": 1737135001,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 264/270: training loss=0.1931263953447342\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b32c62f8a365f6503\",\n",
      "    \"created_at\": 1737135003,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 265/270: training loss=0.20059852302074432\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939d853dcb9e256b9672\",\n",
      "    \"created_at\": 1737135004,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 266/270: training loss=0.12496009469032288\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939e32c62f8a365f6506\",\n",
      "    \"created_at\": 1737135005,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 267/270: training loss=0.2031680792570114\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a0853dcb9e256b9675\",\n",
      "    \"created_at\": 1737135006,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 268/270: training loss=0.1637314110994339\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a132c62f8a365f6509\",\n",
      "    \"created_at\": 1737135008,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 269/270: training loss=0.10068610310554504\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a3853dcb9e256b9678\",\n",
      "    \"created_at\": 1737135010,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 270/270: training loss=0.23182962834835052, validation loss=0.9913114444938248, full validation loss=0.9913114444938248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: succeeded\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935332c62f8a365f64b8\",\n",
      "    \"created_at\": 1737134930,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 214/270: training loss=0.2851610481739044\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9355853dcb9e256b9624\",\n",
      "    \"created_at\": 1737134932,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 215/270: training loss=0.2181839793920517\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935632c62f8a365f64bb\",\n",
      "    \"created_at\": 1737134933,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 216/270: training loss=0.2576529383659363\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9357853dcb9e256b9627\",\n",
      "    \"created_at\": 1737134934,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 217/270: training loss=0.1464187502861023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935932c62f8a365f64be\",\n",
      "    \"created_at\": 1737134936,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 218/270: training loss=0.2709529399871826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935a853dcb9e256b962a\",\n",
      "    \"created_at\": 1737134937,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 219/270: training loss=0.2246333807706833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c32c62f8a365f64c1\",\n",
      "    \"created_at\": 1737134938,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 220/270: training loss=0.15977168083190918\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c853dcb9e256b962d\",\n",
      "    \"created_at\": 1737134940,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 221/270: training loss=0.43252938985824585\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935e32c62f8a365f64c4\",\n",
      "    \"created_at\": 1737134941,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 222/270: training loss=0.18377262353897095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935f853dcb9e256b9630\",\n",
      "    \"created_at\": 1737134942,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 223/270: training loss=0.13245829939842224\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936132c62f8a365f64c7\",\n",
      "    \"created_at\": 1737134944,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 224/270: training loss=0.15940974652767181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9363853dcb9e256b9633\",\n",
      "    \"created_at\": 1737134946,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 225/270: training loss=0.22354091703891754, validation loss=0.9361454093765594, full validation loss=0.9361454093765594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9368853dcb9e256b9636\",\n",
      "    \"created_at\": 1737134950,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 226/270: training loss=0.06987695395946503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936932c62f8a365f64ca\",\n",
      "    \"created_at\": 1737134952,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 227/270: training loss=0.16204065084457397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936a853dcb9e256b9639\",\n",
      "    \"created_at\": 1737134953,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 228/270: training loss=0.10014106333255768\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936c32c62f8a365f64cd\",\n",
      "    \"created_at\": 1737134955,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 229/270: training loss=0.1414417028427124\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936d853dcb9e256b963c\",\n",
      "    \"created_at\": 1737134956,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 230/270: training loss=0.16190625727176666\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936e32c62f8a365f64d0\",\n",
      "    \"created_at\": 1737134957,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 231/270: training loss=0.07265762984752655\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936f853dcb9e256b963f\",\n",
      "    \"created_at\": 1737134958,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 232/270: training loss=0.12164939194917679\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937132c62f8a365f64d3\",\n",
      "    \"created_at\": 1737134960,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 233/270: training loss=0.19458816945552826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9372853dcb9e256b9642\",\n",
      "    \"created_at\": 1737134961,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 234/270: training loss=0.10454107075929642\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937332c62f8a365f64d6\",\n",
      "    \"created_at\": 1737134962,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 235/270: training loss=0.10439317673444748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9375853dcb9e256b9645\",\n",
      "    \"created_at\": 1737134964,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 236/270: training loss=0.11629471182823181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937632c62f8a365f64d9\",\n",
      "    \"created_at\": 1737134965,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 237/270: training loss=0.10698636621236801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9378853dcb9e256b9648\",\n",
      "    \"created_at\": 1737134966,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 238/270: training loss=0.08717890828847885\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937832c62f8a365f64dc\",\n",
      "    \"created_at\": 1737134968,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 239/270: training loss=0.08939964324235916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937832c62f8a365f64dc\",\n",
      "    \"created_at\": 1737134968,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 239/270: training loss=0.08939964324235916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937a853dcb9e256b964b\",\n",
      "    \"created_at\": 1737134969,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 240/270: training loss=0.07499294728040695\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937b32c62f8a365f64df\",\n",
      "    \"created_at\": 1737134970,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 241/270: training loss=0.1073426753282547\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937d853dcb9e256b964e\",\n",
      "    \"created_at\": 1737134972,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 242/270: training loss=0.13548344373703003\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937e32c62f8a365f64e2\",\n",
      "    \"created_at\": 1737134973,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 243/270: training loss=0.07782375812530518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937f853dcb9e256b9651\",\n",
      "    \"created_at\": 1737134974,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 244/270: training loss=0.1626926064491272\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938132c62f8a365f64e5\",\n",
      "    \"created_at\": 1737134976,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 245/270: training loss=0.12877827882766724\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9382853dcb9e256b9654\",\n",
      "    \"created_at\": 1737134977,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 246/270: training loss=0.1313783973455429\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938432c62f8a365f64e8\",\n",
      "    \"created_at\": 1737134978,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 247/270: training loss=0.09170598536729813\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9384853dcb9e256b9657\",\n",
      "    \"created_at\": 1737134980,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 248/270: training loss=0.21569176018238068\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938632c62f8a365f64eb\",\n",
      "    \"created_at\": 1737134981,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 249/270: training loss=0.16949859261512756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9387853dcb9e256b965a\",\n",
      "    \"created_at\": 1737134982,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 250/270: training loss=0.09198608994483948\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938932c62f8a365f64ee\",\n",
      "    \"created_at\": 1737134984,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 251/270: training loss=0.1752678006887436\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938a853dcb9e256b965d\",\n",
      "    \"created_at\": 1737134985,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 252/270: training loss=0.2655774652957916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938b32c62f8a365f64f1\",\n",
      "    \"created_at\": 1737134986,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 253/270: training loss=0.11848416924476624\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938d853dcb9e256b9660\",\n",
      "    \"created_at\": 1737134988,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 254/270: training loss=0.17658597230911255\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938e32c62f8a365f64f4\",\n",
      "    \"created_at\": 1737134989,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 255/270: training loss=0.11616112291812897\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938f853dcb9e256b9663\",\n",
      "    \"created_at\": 1737134990,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 256/270: training loss=0.11873071640729904\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939032c62f8a365f64f7\",\n",
      "    \"created_at\": 1737134992,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 257/270: training loss=0.13619545102119446\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9392853dcb9e256b9666\",\n",
      "    \"created_at\": 1737134993,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 258/270: training loss=0.14970344305038452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939432c62f8a365f64fa\",\n",
      "    \"created_at\": 1737134994,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 259/270: training loss=0.1752220243215561\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9395853dcb9e256b9669\",\n",
      "    \"created_at\": 1737134996,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 260/270: training loss=0.10681001842021942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939632c62f8a365f64fd\",\n",
      "    \"created_at\": 1737134997,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 261/270: training loss=0.13466989994049072\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9397853dcb9e256b966c\",\n",
      "    \"created_at\": 1737134999,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 262/270: training loss=0.08956924825906754\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939932c62f8a365f6500\",\n",
      "    \"created_at\": 1737135000,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 263/270: training loss=0.13542675971984863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b853dcb9e256b966f\",\n",
      "    \"created_at\": 1737135001,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 264/270: training loss=0.1931263953447342\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b32c62f8a365f6503\",\n",
      "    \"created_at\": 1737135003,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 265/270: training loss=0.20059852302074432\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939d853dcb9e256b9672\",\n",
      "    \"created_at\": 1737135004,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 266/270: training loss=0.12496009469032288\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939e32c62f8a365f6506\",\n",
      "    \"created_at\": 1737135005,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 267/270: training loss=0.2031680792570114\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a0853dcb9e256b9675\",\n",
      "    \"created_at\": 1737135006,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 268/270: training loss=0.1637314110994339\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a132c62f8a365f6509\",\n",
      "    \"created_at\": 1737135008,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 269/270: training loss=0.10068610310554504\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a3853dcb9e256b9678\",\n",
      "    \"created_at\": 1737135010,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 270/270: training loss=0.23182962834835052, validation loss=0.9913114444938248, full validation loss=0.9913114444938248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93bb32c62f8a365f6521\",\n",
      "    \"created_at\": 1737135035,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"The job has successfully completed\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93bb32c62f8a365f651f\",\n",
      "    \"created_at\": 1737135035,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"New fine-tuned model created\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93bb32c62f8a365f651d\",\n",
      "    \"created_at\": 1737135035,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Checkpoint created at step 90\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93bb32c62f8a365f651a\",\n",
      "    \"created_at\": 1737135035,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Checkpoint created at step 45\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93bb32c62f8a365f6517\",\n",
      "    \"created_at\": 1737135035,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Checkpoint created at step 225\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93bb32c62f8a365f6514\",\n",
      "    \"created_at\": 1737135035,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Checkpoint created at step 180\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93bb32c62f8a365f6511\",\n",
      "    \"created_at\": 1737135035,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Checkpoint created at step 135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    job_status = client_stg.fine_tuning.jobs.retrieve(job.id)\n",
    "    status = job_status.status\n",
    "    print(f\"\\nCurrent status: {status}\")\n",
    "    \n",
    "    events = client_stg.fine_tuning.jobs.list_events(job.id)\n",
    "    events_list = [e.model_dump() for e in events]\n",
    "    events_list.sort(key=lambda x: x['created_at'])\n",
    "    print(\"\\nJob events:\")\n",
    "    print(json.dumps(events_list, indent=2))\n",
    "    \n",
    "    if status in [\"succeeded\", \"failed\", \"cancelled\"]:\n",
    "        break\n",
    "    \n",
    "    time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0c474a4-89ac-40c2-a1fe-a9d1e9267d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = job_status.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11dfc4b1-6b88-4379-a3b6-ecdd0026ba43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:klusterai:Meta-Llama-3.1-8B-Instruct-Turbo:personal::aacc8010'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_status.fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c41457-2f31-4e98-aa55-3a42a478b8e7",
   "metadata": {},
   "source": [
    "## Performing batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598eeeac-84dc-40eb-a64d-19ee80114bb8",
   "metadata": {},
   "source": [
    "With LLMs it is really important to write a good prompt, including the system prompt. Below you can see our example instruction for the LLM. This is something you should experiment with and see how it changes the performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bb7f503-dbe5-4983-99e7-0794a0835ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = '''\n",
    "    You are a helpful assistant specializing in determining the sentiment of financial news. \n",
    "    Analyze the following text regarding financial information and assign one of the following labels to indicate its sentiment: positive, negative, or neutral. \n",
    "    Provide your response as a single word without any punctuation.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f5a51c-fc39-4567-b85d-95a98d5f9c98",
   "metadata": {},
   "source": [
    "Now that the prompt is defined, it’s time to execute the code and run the classification task for each model. In this step, we loop through the list of models, creating the requests and batch jobs, monitoring progress and retrieving the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe1531a6-844e-4173-8122-a7bf871df06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ft_8b model job completed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "        '8B':\"klusterai/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "        '70B':\"klusterai/Meta-Llama-3.3-70B-Instruct-Turbo\",\n",
    "        '405B':\"klusterai/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "        'ft_8B': fine_tuned_model\n",
    "        }\n",
    "\n",
    "# Process each model: create tasks, run jobs, and get results\n",
    "for name, model in models.items():\n",
    "    task_list = create_tasks(test_df, task_type='assistant', system_prompt=SYSTEM_PROMPT, model=model, content_column='text')\n",
    "    filename = save_tasks(task_list, task_type='assistant')\n",
    "    if name != 'ft_8B':\n",
    "        job = create_batch_job(filename, client=client_prod)\n",
    "        monitor_job_status(client=client_prod, job_id=job.id, task_type=f'{name} model')\n",
    "        test_df[f'answer_base_{name}'] = get_results(client=client_prod, job_id=job.id)\n",
    "    else:\n",
    "        job = create_batch_job(filename, client=client_stg)\n",
    "        monitor_job_status(client=client_stg, job_id=job.id, task_type=f'{name} model')\n",
    "        test_df[f'answer_{name}'] = get_results(client=client_stg, job_id=job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0f539e6-4db6-49e3-af00-8bea1772fab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>answer_base_8B</th>\n",
       "      <th>answer_base_70B</th>\n",
       "      <th>answer_base_405B</th>\n",
       "      <th>answer_ft_8B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>positive</td>\n",
       "      <td>Under the terms of the off-take agreement with Talvivaara , Cameco will provide an up-front investment , to a maximum of $ 60 million , to cover the construction cost of the uranium extraction circuit .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>positive</td>\n",
       "      <td>The contracts have been signed to acquire uranium produced at the Sotkamo nickel-zinc mine in eastern Finland owned by Talvivaara .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>positive</td>\n",
       "      <td>These moderate but significant changes resulted in a significant 24-32 % reduction in the estimated CVD risk .</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                                                                                                                                                                                        text answer_base_8B answer_base_70B answer_base_405B answer_ft_8B\n",
       "461  positive  Under the terms of the off-take agreement with Talvivaara , Cameco will provide an up-front investment , to a maximum of $ 60 million , to cover the construction cost of the uranium extraction circuit .        neutral        positive         positive     positive\n",
       "455  positive                                                                         The contracts have been signed to acquire uranium produced at the Sotkamo nickel-zinc mine in eastern Finland owned by Talvivaara .        neutral        positive          Neutral     positive\n",
       "996  positive                                                                                              These moderate but significant changes resulted in a significant 24-32 % reduction in the estimated CVD risk .       positive        positive         positive     positive"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac1e99-edfe-4041-819e-1d366fbcfd68",
   "metadata": {},
   "source": [
    "## Analyzing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6654619-712c-4a08-b43b-6fdb6caaa871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lf/m3hzxk7j1ns1bt50twyl8hmr0000gn/T/ipykernel_66176/1163933663.py:17: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(y=list(accuracies.keys()), x=list(accuracies.values()), palette=\"viridis\", edgecolor='black', ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rename dictionary\n",
    "rename_dict = {\n",
    "    'answer_base_8B': 'Base 8b model',\n",
    "    'answer_base_70B': 'Base 70b model',\n",
    "    'answer_base_405B': 'Base 405b model',\n",
    "    'answer_ft_8B': 'Fine Tuned 8b model',\n",
    "}\n",
    "\n",
    "# Calculate accuracy for each model with renamed keys\n",
    "accuracies = {}\n",
    "for name in rename_dict:\n",
    "    accuracy = test_df.apply(lambda row: row[name] in row['sentiment'], axis=1).mean()\n",
    "    accuracies[rename_dict[name]] = accuracy\n",
    "\n",
    "# Horizontal bar chart\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.barplot(y=list(accuracies.keys()), x=list(accuracies.values()), palette=\"viridis\", edgecolor='black', ax=ax)\n",
    "\n",
    "# Add labels to bars\n",
    "for i, bar in enumerate(ax.patches):\n",
    "    ax.text(bar.get_width() - 0.02, \n",
    "            bar.get_y() + bar.get_height() / 2, \n",
    "            f\"{list(accuracies.values())[i]:.3f}\", \n",
    "            ha='right', va='center', color='white', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Set plot aesthetics\n",
    "ax.set_xlim(0, max(accuracies.values()) + 0.05)\n",
    "ax.set_xlabel('Accuracy', fontsize=12)\n",
    "ax.set_ylabel('Model', fontsize=12)\n",
    "ax.set_title('Classification Accuracy by Model', fontsize=14, fontweight='bold')\n",
    "sns.despine()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb880d9-13ad-4ef8-a2f6-ece194d4ba4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

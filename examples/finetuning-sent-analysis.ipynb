{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7",
   "metadata": {
    "id": "be189fde-4e5b-4f80-bae1-ded86a5075a7"
   },
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a77d9",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kluster-ai/klusterai-cookbook/blob/main/examples/.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e867bee8-9173-473d-84c4-48c10b38cc2e",
   "metadata": {},
   "source": [
    "## Setting up your environment\n",
    "\n",
    "### API key configuration\n",
    "To get started with this tutorial, you'll need a kluster.ai API key. If you don't have one yet, follow these steps:\n",
    "1. Visit the <a href=\"https://platform.kluster.ai/signup\" target=\"_blank\">kluster.ai</a> to create an account.\n",
    "2. Generate your API key\n",
    "\n",
    "Once you have your API key, we'll use it to authenticate our requests to the kluster.ai API.\n",
    "\n",
    "### Important note\n",
    "Keep your API key secure and never share it publicly. In this notebook, we'll use Python's getpass module to safely input the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f2171bb-2b89-4fd4-a7f0-37f2d076466a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your kluster.ai API key:  ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "# Enter you personal kluster.ai API key (make sure in advance it has no blank spaces)\n",
    "api_key = getpass(\"Enter your kluster.ai API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad68612f-82f7-4519-823a-407e4e51e504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af45325-7087-49fe-b32b-0ff1d6537af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import requests\n",
    "pd.set_option('display.max_columns', 1000, 'display.width', 1000, 'display.max_rows',1000, 'display.max_colwidth', 500)\n",
    "#\n",
    "## Import helper functions\n",
    "#url = \"https://raw.githubusercontent.com/kluster-ai/klusterai-cookbook/refs/heads/joaquin/testing-notebooks/examples/raw/model-comparison.py\"\n",
    "#\n",
    "## Fetch the file and save it locally\n",
    "#response = requests.get(url)\n",
    "#with open(\"helpers.py\", \"w\") as f:\n",
    "#    f.write(response.text)\n",
    "\n",
    "# Import the helper functions\n",
    "from helpers import create_tasks, save_tasks, create_batch_job, monitor_job_status, get_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a6f805-1c74-48a5-8572-0a5fb2c48286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the client\n",
    "client_prod = OpenAI(\n",
    "    base_url=\"https://api.kluster.ai/v1\",\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e1f91fa-ec0f-4843-852e-56a720b7e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key_stg = os.getenv(\"KLUSTER_API_KEY_STG\")\n",
    "base_url = os.getenv(\"KLUSTER_BASE_URL\", \"https://api-r.klusterai.dev/v1\")\n",
    "\n",
    "if not api_key_stg:\n",
    "    raise ValueError(\"KLUSTER_API_KEY environment variable is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e599b93-d419-4690-a295-1038d3286115",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_stg = OpenAI(\n",
    "    api_key=api_key_stg,\n",
    "    base_url=base_url\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8c5014-5b0c-43c2-a238-073dbde2d90a",
   "metadata": {
    "id": "udPtLfTaisSw"
   },
   "source": [
    "## Fetch a real dataset for batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "yC9wJlV4rwOh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                                                                                                                                                                                                                  text\n",
       "0   neutral                                                                                                       According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\n",
       "1   neutral                                        Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .\n",
       "2  negative  The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported ."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "#url = \"https://raw.githubusercontent.com/kluster-ai/klusterai-cookbook/refs/heads/main/data/imdb_top_1000.csv\"\n",
    "#urllib.request.urlretrieve(url,filename='imdb_top_1000.csv')\n",
    "\n",
    "# Load and process the dataset based on URL content\n",
    "df = pd.read_csv('financial-phrasebank.csv', encoding = \"ISO-8859-1\",header=None, names=[\"sentiment\", \"text\"])\n",
    "df = df.iloc[:1000]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a03d805-0d59-42ce-ac2a-4f9beacd639b",
   "metadata": {},
   "source": [
    "#### Train-test split for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de8b2580-43ba-438f-8aab-4916a4c1fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.9, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb5b6d85-aea0-4c77-97d5-a8cb007fa43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebefac4-cb4c-4e75-af96-c827b5668188",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4903010-b32f-47d0-9a01-6be8e0938328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate JSONLines file\n",
    "with open(\"finetuning/data/sentiment.jsonl\", \"w\") as f:\n",
    "    for _, row in train_df.iterrows():\n",
    "        # Create the message structure\n",
    "        messages = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": row['text']},\n",
    "                {\"role\": \"assistant\", \"content\": row[\"sentiment\"]}\n",
    "            ]\n",
    "        }\n",
    "        # Write to the file as a single JSON object per line\n",
    "        f.write(json.dumps(messages) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "653ff10c-59bb-443d-b031-c6678744bdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully. File ID: 678a92129865c142b39dab99\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'finetuning/data/sentiment.jsonl'\n",
    "\n",
    "with open(data_dir, 'rb') as file:\n",
    "    upload_response = client_stg.files.create(\n",
    "        file=file,\n",
    "        purpose=\"fine-tune\"\n",
    "    )\n",
    "    file_id = upload_response.id\n",
    "    print(f\"File uploaded successfully. File ID: {file_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c4bcef6-aee7-4d3e-9161-9465ac6656db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning job created:\n",
      "{\n",
      "  \"id\": \"678a9216da5fe6a8dc4dfd52\",\n",
      "  \"created_at\": 1737134614,\n",
      "  \"error\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"finished_at\": null,\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": \"auto\",\n",
      "    \"batch_size\": \"auto\",\n",
      "    \"learning_rate_multiplier\": \"auto\"\n",
      "  },\n",
      "  \"model\": \"klusterai/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": null,\n",
      "  \"result_files\": [],\n",
      "  \"seed\": null,\n",
      "  \"status\": \"queued\",\n",
      "  \"trained_tokens\": null,\n",
      "  \"training_file\": \"678a92129865c142b39dab99\",\n",
      "  \"validation_file\": null,\n",
      "  \"estimated_finish\": null,\n",
      "  \"integrations\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job = client_stg.fine_tuning.jobs.create(\n",
    "    training_file=file_id,\n",
    "    model=\"klusterai/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "    #hyperparameters={\n",
    "    #    \"batch_size\": 4,\n",
    "    #    \"n_epochs\": 2,\n",
    "    #    \"learning_rate_multiplier\": 1\n",
    "    #}\n",
    ")\n",
    "print(\"\\nFine-tuning job created:\")\n",
    "print(json.dumps(job.model_dump(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "419c1ad3-617c-4d5f-aa57-86f7f48cec05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935332c62f8a365f64b8\",\n",
      "    \"created_at\": 1737134930,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 214/270: training loss=0.2851610481739044\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9355853dcb9e256b9624\",\n",
      "    \"created_at\": 1737134932,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 215/270: training loss=0.2181839793920517\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935632c62f8a365f64bb\",\n",
      "    \"created_at\": 1737134933,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 216/270: training loss=0.2576529383659363\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9357853dcb9e256b9627\",\n",
      "    \"created_at\": 1737134934,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 217/270: training loss=0.1464187502861023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935932c62f8a365f64be\",\n",
      "    \"created_at\": 1737134936,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 218/270: training loss=0.2709529399871826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935a853dcb9e256b962a\",\n",
      "    \"created_at\": 1737134937,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 219/270: training loss=0.2246333807706833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c32c62f8a365f64c1\",\n",
      "    \"created_at\": 1737134938,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 220/270: training loss=0.15977168083190918\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c853dcb9e256b962d\",\n",
      "    \"created_at\": 1737134940,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 221/270: training loss=0.43252938985824585\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935e32c62f8a365f64c4\",\n",
      "    \"created_at\": 1737134941,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 222/270: training loss=0.18377262353897095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935f853dcb9e256b9630\",\n",
      "    \"created_at\": 1737134942,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 223/270: training loss=0.13245829939842224\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935332c62f8a365f64b8\",\n",
      "    \"created_at\": 1737134930,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 214/270: training loss=0.2851610481739044\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9355853dcb9e256b9624\",\n",
      "    \"created_at\": 1737134932,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 215/270: training loss=0.2181839793920517\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935632c62f8a365f64bb\",\n",
      "    \"created_at\": 1737134933,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 216/270: training loss=0.2576529383659363\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9357853dcb9e256b9627\",\n",
      "    \"created_at\": 1737134934,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 217/270: training loss=0.1464187502861023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935932c62f8a365f64be\",\n",
      "    \"created_at\": 1737134936,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 218/270: training loss=0.2709529399871826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935a853dcb9e256b962a\",\n",
      "    \"created_at\": 1737134937,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 219/270: training loss=0.2246333807706833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c32c62f8a365f64c1\",\n",
      "    \"created_at\": 1737134938,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 220/270: training loss=0.15977168083190918\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c853dcb9e256b962d\",\n",
      "    \"created_at\": 1737134940,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 221/270: training loss=0.43252938985824585\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935e32c62f8a365f64c4\",\n",
      "    \"created_at\": 1737134941,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 222/270: training loss=0.18377262353897095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935f853dcb9e256b9630\",\n",
      "    \"created_at\": 1737134942,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 223/270: training loss=0.13245829939842224\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936132c62f8a365f64c7\",\n",
      "    \"created_at\": 1737134944,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 224/270: training loss=0.15940974652767181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9363853dcb9e256b9633\",\n",
      "    \"created_at\": 1737134946,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 225/270: training loss=0.22354091703891754, validation loss=0.9361454093765594, full validation loss=0.9361454093765594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9368853dcb9e256b9636\",\n",
      "    \"created_at\": 1737134950,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 226/270: training loss=0.06987695395946503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936932c62f8a365f64ca\",\n",
      "    \"created_at\": 1737134952,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 227/270: training loss=0.16204065084457397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936a853dcb9e256b9639\",\n",
      "    \"created_at\": 1737134953,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 228/270: training loss=0.10014106333255768\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936c32c62f8a365f64cd\",\n",
      "    \"created_at\": 1737134955,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 229/270: training loss=0.1414417028427124\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936d853dcb9e256b963c\",\n",
      "    \"created_at\": 1737134956,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 230/270: training loss=0.16190625727176666\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936e32c62f8a365f64d0\",\n",
      "    \"created_at\": 1737134957,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 231/270: training loss=0.07265762984752655\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936f853dcb9e256b963f\",\n",
      "    \"created_at\": 1737134958,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 232/270: training loss=0.12164939194917679\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937132c62f8a365f64d3\",\n",
      "    \"created_at\": 1737134960,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 233/270: training loss=0.19458816945552826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9372853dcb9e256b9642\",\n",
      "    \"created_at\": 1737134961,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 234/270: training loss=0.10454107075929642\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937332c62f8a365f64d6\",\n",
      "    \"created_at\": 1737134962,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 235/270: training loss=0.10439317673444748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9375853dcb9e256b9645\",\n",
      "    \"created_at\": 1737134964,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 236/270: training loss=0.11629471182823181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937632c62f8a365f64d9\",\n",
      "    \"created_at\": 1737134965,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 237/270: training loss=0.10698636621236801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9378853dcb9e256b9648\",\n",
      "    \"created_at\": 1737134966,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 238/270: training loss=0.08717890828847885\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937832c62f8a365f64dc\",\n",
      "    \"created_at\": 1737134968,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 239/270: training loss=0.08939964324235916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935332c62f8a365f64b8\",\n",
      "    \"created_at\": 1737134930,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 214/270: training loss=0.2851610481739044\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9355853dcb9e256b9624\",\n",
      "    \"created_at\": 1737134932,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 215/270: training loss=0.2181839793920517\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935632c62f8a365f64bb\",\n",
      "    \"created_at\": 1737134933,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 216/270: training loss=0.2576529383659363\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9357853dcb9e256b9627\",\n",
      "    \"created_at\": 1737134934,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 217/270: training loss=0.1464187502861023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935932c62f8a365f64be\",\n",
      "    \"created_at\": 1737134936,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 218/270: training loss=0.2709529399871826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935a853dcb9e256b962a\",\n",
      "    \"created_at\": 1737134937,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 219/270: training loss=0.2246333807706833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c32c62f8a365f64c1\",\n",
      "    \"created_at\": 1737134938,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 220/270: training loss=0.15977168083190918\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c853dcb9e256b962d\",\n",
      "    \"created_at\": 1737134940,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 221/270: training loss=0.43252938985824585\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935e32c62f8a365f64c4\",\n",
      "    \"created_at\": 1737134941,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 222/270: training loss=0.18377262353897095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935f853dcb9e256b9630\",\n",
      "    \"created_at\": 1737134942,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 223/270: training loss=0.13245829939842224\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936132c62f8a365f64c7\",\n",
      "    \"created_at\": 1737134944,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 224/270: training loss=0.15940974652767181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9363853dcb9e256b9633\",\n",
      "    \"created_at\": 1737134946,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 225/270: training loss=0.22354091703891754, validation loss=0.9361454093765594, full validation loss=0.9361454093765594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9368853dcb9e256b9636\",\n",
      "    \"created_at\": 1737134950,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 226/270: training loss=0.06987695395946503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936932c62f8a365f64ca\",\n",
      "    \"created_at\": 1737134952,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 227/270: training loss=0.16204065084457397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936a853dcb9e256b9639\",\n",
      "    \"created_at\": 1737134953,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 228/270: training loss=0.10014106333255768\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936c32c62f8a365f64cd\",\n",
      "    \"created_at\": 1737134955,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 229/270: training loss=0.1414417028427124\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936d853dcb9e256b963c\",\n",
      "    \"created_at\": 1737134956,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 230/270: training loss=0.16190625727176666\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936e32c62f8a365f64d0\",\n",
      "    \"created_at\": 1737134957,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 231/270: training loss=0.07265762984752655\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936f853dcb9e256b963f\",\n",
      "    \"created_at\": 1737134958,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 232/270: training loss=0.12164939194917679\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937132c62f8a365f64d3\",\n",
      "    \"created_at\": 1737134960,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 233/270: training loss=0.19458816945552826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9372853dcb9e256b9642\",\n",
      "    \"created_at\": 1737134961,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 234/270: training loss=0.10454107075929642\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937332c62f8a365f64d6\",\n",
      "    \"created_at\": 1737134962,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 235/270: training loss=0.10439317673444748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9375853dcb9e256b9645\",\n",
      "    \"created_at\": 1737134964,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 236/270: training loss=0.11629471182823181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937632c62f8a365f64d9\",\n",
      "    \"created_at\": 1737134965,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 237/270: training loss=0.10698636621236801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9378853dcb9e256b9648\",\n",
      "    \"created_at\": 1737134966,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 238/270: training loss=0.08717890828847885\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937832c62f8a365f64dc\",\n",
      "    \"created_at\": 1737134968,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 239/270: training loss=0.08939964324235916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937a853dcb9e256b964b\",\n",
      "    \"created_at\": 1737134969,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 240/270: training loss=0.07499294728040695\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937b32c62f8a365f64df\",\n",
      "    \"created_at\": 1737134970,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 241/270: training loss=0.1073426753282547\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937d853dcb9e256b964e\",\n",
      "    \"created_at\": 1737134972,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 242/270: training loss=0.13548344373703003\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937e32c62f8a365f64e2\",\n",
      "    \"created_at\": 1737134973,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 243/270: training loss=0.07782375812530518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937f853dcb9e256b9651\",\n",
      "    \"created_at\": 1737134974,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 244/270: training loss=0.1626926064491272\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938132c62f8a365f64e5\",\n",
      "    \"created_at\": 1737134976,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 245/270: training loss=0.12877827882766724\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9382853dcb9e256b9654\",\n",
      "    \"created_at\": 1737134977,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 246/270: training loss=0.1313783973455429\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938432c62f8a365f64e8\",\n",
      "    \"created_at\": 1737134978,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 247/270: training loss=0.09170598536729813\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9384853dcb9e256b9657\",\n",
      "    \"created_at\": 1737134980,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 248/270: training loss=0.21569176018238068\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938632c62f8a365f64eb\",\n",
      "    \"created_at\": 1737134981,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 249/270: training loss=0.16949859261512756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9387853dcb9e256b965a\",\n",
      "    \"created_at\": 1737134982,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 250/270: training loss=0.09198608994483948\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935332c62f8a365f64b8\",\n",
      "    \"created_at\": 1737134930,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 214/270: training loss=0.2851610481739044\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9355853dcb9e256b9624\",\n",
      "    \"created_at\": 1737134932,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 215/270: training loss=0.2181839793920517\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935632c62f8a365f64bb\",\n",
      "    \"created_at\": 1737134933,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 216/270: training loss=0.2576529383659363\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9357853dcb9e256b9627\",\n",
      "    \"created_at\": 1737134934,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 217/270: training loss=0.1464187502861023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935932c62f8a365f64be\",\n",
      "    \"created_at\": 1737134936,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 218/270: training loss=0.2709529399871826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935a853dcb9e256b962a\",\n",
      "    \"created_at\": 1737134937,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 219/270: training loss=0.2246333807706833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c32c62f8a365f64c1\",\n",
      "    \"created_at\": 1737134938,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 220/270: training loss=0.15977168083190918\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c853dcb9e256b962d\",\n",
      "    \"created_at\": 1737134940,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 221/270: training loss=0.43252938985824585\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935e32c62f8a365f64c4\",\n",
      "    \"created_at\": 1737134941,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 222/270: training loss=0.18377262353897095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935f853dcb9e256b9630\",\n",
      "    \"created_at\": 1737134942,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 223/270: training loss=0.13245829939842224\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936132c62f8a365f64c7\",\n",
      "    \"created_at\": 1737134944,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 224/270: training loss=0.15940974652767181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9363853dcb9e256b9633\",\n",
      "    \"created_at\": 1737134946,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 225/270: training loss=0.22354091703891754, validation loss=0.9361454093765594, full validation loss=0.9361454093765594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9368853dcb9e256b9636\",\n",
      "    \"created_at\": 1737134950,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 226/270: training loss=0.06987695395946503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936932c62f8a365f64ca\",\n",
      "    \"created_at\": 1737134952,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 227/270: training loss=0.16204065084457397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936a853dcb9e256b9639\",\n",
      "    \"created_at\": 1737134953,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 228/270: training loss=0.10014106333255768\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936c32c62f8a365f64cd\",\n",
      "    \"created_at\": 1737134955,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 229/270: training loss=0.1414417028427124\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936d853dcb9e256b963c\",\n",
      "    \"created_at\": 1737134956,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 230/270: training loss=0.16190625727176666\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936e32c62f8a365f64d0\",\n",
      "    \"created_at\": 1737134957,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 231/270: training loss=0.07265762984752655\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936f853dcb9e256b963f\",\n",
      "    \"created_at\": 1737134958,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 232/270: training loss=0.12164939194917679\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937132c62f8a365f64d3\",\n",
      "    \"created_at\": 1737134960,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 233/270: training loss=0.19458816945552826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9372853dcb9e256b9642\",\n",
      "    \"created_at\": 1737134961,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 234/270: training loss=0.10454107075929642\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937332c62f8a365f64d6\",\n",
      "    \"created_at\": 1737134962,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 235/270: training loss=0.10439317673444748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9375853dcb9e256b9645\",\n",
      "    \"created_at\": 1737134964,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 236/270: training loss=0.11629471182823181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937632c62f8a365f64d9\",\n",
      "    \"created_at\": 1737134965,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 237/270: training loss=0.10698636621236801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9378853dcb9e256b9648\",\n",
      "    \"created_at\": 1737134966,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 238/270: training loss=0.08717890828847885\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937832c62f8a365f64dc\",\n",
      "    \"created_at\": 1737134968,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 239/270: training loss=0.08939964324235916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937a853dcb9e256b964b\",\n",
      "    \"created_at\": 1737134969,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 240/270: training loss=0.07499294728040695\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937b32c62f8a365f64df\",\n",
      "    \"created_at\": 1737134970,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 241/270: training loss=0.1073426753282547\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937d853dcb9e256b964e\",\n",
      "    \"created_at\": 1737134972,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 242/270: training loss=0.13548344373703003\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937e32c62f8a365f64e2\",\n",
      "    \"created_at\": 1737134973,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 243/270: training loss=0.07782375812530518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937f853dcb9e256b9651\",\n",
      "    \"created_at\": 1737134974,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 244/270: training loss=0.1626926064491272\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938132c62f8a365f64e5\",\n",
      "    \"created_at\": 1737134976,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 245/270: training loss=0.12877827882766724\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9382853dcb9e256b9654\",\n",
      "    \"created_at\": 1737134977,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 246/270: training loss=0.1313783973455429\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938432c62f8a365f64e8\",\n",
      "    \"created_at\": 1737134978,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 247/270: training loss=0.09170598536729813\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9384853dcb9e256b9657\",\n",
      "    \"created_at\": 1737134980,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 248/270: training loss=0.21569176018238068\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938632c62f8a365f64eb\",\n",
      "    \"created_at\": 1737134981,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 249/270: training loss=0.16949859261512756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9387853dcb9e256b965a\",\n",
      "    \"created_at\": 1737134982,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 250/270: training loss=0.09198608994483948\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938932c62f8a365f64ee\",\n",
      "    \"created_at\": 1737134984,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 251/270: training loss=0.1752678006887436\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938a853dcb9e256b965d\",\n",
      "    \"created_at\": 1737134985,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 252/270: training loss=0.2655774652957916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938b32c62f8a365f64f1\",\n",
      "    \"created_at\": 1737134986,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 253/270: training loss=0.11848416924476624\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938d853dcb9e256b9660\",\n",
      "    \"created_at\": 1737134988,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 254/270: training loss=0.17658597230911255\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938e32c62f8a365f64f4\",\n",
      "    \"created_at\": 1737134989,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 255/270: training loss=0.11616112291812897\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938f853dcb9e256b9663\",\n",
      "    \"created_at\": 1737134990,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 256/270: training loss=0.11873071640729904\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939032c62f8a365f64f7\",\n",
      "    \"created_at\": 1737134992,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 257/270: training loss=0.13619545102119446\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9392853dcb9e256b9666\",\n",
      "    \"created_at\": 1737134993,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 258/270: training loss=0.14970344305038452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939432c62f8a365f64fa\",\n",
      "    \"created_at\": 1737134994,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 259/270: training loss=0.1752220243215561\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9395853dcb9e256b9669\",\n",
      "    \"created_at\": 1737134996,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 260/270: training loss=0.10681001842021942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939632c62f8a365f64fd\",\n",
      "    \"created_at\": 1737134997,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 261/270: training loss=0.13466989994049072\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9397853dcb9e256b966c\",\n",
      "    \"created_at\": 1737134999,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 262/270: training loss=0.08956924825906754\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939932c62f8a365f6500\",\n",
      "    \"created_at\": 1737135000,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 263/270: training loss=0.13542675971984863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b853dcb9e256b966f\",\n",
      "    \"created_at\": 1737135001,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 264/270: training loss=0.1931263953447342\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b32c62f8a365f6503\",\n",
      "    \"created_at\": 1737135003,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 265/270: training loss=0.20059852302074432\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935332c62f8a365f64b8\",\n",
      "    \"created_at\": 1737134930,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 214/270: training loss=0.2851610481739044\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9355853dcb9e256b9624\",\n",
      "    \"created_at\": 1737134932,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 215/270: training loss=0.2181839793920517\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935632c62f8a365f64bb\",\n",
      "    \"created_at\": 1737134933,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 216/270: training loss=0.2576529383659363\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9357853dcb9e256b9627\",\n",
      "    \"created_at\": 1737134934,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 217/270: training loss=0.1464187502861023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935932c62f8a365f64be\",\n",
      "    \"created_at\": 1737134936,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 218/270: training loss=0.2709529399871826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935a853dcb9e256b962a\",\n",
      "    \"created_at\": 1737134937,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 219/270: training loss=0.2246333807706833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c32c62f8a365f64c1\",\n",
      "    \"created_at\": 1737134938,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 220/270: training loss=0.15977168083190918\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c853dcb9e256b962d\",\n",
      "    \"created_at\": 1737134940,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 221/270: training loss=0.43252938985824585\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935e32c62f8a365f64c4\",\n",
      "    \"created_at\": 1737134941,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 222/270: training loss=0.18377262353897095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935f853dcb9e256b9630\",\n",
      "    \"created_at\": 1737134942,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 223/270: training loss=0.13245829939842224\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936132c62f8a365f64c7\",\n",
      "    \"created_at\": 1737134944,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 224/270: training loss=0.15940974652767181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9363853dcb9e256b9633\",\n",
      "    \"created_at\": 1737134946,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 225/270: training loss=0.22354091703891754, validation loss=0.9361454093765594, full validation loss=0.9361454093765594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9368853dcb9e256b9636\",\n",
      "    \"created_at\": 1737134950,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 226/270: training loss=0.06987695395946503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936932c62f8a365f64ca\",\n",
      "    \"created_at\": 1737134952,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 227/270: training loss=0.16204065084457397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936a853dcb9e256b9639\",\n",
      "    \"created_at\": 1737134953,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 228/270: training loss=0.10014106333255768\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936c32c62f8a365f64cd\",\n",
      "    \"created_at\": 1737134955,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 229/270: training loss=0.1414417028427124\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936d853dcb9e256b963c\",\n",
      "    \"created_at\": 1737134956,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 230/270: training loss=0.16190625727176666\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936e32c62f8a365f64d0\",\n",
      "    \"created_at\": 1737134957,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 231/270: training loss=0.07265762984752655\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936f853dcb9e256b963f\",\n",
      "    \"created_at\": 1737134958,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 232/270: training loss=0.12164939194917679\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937132c62f8a365f64d3\",\n",
      "    \"created_at\": 1737134960,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 233/270: training loss=0.19458816945552826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9372853dcb9e256b9642\",\n",
      "    \"created_at\": 1737134961,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 234/270: training loss=0.10454107075929642\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937332c62f8a365f64d6\",\n",
      "    \"created_at\": 1737134962,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 235/270: training loss=0.10439317673444748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9375853dcb9e256b9645\",\n",
      "    \"created_at\": 1737134964,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 236/270: training loss=0.11629471182823181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937632c62f8a365f64d9\",\n",
      "    \"created_at\": 1737134965,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 237/270: training loss=0.10698636621236801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9378853dcb9e256b9648\",\n",
      "    \"created_at\": 1737134966,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 238/270: training loss=0.08717890828847885\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937832c62f8a365f64dc\",\n",
      "    \"created_at\": 1737134968,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 239/270: training loss=0.08939964324235916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937a853dcb9e256b964b\",\n",
      "    \"created_at\": 1737134969,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 240/270: training loss=0.07499294728040695\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937b32c62f8a365f64df\",\n",
      "    \"created_at\": 1737134970,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 241/270: training loss=0.1073426753282547\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937d853dcb9e256b964e\",\n",
      "    \"created_at\": 1737134972,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 242/270: training loss=0.13548344373703003\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937e32c62f8a365f64e2\",\n",
      "    \"created_at\": 1737134973,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 243/270: training loss=0.07782375812530518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937f853dcb9e256b9651\",\n",
      "    \"created_at\": 1737134974,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 244/270: training loss=0.1626926064491272\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938132c62f8a365f64e5\",\n",
      "    \"created_at\": 1737134976,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 245/270: training loss=0.12877827882766724\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9382853dcb9e256b9654\",\n",
      "    \"created_at\": 1737134977,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 246/270: training loss=0.1313783973455429\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938432c62f8a365f64e8\",\n",
      "    \"created_at\": 1737134978,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 247/270: training loss=0.09170598536729813\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9384853dcb9e256b9657\",\n",
      "    \"created_at\": 1737134980,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 248/270: training loss=0.21569176018238068\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938632c62f8a365f64eb\",\n",
      "    \"created_at\": 1737134981,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 249/270: training loss=0.16949859261512756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9387853dcb9e256b965a\",\n",
      "    \"created_at\": 1737134982,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 250/270: training loss=0.09198608994483948\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938932c62f8a365f64ee\",\n",
      "    \"created_at\": 1737134984,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 251/270: training loss=0.1752678006887436\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938a853dcb9e256b965d\",\n",
      "    \"created_at\": 1737134985,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 252/270: training loss=0.2655774652957916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938b32c62f8a365f64f1\",\n",
      "    \"created_at\": 1737134986,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 253/270: training loss=0.11848416924476624\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938d853dcb9e256b9660\",\n",
      "    \"created_at\": 1737134988,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 254/270: training loss=0.17658597230911255\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938e32c62f8a365f64f4\",\n",
      "    \"created_at\": 1737134989,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 255/270: training loss=0.11616112291812897\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938f853dcb9e256b9663\",\n",
      "    \"created_at\": 1737134990,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 256/270: training loss=0.11873071640729904\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939032c62f8a365f64f7\",\n",
      "    \"created_at\": 1737134992,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 257/270: training loss=0.13619545102119446\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9392853dcb9e256b9666\",\n",
      "    \"created_at\": 1737134993,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 258/270: training loss=0.14970344305038452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939432c62f8a365f64fa\",\n",
      "    \"created_at\": 1737134994,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 259/270: training loss=0.1752220243215561\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9395853dcb9e256b9669\",\n",
      "    \"created_at\": 1737134996,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 260/270: training loss=0.10681001842021942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939632c62f8a365f64fd\",\n",
      "    \"created_at\": 1737134997,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 261/270: training loss=0.13466989994049072\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9397853dcb9e256b966c\",\n",
      "    \"created_at\": 1737134999,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 262/270: training loss=0.08956924825906754\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939932c62f8a365f6500\",\n",
      "    \"created_at\": 1737135000,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 263/270: training loss=0.13542675971984863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b853dcb9e256b966f\",\n",
      "    \"created_at\": 1737135001,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 264/270: training loss=0.1931263953447342\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b32c62f8a365f6503\",\n",
      "    \"created_at\": 1737135003,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 265/270: training loss=0.20059852302074432\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939d853dcb9e256b9672\",\n",
      "    \"created_at\": 1737135004,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 266/270: training loss=0.12496009469032288\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939e32c62f8a365f6506\",\n",
      "    \"created_at\": 1737135005,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 267/270: training loss=0.2031680792570114\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a0853dcb9e256b9675\",\n",
      "    \"created_at\": 1737135006,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 268/270: training loss=0.1637314110994339\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a132c62f8a365f6509\",\n",
      "    \"created_at\": 1737135008,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 269/270: training loss=0.10068610310554504\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a3853dcb9e256b9678\",\n",
      "    \"created_at\": 1737135010,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 270/270: training loss=0.23182962834835052, validation loss=0.9913114444938248, full validation loss=0.9913114444938248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: running\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9216da5fe6a8dc4dfd54\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Created fine-tuning job: 678a9216da5fe6a8dc4dfd52\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935332c62f8a365f64b8\",\n",
      "    \"created_at\": 1737134930,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 214/270: training loss=0.2851610481739044\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9355853dcb9e256b9624\",\n",
      "    \"created_at\": 1737134932,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 215/270: training loss=0.2181839793920517\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935632c62f8a365f64bb\",\n",
      "    \"created_at\": 1737134933,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 216/270: training loss=0.2576529383659363\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9357853dcb9e256b9627\",\n",
      "    \"created_at\": 1737134934,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 217/270: training loss=0.1464187502861023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935932c62f8a365f64be\",\n",
      "    \"created_at\": 1737134936,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 218/270: training loss=0.2709529399871826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935a853dcb9e256b962a\",\n",
      "    \"created_at\": 1737134937,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 219/270: training loss=0.2246333807706833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c32c62f8a365f64c1\",\n",
      "    \"created_at\": 1737134938,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 220/270: training loss=0.15977168083190918\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c853dcb9e256b962d\",\n",
      "    \"created_at\": 1737134940,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 221/270: training loss=0.43252938985824585\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935e32c62f8a365f64c4\",\n",
      "    \"created_at\": 1737134941,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 222/270: training loss=0.18377262353897095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935f853dcb9e256b9630\",\n",
      "    \"created_at\": 1737134942,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 223/270: training loss=0.13245829939842224\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936132c62f8a365f64c7\",\n",
      "    \"created_at\": 1737134944,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 224/270: training loss=0.15940974652767181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9363853dcb9e256b9633\",\n",
      "    \"created_at\": 1737134946,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 225/270: training loss=0.22354091703891754, validation loss=0.9361454093765594, full validation loss=0.9361454093765594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9368853dcb9e256b9636\",\n",
      "    \"created_at\": 1737134950,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 226/270: training loss=0.06987695395946503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936932c62f8a365f64ca\",\n",
      "    \"created_at\": 1737134952,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 227/270: training loss=0.16204065084457397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936a853dcb9e256b9639\",\n",
      "    \"created_at\": 1737134953,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 228/270: training loss=0.10014106333255768\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936c32c62f8a365f64cd\",\n",
      "    \"created_at\": 1737134955,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 229/270: training loss=0.1414417028427124\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936d853dcb9e256b963c\",\n",
      "    \"created_at\": 1737134956,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 230/270: training loss=0.16190625727176666\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936e32c62f8a365f64d0\",\n",
      "    \"created_at\": 1737134957,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 231/270: training loss=0.07265762984752655\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936f853dcb9e256b963f\",\n",
      "    \"created_at\": 1737134958,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 232/270: training loss=0.12164939194917679\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937132c62f8a365f64d3\",\n",
      "    \"created_at\": 1737134960,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 233/270: training loss=0.19458816945552826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9372853dcb9e256b9642\",\n",
      "    \"created_at\": 1737134961,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 234/270: training loss=0.10454107075929642\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937332c62f8a365f64d6\",\n",
      "    \"created_at\": 1737134962,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 235/270: training loss=0.10439317673444748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9375853dcb9e256b9645\",\n",
      "    \"created_at\": 1737134964,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 236/270: training loss=0.11629471182823181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937632c62f8a365f64d9\",\n",
      "    \"created_at\": 1737134965,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 237/270: training loss=0.10698636621236801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9378853dcb9e256b9648\",\n",
      "    \"created_at\": 1737134966,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 238/270: training loss=0.08717890828847885\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937832c62f8a365f64dc\",\n",
      "    \"created_at\": 1737134968,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 239/270: training loss=0.08939964324235916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937a853dcb9e256b964b\",\n",
      "    \"created_at\": 1737134969,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 240/270: training loss=0.07499294728040695\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937b32c62f8a365f64df\",\n",
      "    \"created_at\": 1737134970,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 241/270: training loss=0.1073426753282547\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937d853dcb9e256b964e\",\n",
      "    \"created_at\": 1737134972,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 242/270: training loss=0.13548344373703003\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937e32c62f8a365f64e2\",\n",
      "    \"created_at\": 1737134973,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 243/270: training loss=0.07782375812530518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937f853dcb9e256b9651\",\n",
      "    \"created_at\": 1737134974,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 244/270: training loss=0.1626926064491272\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938132c62f8a365f64e5\",\n",
      "    \"created_at\": 1737134976,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 245/270: training loss=0.12877827882766724\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9382853dcb9e256b9654\",\n",
      "    \"created_at\": 1737134977,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 246/270: training loss=0.1313783973455429\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938432c62f8a365f64e8\",\n",
      "    \"created_at\": 1737134978,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 247/270: training loss=0.09170598536729813\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9384853dcb9e256b9657\",\n",
      "    \"created_at\": 1737134980,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 248/270: training loss=0.21569176018238068\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938632c62f8a365f64eb\",\n",
      "    \"created_at\": 1737134981,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 249/270: training loss=0.16949859261512756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9387853dcb9e256b965a\",\n",
      "    \"created_at\": 1737134982,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 250/270: training loss=0.09198608994483948\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938932c62f8a365f64ee\",\n",
      "    \"created_at\": 1737134984,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 251/270: training loss=0.1752678006887436\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938a853dcb9e256b965d\",\n",
      "    \"created_at\": 1737134985,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 252/270: training loss=0.2655774652957916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938b32c62f8a365f64f1\",\n",
      "    \"created_at\": 1737134986,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 253/270: training loss=0.11848416924476624\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938d853dcb9e256b9660\",\n",
      "    \"created_at\": 1737134988,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 254/270: training loss=0.17658597230911255\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938e32c62f8a365f64f4\",\n",
      "    \"created_at\": 1737134989,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 255/270: training loss=0.11616112291812897\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938f853dcb9e256b9663\",\n",
      "    \"created_at\": 1737134990,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 256/270: training loss=0.11873071640729904\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939032c62f8a365f64f7\",\n",
      "    \"created_at\": 1737134992,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 257/270: training loss=0.13619545102119446\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9392853dcb9e256b9666\",\n",
      "    \"created_at\": 1737134993,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 258/270: training loss=0.14970344305038452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939432c62f8a365f64fa\",\n",
      "    \"created_at\": 1737134994,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 259/270: training loss=0.1752220243215561\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9395853dcb9e256b9669\",\n",
      "    \"created_at\": 1737134996,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 260/270: training loss=0.10681001842021942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939632c62f8a365f64fd\",\n",
      "    \"created_at\": 1737134997,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 261/270: training loss=0.13466989994049072\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9397853dcb9e256b966c\",\n",
      "    \"created_at\": 1737134999,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 262/270: training loss=0.08956924825906754\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939932c62f8a365f6500\",\n",
      "    \"created_at\": 1737135000,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 263/270: training loss=0.13542675971984863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b853dcb9e256b966f\",\n",
      "    \"created_at\": 1737135001,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 264/270: training loss=0.1931263953447342\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b32c62f8a365f6503\",\n",
      "    \"created_at\": 1737135003,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 265/270: training loss=0.20059852302074432\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939d853dcb9e256b9672\",\n",
      "    \"created_at\": 1737135004,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 266/270: training loss=0.12496009469032288\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939e32c62f8a365f6506\",\n",
      "    \"created_at\": 1737135005,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 267/270: training loss=0.2031680792570114\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a0853dcb9e256b9675\",\n",
      "    \"created_at\": 1737135006,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 268/270: training loss=0.1637314110994339\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a132c62f8a365f6509\",\n",
      "    \"created_at\": 1737135008,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 269/270: training loss=0.10068610310554504\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a3853dcb9e256b9678\",\n",
      "    \"created_at\": 1737135010,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 270/270: training loss=0.23182962834835052, validation loss=0.9913114444938248, full validation loss=0.9913114444938248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Current status: succeeded\n",
      "\n",
      "Job events:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f637b\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Files validated, moving job to queued state\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a921632c62f8a365f6376\",\n",
      "    \"created_at\": 1737134614,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Validating training file: 678a92129865c142b39dab99\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9224853dcb9e256b94dd\",\n",
      "    \"created_at\": 1737134627,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 1/270: training loss=4.157246112823486\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922632c62f8a365f6380\",\n",
      "    \"created_at\": 1737134629,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 2/270: training loss=3.479300022125244\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9227853dcb9e256b94e0\",\n",
      "    \"created_at\": 1737134630,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 3/270: training loss=3.0355076789855957\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922932c62f8a365f6383\",\n",
      "    \"created_at\": 1737134631,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 4/270: training loss=3.117647409439087\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922a853dcb9e256b94e3\",\n",
      "    \"created_at\": 1737134633,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 5/270: training loss=2.943697452545166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922b32c62f8a365f6386\",\n",
      "    \"created_at\": 1737134634,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 6/270: training loss=2.67352294921875\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922d853dcb9e256b94e6\",\n",
      "    \"created_at\": 1737134636,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 7/270: training loss=2.190591335296631\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922e32c62f8a365f6389\",\n",
      "    \"created_at\": 1737134637,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 8/270: training loss=2.2816479206085205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a922f853dcb9e256b94e9\",\n",
      "    \"created_at\": 1737134638,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 9/270: training loss=1.6980383396148682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923032c62f8a365f638c\",\n",
      "    \"created_at\": 1737134640,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 10/270: training loss=1.8848466873168945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9232853dcb9e256b94ec\",\n",
      "    \"created_at\": 1737134641,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 11/270: training loss=1.8548614978790283\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923432c62f8a365f638f\",\n",
      "    \"created_at\": 1737134642,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 12/270: training loss=1.502110242843628\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9235853dcb9e256b94ef\",\n",
      "    \"created_at\": 1737134644,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 13/270: training loss=0.8761674165725708\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923632c62f8a365f6392\",\n",
      "    \"created_at\": 1737134645,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 14/270: training loss=0.8883800506591797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9237853dcb9e256b94f2\",\n",
      "    \"created_at\": 1737134646,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 15/270: training loss=1.1299223899841309\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923932c62f8a365f6395\",\n",
      "    \"created_at\": 1737134648,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 16/270: training loss=1.0204992294311523\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923a853dcb9e256b94f5\",\n",
      "    \"created_at\": 1737134649,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 17/270: training loss=0.9923850297927856\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923b32c62f8a365f6398\",\n",
      "    \"created_at\": 1737134650,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 18/270: training loss=0.883806049823761\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923c853dcb9e256b94f8\",\n",
      "    \"created_at\": 1737134652,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 19/270: training loss=1.062593936920166\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a923e32c62f8a365f639b\",\n",
      "    \"created_at\": 1737134653,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 20/270: training loss=0.8635369539260864\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9240853dcb9e256b94fb\",\n",
      "    \"created_at\": 1737134654,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 21/270: training loss=0.9645747542381287\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924132c62f8a365f639e\",\n",
      "    \"created_at\": 1737134656,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 22/270: training loss=1.068274736404419\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9242853dcb9e256b94fe\",\n",
      "    \"created_at\": 1737134657,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 23/270: training loss=0.7314077615737915\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924332c62f8a365f63a1\",\n",
      "    \"created_at\": 1737134658,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 24/270: training loss=0.5633673667907715\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9245853dcb9e256b9501\",\n",
      "    \"created_at\": 1737134660,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 25/270: training loss=0.7416453957557678\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924732c62f8a365f63a4\",\n",
      "    \"created_at\": 1737134661,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 26/270: training loss=0.6307487487792969\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9247853dcb9e256b9504\",\n",
      "    \"created_at\": 1737134662,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 27/270: training loss=0.6258577704429626\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924932c62f8a365f63a7\",\n",
      "    \"created_at\": 1737134664,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 28/270: training loss=0.5258796215057373\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924a853dcb9e256b9507\",\n",
      "    \"created_at\": 1737134665,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 29/270: training loss=0.6549425721168518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c32c62f8a365f63aa\",\n",
      "    \"created_at\": 1737134667,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 30/270: training loss=0.9605180621147156\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924c853dcb9e256b950a\",\n",
      "    \"created_at\": 1737134668,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 31/270: training loss=0.7077726125717163\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a924e32c62f8a365f63ad\",\n",
      "    \"created_at\": 1737134669,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 32/270: training loss=0.863519549369812\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9250853dcb9e256b950d\",\n",
      "    \"created_at\": 1737134670,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 33/270: training loss=0.9360374212265015\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925132c62f8a365f63b0\",\n",
      "    \"created_at\": 1737134672,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 34/270: training loss=1.0755412578582764\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9252853dcb9e256b9510\",\n",
      "    \"created_at\": 1737134673,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 35/270: training loss=1.5087764263153076\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925332c62f8a365f63b3\",\n",
      "    \"created_at\": 1737134674,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 36/270: training loss=0.7266027331352234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9255853dcb9e256b9513\",\n",
      "    \"created_at\": 1737134676,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 37/270: training loss=0.7520589232444763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925632c62f8a365f63b6\",\n",
      "    \"created_at\": 1737134677,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 38/270: training loss=0.922095775604248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9258853dcb9e256b9516\",\n",
      "    \"created_at\": 1737134678,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 39/270: training loss=0.562287449836731\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925932c62f8a365f63b9\",\n",
      "    \"created_at\": 1737134680,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 40/270: training loss=0.7168359160423279\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925a853dcb9e256b9519\",\n",
      "    \"created_at\": 1737134681,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 41/270: training loss=0.8490566611289978\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925c32c62f8a365f63bc\",\n",
      "    \"created_at\": 1737134682,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 42/270: training loss=0.9911202192306519\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925d853dcb9e256b951c\",\n",
      "    \"created_at\": 1737134684,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 43/270: training loss=0.8643282055854797\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a925e32c62f8a365f63bf\",\n",
      "    \"created_at\": 1737134685,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 44/270: training loss=1.0247966051101685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9260853dcb9e256b951f\",\n",
      "    \"created_at\": 1737134687,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 45/270: training loss=0.961582362651825, validation loss=0.7749444957740769, full validation loss=0.7749444957740769\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9265853dcb9e256b9522\",\n",
      "    \"created_at\": 1737134692,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 46/270: training loss=0.7744175791740417\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926732c62f8a365f63c2\",\n",
      "    \"created_at\": 1737134694,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 47/270: training loss=1.0077729225158691\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9268853dcb9e256b9525\",\n",
      "    \"created_at\": 1737134695,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 48/270: training loss=0.7447673082351685\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926932c62f8a365f63c5\",\n",
      "    \"created_at\": 1737134696,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 49/270: training loss=0.49264147877693176\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926a853dcb9e256b9528\",\n",
      "    \"created_at\": 1737134698,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 50/270: training loss=0.771428644657135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926c32c62f8a365f63c8\",\n",
      "    \"created_at\": 1737134699,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 51/270: training loss=0.801433265209198\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926d853dcb9e256b952b\",\n",
      "    \"created_at\": 1737134700,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 52/270: training loss=0.9977320432662964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a926f32c62f8a365f63cb\",\n",
      "    \"created_at\": 1737134702,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 53/270: training loss=0.3401244878768921\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9270853dcb9e256b952e\",\n",
      "    \"created_at\": 1737134703,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 54/270: training loss=0.733187735080719\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927132c62f8a365f63ce\",\n",
      "    \"created_at\": 1737134704,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 55/270: training loss=0.823998749256134\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9273853dcb9e256b9531\",\n",
      "    \"created_at\": 1737134706,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 56/270: training loss=0.5373837947845459\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927432c62f8a365f63d1\",\n",
      "    \"created_at\": 1737134707,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 57/270: training loss=0.7745412588119507\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9275853dcb9e256b9534\",\n",
      "    \"created_at\": 1737134708,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 58/270: training loss=0.8578311204910278\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927632c62f8a365f63d4\",\n",
      "    \"created_at\": 1737134709,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 59/270: training loss=0.5527213215827942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9278853dcb9e256b9537\",\n",
      "    \"created_at\": 1737134711,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 60/270: training loss=0.4340481460094452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927a32c62f8a365f63d7\",\n",
      "    \"created_at\": 1737134712,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 61/270: training loss=0.6392520666122437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927b853dcb9e256b953a\",\n",
      "    \"created_at\": 1737134714,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 62/270: training loss=0.6619412899017334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927c32c62f8a365f63da\",\n",
      "    \"created_at\": 1737134715,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 63/270: training loss=0.6005080938339233\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927d853dcb9e256b953d\",\n",
      "    \"created_at\": 1737134716,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 64/270: training loss=0.4383525848388672\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a927f32c62f8a365f63dd\",\n",
      "    \"created_at\": 1737134718,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 65/270: training loss=0.9250844717025757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9280853dcb9e256b9540\",\n",
      "    \"created_at\": 1737134719,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 66/270: training loss=0.9052207469940186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928132c62f8a365f63e0\",\n",
      "    \"created_at\": 1737134720,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 67/270: training loss=0.8101873993873596\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9282853dcb9e256b9543\",\n",
      "    \"created_at\": 1737134722,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 68/270: training loss=0.6942877173423767\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928432c62f8a365f63e3\",\n",
      "    \"created_at\": 1737134723,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 69/270: training loss=0.3953193724155426\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9285853dcb9e256b9546\",\n",
      "    \"created_at\": 1737134724,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 70/270: training loss=0.7341069579124451\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928632c62f8a365f63e6\",\n",
      "    \"created_at\": 1737134725,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 71/270: training loss=0.6561421751976013\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9288853dcb9e256b9549\",\n",
      "    \"created_at\": 1737134727,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 72/270: training loss=0.4864661395549774\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928932c62f8a365f63e9\",\n",
      "    \"created_at\": 1737134728,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 73/270: training loss=0.740798830986023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b853dcb9e256b954c\",\n",
      "    \"created_at\": 1737134729,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 74/270: training loss=0.8047145009040833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928b32c62f8a365f63ec\",\n",
      "    \"created_at\": 1737134731,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 75/270: training loss=0.7864190936088562\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928d853dcb9e256b954f\",\n",
      "    \"created_at\": 1737134732,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 76/270: training loss=0.7286906838417053\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a928e32c62f8a365f63ef\",\n",
      "    \"created_at\": 1737134733,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 77/270: training loss=0.6788330078125\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9290853dcb9e256b9552\",\n",
      "    \"created_at\": 1737134735,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 78/270: training loss=0.6764287948608398\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929132c62f8a365f63f2\",\n",
      "    \"created_at\": 1737134736,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 79/270: training loss=0.7135483622550964\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9292853dcb9e256b9555\",\n",
      "    \"created_at\": 1737134737,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 80/270: training loss=0.4955492317676544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929432c62f8a365f63f5\",\n",
      "    \"created_at\": 1737134739,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 81/270: training loss=0.948029100894928\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9295853dcb9e256b9558\",\n",
      "    \"created_at\": 1737134740,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 82/270: training loss=0.6388355493545532\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929732c62f8a365f63f8\",\n",
      "    \"created_at\": 1737134741,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 83/270: training loss=0.8285297751426697\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9298853dcb9e256b955b\",\n",
      "    \"created_at\": 1737134743,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 84/270: training loss=0.8430869579315186\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929932c62f8a365f63fb\",\n",
      "    \"created_at\": 1737134744,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 85/270: training loss=0.9519423842430115\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929a853dcb9e256b955e\",\n",
      "    \"created_at\": 1737134745,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 86/270: training loss=0.6201338768005371\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929c32c62f8a365f63fe\",\n",
      "    \"created_at\": 1737134747,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 87/270: training loss=0.8004821538925171\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929d853dcb9e256b9561\",\n",
      "    \"created_at\": 1737134748,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 88/270: training loss=0.9571759104728699\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a929e32c62f8a365f6401\",\n",
      "    \"created_at\": 1737134749,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 89/270: training loss=0.7956082224845886\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a1853dcb9e256b9564\",\n",
      "    \"created_at\": 1737134751,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 90/270: training loss=0.869749128818512, validation loss=0.7573470612485965, full validation loss=0.7573470612485965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a5853dcb9e256b9567\",\n",
      "    \"created_at\": 1737134756,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 91/270: training loss=0.7799859046936035\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a732c62f8a365f6404\",\n",
      "    \"created_at\": 1737134758,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 92/270: training loss=0.8143336772918701\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92a8853dcb9e256b956a\",\n",
      "    \"created_at\": 1737134759,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 93/270: training loss=0.5696067810058594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92aa32c62f8a365f6407\",\n",
      "    \"created_at\": 1737134760,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 94/270: training loss=0.38460487127304077\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ab853dcb9e256b956d\",\n",
      "    \"created_at\": 1737134762,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 95/270: training loss=0.5083650946617126\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ac32c62f8a365f640a\",\n",
      "    \"created_at\": 1737134763,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 96/270: training loss=0.5226320028305054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ae853dcb9e256b9570\",\n",
      "    \"created_at\": 1737134764,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 97/270: training loss=0.6523292660713196\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92af32c62f8a365f640d\",\n",
      "    \"created_at\": 1737134766,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 98/270: training loss=0.49743983149528503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b0853dcb9e256b9573\",\n",
      "    \"created_at\": 1737134767,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 99/270: training loss=0.5286422371864319\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b132c62f8a365f6410\",\n",
      "    \"created_at\": 1737134768,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 100/270: training loss=0.7625733613967896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b3853dcb9e256b9576\",\n",
      "    \"created_at\": 1737134770,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 101/270: training loss=0.28714171051979065\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b432c62f8a365f6413\",\n",
      "    \"created_at\": 1737134771,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 102/270: training loss=0.6132801175117493\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b5853dcb9e256b9579\",\n",
      "    \"created_at\": 1737134772,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 103/270: training loss=0.3796748220920563\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b732c62f8a365f6416\",\n",
      "    \"created_at\": 1737134774,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 104/270: training loss=0.5842981338500977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92b8853dcb9e256b957c\",\n",
      "    \"created_at\": 1737134775,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 105/270: training loss=0.4349120557308197\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba32c62f8a365f6419\",\n",
      "    \"created_at\": 1737134776,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 106/270: training loss=0.6901721954345703\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ba853dcb9e256b957f\",\n",
      "    \"created_at\": 1737134778,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 107/270: training loss=0.7403475642204285\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bc32c62f8a365f641c\",\n",
      "    \"created_at\": 1737134779,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 108/270: training loss=0.45812124013900757\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92be853dcb9e256b9582\",\n",
      "    \"created_at\": 1737134780,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 109/270: training loss=0.2545550465583801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92bf32c62f8a365f641f\",\n",
      "    \"created_at\": 1737134782,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 110/270: training loss=0.6085165739059448\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c0853dcb9e256b9585\",\n",
      "    \"created_at\": 1737134783,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 111/270: training loss=0.5281859636306763\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c132c62f8a365f6422\",\n",
      "    \"created_at\": 1737134784,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 112/270: training loss=0.63717120885849\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c3853dcb9e256b9588\",\n",
      "    \"created_at\": 1737134786,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 113/270: training loss=0.8405728936195374\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c432c62f8a365f6425\",\n",
      "    \"created_at\": 1737134787,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 114/270: training loss=0.3885701596736908\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c6853dcb9e256b958b\",\n",
      "    \"created_at\": 1737134788,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 115/270: training loss=0.5759639739990234\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c732c62f8a365f6428\",\n",
      "    \"created_at\": 1737134790,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 116/270: training loss=0.6229445934295654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92c8853dcb9e256b958e\",\n",
      "    \"created_at\": 1737134791,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 117/270: training loss=0.6059064269065857\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ca32c62f8a365f642b\",\n",
      "    \"created_at\": 1737134792,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 118/270: training loss=0.5155099630355835\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cb853dcb9e256b9591\",\n",
      "    \"created_at\": 1737134794,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 119/270: training loss=0.559758186340332\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cc32c62f8a365f642e\",\n",
      "    \"created_at\": 1737134795,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 120/270: training loss=0.45335423946380615\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cd853dcb9e256b9594\",\n",
      "    \"created_at\": 1737134797,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 121/270: training loss=0.5256717205047607\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92cf32c62f8a365f6431\",\n",
      "    \"created_at\": 1737134798,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 122/270: training loss=0.5633295774459839\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d1853dcb9e256b9597\",\n",
      "    \"created_at\": 1737134799,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 123/270: training loss=0.33911368250846863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d132c62f8a365f6434\",\n",
      "    \"created_at\": 1737134801,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 124/270: training loss=0.4621177017688751\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d3853dcb9e256b959a\",\n",
      "    \"created_at\": 1737134802,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 125/270: training loss=0.5287662744522095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d532c62f8a365f6437\",\n",
      "    \"created_at\": 1737134803,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 126/270: training loss=0.36446163058280945\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d6853dcb9e256b959d\",\n",
      "    \"created_at\": 1737134805,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 127/270: training loss=0.4942690134048462\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d732c62f8a365f643a\",\n",
      "    \"created_at\": 1737134806,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 128/270: training loss=0.6411488056182861\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92d8853dcb9e256b95a0\",\n",
      "    \"created_at\": 1737134807,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 129/270: training loss=0.5725587606430054\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92da32c62f8a365f643d\",\n",
      "    \"created_at\": 1737134809,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 130/270: training loss=0.7761797904968262\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92db853dcb9e256b95a3\",\n",
      "    \"created_at\": 1737134810,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 131/270: training loss=0.6525537371635437\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92dc32c62f8a365f6440\",\n",
      "    \"created_at\": 1737134811,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 132/270: training loss=0.5501445531845093\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92de853dcb9e256b95a6\",\n",
      "    \"created_at\": 1737134813,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 133/270: training loss=0.6427453756332397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92df32c62f8a365f6443\",\n",
      "    \"created_at\": 1737134814,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 134/270: training loss=0.3210255801677704\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e2853dcb9e256b95a9\",\n",
      "    \"created_at\": 1737134816,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 135/270: training loss=0.7394123673439026, validation loss=0.7760691994916418, full validation loss=0.7760691994916418\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e7853dcb9e256b95ac\",\n",
      "    \"created_at\": 1737134821,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 136/270: training loss=0.42393773794174194\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e832c62f8a365f6446\",\n",
      "    \"created_at\": 1737134823,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 137/270: training loss=0.27750614285469055\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92e9853dcb9e256b95af\",\n",
      "    \"created_at\": 1737134824,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 138/270: training loss=0.48560062050819397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ea32c62f8a365f6449\",\n",
      "    \"created_at\": 1737134825,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 139/270: training loss=0.4516056180000305\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ec853dcb9e256b95b2\",\n",
      "    \"created_at\": 1737134827,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 140/270: training loss=0.22567184269428253\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ed32c62f8a365f644c\",\n",
      "    \"created_at\": 1737134828,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 141/270: training loss=0.32141244411468506\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ef853dcb9e256b95b5\",\n",
      "    \"created_at\": 1737134829,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 142/270: training loss=0.2999648153781891\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f032c62f8a365f644f\",\n",
      "    \"created_at\": 1737134831,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 143/270: training loss=0.49772366881370544\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f1853dcb9e256b95b8\",\n",
      "    \"created_at\": 1737134832,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 144/270: training loss=0.2791365683078766\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f332c62f8a365f6452\",\n",
      "    \"created_at\": 1737134833,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 145/270: training loss=0.2979296147823334\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f4853dcb9e256b95bb\",\n",
      "    \"created_at\": 1737134835,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 146/270: training loss=0.4445890486240387\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f532c62f8a365f6455\",\n",
      "    \"created_at\": 1737134836,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 147/270: training loss=0.30539077520370483\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f6853dcb9e256b95be\",\n",
      "    \"created_at\": 1737134837,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 148/270: training loss=0.38680776953697205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92f832c62f8a365f6458\",\n",
      "    \"created_at\": 1737134839,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 149/270: training loss=0.2095722109079361\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fa853dcb9e256b95c1\",\n",
      "    \"created_at\": 1737134840,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 150/270: training loss=0.20651578903198242\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fb32c62f8a365f645b\",\n",
      "    \"created_at\": 1737134841,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 151/270: training loss=0.6303948760032654\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fc853dcb9e256b95c4\",\n",
      "    \"created_at\": 1737134843,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 152/270: training loss=0.2700573801994324\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92fd32c62f8a365f645e\",\n",
      "    \"created_at\": 1737134844,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 153/270: training loss=0.3759068548679352\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff853dcb9e256b95c7\",\n",
      "    \"created_at\": 1737134845,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 154/270: training loss=0.33040091395378113\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a92ff32c62f8a365f6461\",\n",
      "    \"created_at\": 1737134847,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 155/270: training loss=0.30677393078804016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9301853dcb9e256b95ca\",\n",
      "    \"created_at\": 1737134848,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 156/270: training loss=0.3379734754562378\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930232c62f8a365f6464\",\n",
      "    \"created_at\": 1737134849,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 157/270: training loss=0.3738037645816803\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9304853dcb9e256b95cd\",\n",
      "    \"created_at\": 1737134851,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 158/270: training loss=0.2922765910625458\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930532c62f8a365f6467\",\n",
      "    \"created_at\": 1737134852,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 159/270: training loss=0.41545379161834717\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9306853dcb9e256b95d0\",\n",
      "    \"created_at\": 1737134853,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 160/270: training loss=0.4290439188480377\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930832c62f8a365f646a\",\n",
      "    \"created_at\": 1737134855,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 161/270: training loss=0.4658515751361847\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9309853dcb9e256b95d3\",\n",
      "    \"created_at\": 1737134856,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 162/270: training loss=0.32352590560913086\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930a32c62f8a365f646d\",\n",
      "    \"created_at\": 1737134857,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 163/270: training loss=0.19933439791202545\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930b853dcb9e256b95d6\",\n",
      "    \"created_at\": 1737134859,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 164/270: training loss=0.25139543414115906\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930d32c62f8a365f6470\",\n",
      "    \"created_at\": 1737134860,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 165/270: training loss=0.3276967704296112\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a930f853dcb9e256b95d9\",\n",
      "    \"created_at\": 1737134861,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 166/270: training loss=0.31872284412384033\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931032c62f8a365f6473\",\n",
      "    \"created_at\": 1737134863,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 167/270: training loss=0.3165365159511566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9311853dcb9e256b95dc\",\n",
      "    \"created_at\": 1737134864,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 168/270: training loss=0.23913145065307617\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931232c62f8a365f6476\",\n",
      "    \"created_at\": 1737134865,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 169/270: training loss=0.29167768359184265\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9314853dcb9e256b95df\",\n",
      "    \"created_at\": 1737134867,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 170/270: training loss=0.6221866607666016\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931532c62f8a365f6479\",\n",
      "    \"created_at\": 1737134868,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 171/270: training loss=0.48333731293678284\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9316853dcb9e256b95e2\",\n",
      "    \"created_at\": 1737134869,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 172/270: training loss=0.13450482487678528\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931732c62f8a365f647c\",\n",
      "    \"created_at\": 1737134871,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 173/270: training loss=0.3056584596633911\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9319853dcb9e256b95e5\",\n",
      "    \"created_at\": 1737134872,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 174/270: training loss=0.37322017550468445\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931b32c62f8a365f647f\",\n",
      "    \"created_at\": 1737134873,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 175/270: training loss=0.2863910496234894\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931c853dcb9e256b95e8\",\n",
      "    \"created_at\": 1737134875,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 176/270: training loss=0.4114612638950348\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931d32c62f8a365f6482\",\n",
      "    \"created_at\": 1737134876,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 177/270: training loss=0.2955276072025299\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a931e853dcb9e256b95eb\",\n",
      "    \"created_at\": 1737134877,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 178/270: training loss=0.39674073457717896\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932032c62f8a365f6485\",\n",
      "    \"created_at\": 1737134879,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 179/270: training loss=0.47086191177368164\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9322853dcb9e256b95ee\",\n",
      "    \"created_at\": 1737134881,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 180/270: training loss=0.3887781500816345, validation loss=0.8875239023905315, full validation loss=0.8875239023905315\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9327853dcb9e256b95f1\",\n",
      "    \"created_at\": 1737134886,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 181/270: training loss=0.16340813040733337\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932832c62f8a365f6488\",\n",
      "    \"created_at\": 1737134888,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 182/270: training loss=0.2872186005115509\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932a853dcb9e256b95f4\",\n",
      "    \"created_at\": 1737134889,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 183/270: training loss=0.2042664736509323\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932b32c62f8a365f648b\",\n",
      "    \"created_at\": 1737134890,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 184/270: training loss=0.17257578670978546\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932d853dcb9e256b95f7\",\n",
      "    \"created_at\": 1737134892,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 185/270: training loss=0.22902894020080566\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932e32c62f8a365f648e\",\n",
      "    \"created_at\": 1737134893,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 186/270: training loss=0.17709097266197205\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a932f853dcb9e256b95fa\",\n",
      "    \"created_at\": 1737134894,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 187/270: training loss=0.1106746718287468\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933132c62f8a365f6491\",\n",
      "    \"created_at\": 1737134896,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 188/270: training loss=0.23616911470890045\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9332853dcb9e256b95fd\",\n",
      "    \"created_at\": 1737134897,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 189/270: training loss=0.24219271540641785\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933432c62f8a365f6494\",\n",
      "    \"created_at\": 1737134898,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 190/270: training loss=0.14246848225593567\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9334853dcb9e256b9600\",\n",
      "    \"created_at\": 1737134899,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 191/270: training loss=0.16367362439632416\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933632c62f8a365f6497\",\n",
      "    \"created_at\": 1737134901,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 192/270: training loss=0.15395870804786682\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9337853dcb9e256b9603\",\n",
      "    \"created_at\": 1737134902,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 193/270: training loss=0.3605942130088806\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933932c62f8a365f649a\",\n",
      "    \"created_at\": 1737134903,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 194/270: training loss=0.15013539791107178\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933a853dcb9e256b9606\",\n",
      "    \"created_at\": 1737134905,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 195/270: training loss=0.227956160902977\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933b32c62f8a365f649d\",\n",
      "    \"created_at\": 1737134906,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 196/270: training loss=0.22226417064666748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933d853dcb9e256b9609\",\n",
      "    \"created_at\": 1737134908,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 197/270: training loss=0.2799544036388397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933e32c62f8a365f64a0\",\n",
      "    \"created_at\": 1737134909,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 198/270: training loss=0.2308894246816635\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a933f853dcb9e256b960c\",\n",
      "    \"created_at\": 1737134910,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 199/270: training loss=0.13425782322883606\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934032c62f8a365f64a3\",\n",
      "    \"created_at\": 1737134912,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 200/270: training loss=0.14698900282382965\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9342853dcb9e256b960f\",\n",
      "    \"created_at\": 1737134913,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 201/270: training loss=0.2805449664592743\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934432c62f8a365f64a6\",\n",
      "    \"created_at\": 1737134914,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 202/270: training loss=0.2624305188655853\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9345853dcb9e256b9612\",\n",
      "    \"created_at\": 1737134916,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 203/270: training loss=0.11141934990882874\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934632c62f8a365f64a9\",\n",
      "    \"created_at\": 1737134917,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 204/270: training loss=0.13795310258865356\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9347853dcb9e256b9615\",\n",
      "    \"created_at\": 1737134918,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 205/270: training loss=0.2362653613090515\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934932c62f8a365f64ac\",\n",
      "    \"created_at\": 1737134920,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 206/270: training loss=0.26954129338264465\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934a853dcb9e256b9618\",\n",
      "    \"created_at\": 1737134921,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 207/270: training loss=0.2700280249118805\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c32c62f8a365f64af\",\n",
      "    \"created_at\": 1737134922,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 208/270: training loss=0.17933939397335052\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934c853dcb9e256b961b\",\n",
      "    \"created_at\": 1737134924,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 209/270: training loss=0.18747226893901825\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a934e32c62f8a365f64b2\",\n",
      "    \"created_at\": 1737134925,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 210/270: training loss=0.24863697588443756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9350853dcb9e256b961e\",\n",
      "    \"created_at\": 1737134926,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 211/270: training loss=0.35636594891548157\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935032c62f8a365f64b5\",\n",
      "    \"created_at\": 1737134928,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 212/270: training loss=0.17372293770313263\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9352853dcb9e256b9621\",\n",
      "    \"created_at\": 1737134929,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 213/270: training loss=0.24861016869544983\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935332c62f8a365f64b8\",\n",
      "    \"created_at\": 1737134930,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 214/270: training loss=0.2851610481739044\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9355853dcb9e256b9624\",\n",
      "    \"created_at\": 1737134932,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 215/270: training loss=0.2181839793920517\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935632c62f8a365f64bb\",\n",
      "    \"created_at\": 1737134933,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 216/270: training loss=0.2576529383659363\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9357853dcb9e256b9627\",\n",
      "    \"created_at\": 1737134934,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 217/270: training loss=0.1464187502861023\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935932c62f8a365f64be\",\n",
      "    \"created_at\": 1737134936,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 218/270: training loss=0.2709529399871826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935a853dcb9e256b962a\",\n",
      "    \"created_at\": 1737134937,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 219/270: training loss=0.2246333807706833\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c32c62f8a365f64c1\",\n",
      "    \"created_at\": 1737134938,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 220/270: training loss=0.15977168083190918\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935c853dcb9e256b962d\",\n",
      "    \"created_at\": 1737134940,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 221/270: training loss=0.43252938985824585\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935e32c62f8a365f64c4\",\n",
      "    \"created_at\": 1737134941,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 222/270: training loss=0.18377262353897095\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a935f853dcb9e256b9630\",\n",
      "    \"created_at\": 1737134942,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 223/270: training loss=0.13245829939842224\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936132c62f8a365f64c7\",\n",
      "    \"created_at\": 1737134944,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 224/270: training loss=0.15940974652767181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9363853dcb9e256b9633\",\n",
      "    \"created_at\": 1737134946,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 225/270: training loss=0.22354091703891754, validation loss=0.9361454093765594, full validation loss=0.9361454093765594\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9368853dcb9e256b9636\",\n",
      "    \"created_at\": 1737134950,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 226/270: training loss=0.06987695395946503\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936932c62f8a365f64ca\",\n",
      "    \"created_at\": 1737134952,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 227/270: training loss=0.16204065084457397\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936a853dcb9e256b9639\",\n",
      "    \"created_at\": 1737134953,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 228/270: training loss=0.10014106333255768\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936c32c62f8a365f64cd\",\n",
      "    \"created_at\": 1737134955,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 229/270: training loss=0.1414417028427124\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936d853dcb9e256b963c\",\n",
      "    \"created_at\": 1737134956,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 230/270: training loss=0.16190625727176666\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936e32c62f8a365f64d0\",\n",
      "    \"created_at\": 1737134957,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 231/270: training loss=0.07265762984752655\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a936f853dcb9e256b963f\",\n",
      "    \"created_at\": 1737134958,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 232/270: training loss=0.12164939194917679\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937132c62f8a365f64d3\",\n",
      "    \"created_at\": 1737134960,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 233/270: training loss=0.19458816945552826\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9372853dcb9e256b9642\",\n",
      "    \"created_at\": 1737134961,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 234/270: training loss=0.10454107075929642\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937332c62f8a365f64d6\",\n",
      "    \"created_at\": 1737134962,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 235/270: training loss=0.10439317673444748\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9375853dcb9e256b9645\",\n",
      "    \"created_at\": 1737134964,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 236/270: training loss=0.11629471182823181\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937632c62f8a365f64d9\",\n",
      "    \"created_at\": 1737134965,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 237/270: training loss=0.10698636621236801\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9378853dcb9e256b9648\",\n",
      "    \"created_at\": 1737134966,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 238/270: training loss=0.08717890828847885\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937832c62f8a365f64dc\",\n",
      "    \"created_at\": 1737134968,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 239/270: training loss=0.08939964324235916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937832c62f8a365f64dc\",\n",
      "    \"created_at\": 1737134968,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 239/270: training loss=0.08939964324235916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937a853dcb9e256b964b\",\n",
      "    \"created_at\": 1737134969,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 240/270: training loss=0.07499294728040695\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937b32c62f8a365f64df\",\n",
      "    \"created_at\": 1737134970,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 241/270: training loss=0.1073426753282547\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937d853dcb9e256b964e\",\n",
      "    \"created_at\": 1737134972,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 242/270: training loss=0.13548344373703003\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937e32c62f8a365f64e2\",\n",
      "    \"created_at\": 1737134973,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 243/270: training loss=0.07782375812530518\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a937f853dcb9e256b9651\",\n",
      "    \"created_at\": 1737134974,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 244/270: training loss=0.1626926064491272\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938132c62f8a365f64e5\",\n",
      "    \"created_at\": 1737134976,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 245/270: training loss=0.12877827882766724\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9382853dcb9e256b9654\",\n",
      "    \"created_at\": 1737134977,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 246/270: training loss=0.1313783973455429\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938432c62f8a365f64e8\",\n",
      "    \"created_at\": 1737134978,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 247/270: training loss=0.09170598536729813\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9384853dcb9e256b9657\",\n",
      "    \"created_at\": 1737134980,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 248/270: training loss=0.21569176018238068\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938632c62f8a365f64eb\",\n",
      "    \"created_at\": 1737134981,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 249/270: training loss=0.16949859261512756\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9387853dcb9e256b965a\",\n",
      "    \"created_at\": 1737134982,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 250/270: training loss=0.09198608994483948\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938932c62f8a365f64ee\",\n",
      "    \"created_at\": 1737134984,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 251/270: training loss=0.1752678006887436\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938a853dcb9e256b965d\",\n",
      "    \"created_at\": 1737134985,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 252/270: training loss=0.2655774652957916\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938b32c62f8a365f64f1\",\n",
      "    \"created_at\": 1737134986,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 253/270: training loss=0.11848416924476624\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938d853dcb9e256b9660\",\n",
      "    \"created_at\": 1737134988,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 254/270: training loss=0.17658597230911255\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938e32c62f8a365f64f4\",\n",
      "    \"created_at\": 1737134989,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 255/270: training loss=0.11616112291812897\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a938f853dcb9e256b9663\",\n",
      "    \"created_at\": 1737134990,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 256/270: training loss=0.11873071640729904\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939032c62f8a365f64f7\",\n",
      "    \"created_at\": 1737134992,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 257/270: training loss=0.13619545102119446\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9392853dcb9e256b9666\",\n",
      "    \"created_at\": 1737134993,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 258/270: training loss=0.14970344305038452\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939432c62f8a365f64fa\",\n",
      "    \"created_at\": 1737134994,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 259/270: training loss=0.1752220243215561\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9395853dcb9e256b9669\",\n",
      "    \"created_at\": 1737134996,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 260/270: training loss=0.10681001842021942\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939632c62f8a365f64fd\",\n",
      "    \"created_at\": 1737134997,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 261/270: training loss=0.13466989994049072\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a9397853dcb9e256b966c\",\n",
      "    \"created_at\": 1737134999,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 262/270: training loss=0.08956924825906754\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939932c62f8a365f6500\",\n",
      "    \"created_at\": 1737135000,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 263/270: training loss=0.13542675971984863\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b853dcb9e256b966f\",\n",
      "    \"created_at\": 1737135001,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 264/270: training loss=0.1931263953447342\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939b32c62f8a365f6503\",\n",
      "    \"created_at\": 1737135003,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 265/270: training loss=0.20059852302074432\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939d853dcb9e256b9672\",\n",
      "    \"created_at\": 1737135004,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 266/270: training loss=0.12496009469032288\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a939e32c62f8a365f6506\",\n",
      "    \"created_at\": 1737135005,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 267/270: training loss=0.2031680792570114\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a0853dcb9e256b9675\",\n",
      "    \"created_at\": 1737135006,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 268/270: training loss=0.1637314110994339\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a132c62f8a365f6509\",\n",
      "    \"created_at\": 1737135008,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 269/270: training loss=0.10068610310554504\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93a3853dcb9e256b9678\",\n",
      "    \"created_at\": 1737135010,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Step 270/270: training loss=0.23182962834835052, validation loss=0.9913114444938248, full validation loss=0.9913114444938248\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93bb32c62f8a365f6521\",\n",
      "    \"created_at\": 1737135035,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"The job has successfully completed\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93bb32c62f8a365f651f\",\n",
      "    \"created_at\": 1737135035,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"New fine-tuned model created\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93bb32c62f8a365f651d\",\n",
      "    \"created_at\": 1737135035,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Checkpoint created at step 90\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93bb32c62f8a365f651a\",\n",
      "    \"created_at\": 1737135035,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Checkpoint created at step 45\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93bb32c62f8a365f6517\",\n",
      "    \"created_at\": 1737135035,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Checkpoint created at step 225\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93bb32c62f8a365f6514\",\n",
      "    \"created_at\": 1737135035,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Checkpoint created at step 180\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"678a93bb32c62f8a365f6511\",\n",
      "    \"created_at\": 1737135035,\n",
      "    \"level\": \"info\",\n",
      "    \"message\": \"Checkpoint created at step 135\",\n",
      "    \"object\": \"fine_tuning.job.event\",\n",
      "    \"data\": {},\n",
      "    \"type\": \"message\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    job_status = client_stg.fine_tuning.jobs.retrieve(job.id)\n",
    "    status = job_status.status\n",
    "    print(f\"\\nCurrent status: {status}\")\n",
    "    \n",
    "    events = client_stg.fine_tuning.jobs.list_events(job.id)\n",
    "    events_list = [e.model_dump() for e in events]\n",
    "    events_list.sort(key=lambda x: x['created_at'])\n",
    "    print(\"\\nJob events:\")\n",
    "    print(json.dumps(events_list, indent=2))\n",
    "    \n",
    "    if status in [\"succeeded\", \"failed\", \"cancelled\"]:\n",
    "        break\n",
    "    \n",
    "    time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0c474a4-89ac-40c2-a1fe-a9d1e9267d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = job_status.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11dfc4b1-6b88-4379-a3b6-ecdd0026ba43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:klusterai:Meta-Llama-3.1-8B-Instruct-Turbo:personal::aacc8010'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_status.fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c41457-2f31-4e98-aa55-3a42a478b8e7",
   "metadata": {},
   "source": [
    "## Performing batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598eeeac-84dc-40eb-a64d-19ee80114bb8",
   "metadata": {},
   "source": [
    "With LLMs it is really important to write a good prompt, including the system prompt. Below you can see our example instruction for the LLM. This is something you should experiment with and see how it changes the performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bb7f503-dbe5-4983-99e7-0794a0835ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = '''\n",
    "    You are a helpful assistant specializing in determining the sentiment of financial news. \n",
    "    Analyze the following text regarding financial information and assign one of the following labels to indicate its sentiment: positive, negative, or neutral. \n",
    "    Provide your response as a single word without any punctuation.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce56296-b9a3-4676-9406-2d6f83420365",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = 'ft:klusterai:Meta-Llama-3.1-8B-Instruct-Turbo:personal::aacc8010'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f5a51c-fc39-4567-b85d-95a98d5f9c98",
   "metadata": {},
   "source": [
    "Now that the prompt is defined, it’s time to execute the code and run the classification task for each model. In this step, we loop through the list of models, creating the requests and batch jobs, monitoring progress and retrieving the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe1531a6-844e-4173-8122-a7bf871df06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ft_8b model job completed!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "        '8B':\"klusterai/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "        '70B':\"klusterai/Meta-Llama-3.3-70B-Instruct-Turbo\",\n",
    "        '405B':\"klusterai/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "        'ft_8B': fine_tuned_model\n",
    "        }\n",
    "\n",
    "# Process each model: create tasks, run jobs, and get results\n",
    "for name, model in models.items():\n",
    "    task_list = create_tasks(test_df, task_type='assistant', system_prompt=SYSTEM_PROMPT, model=model, content_column='text')\n",
    "    filename = save_tasks(task_list, task_type='assistant')\n",
    "    if name != 'ft_8B':\n",
    "        job = create_batch_job(filename, client=client_prod)\n",
    "        monitor_job_status(client=client_prod, job_id=job.id, task_type=f'{name} model')\n",
    "        test_df[f'answer_base_{name}'] = get_results(client=client_prod, job_id=job.id)\n",
    "    else:\n",
    "        job = create_batch_job(filename, client=client_stg)\n",
    "        monitor_job_status(client=client_stg, job_id=job.id, task_type=f'{name} model')\n",
    "        test_df[f'answer_{name}'] = get_results(client=client_stg, job_id=job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f539e6-4db6-49e3-af00-8bea1772fab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>answer_base_8B</th>\n",
       "      <th>answer_base_70B</th>\n",
       "      <th>answer_base_405B</th>\n",
       "      <th>answer_ft_8B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>positive</td>\n",
       "      <td>Under the terms of the off-take agreement with Talvivaara , Cameco will provide an up-front investment , to a maximum of $ 60 million , to cover the construction cost of the uranium extraction circuit .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>positive</td>\n",
       "      <td>The contracts have been signed to acquire uranium produced at the Sotkamo nickel-zinc mine in eastern Finland owned by Talvivaara .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>positive</td>\n",
       "      <td>These moderate but significant changes resulted in a significant 24-32 % reduction in the estimated CVD risk .</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                                                                                                                                                                                        text answer_base_8B answer_base_70B answer_base_405B answer_ft_8B\n",
       "461  positive  Under the terms of the off-take agreement with Talvivaara , Cameco will provide an up-front investment , to a maximum of $ 60 million , to cover the construction cost of the uranium extraction circuit .        neutral        positive         positive     positive\n",
       "455  positive                                                                         The contracts have been signed to acquire uranium produced at the Sotkamo nickel-zinc mine in eastern Finland owned by Talvivaara .        neutral        positive          Neutral     positive\n",
       "996  positive                                                                                              These moderate but significant changes resulted in a significant 24-32 % reduction in the estimated CVD risk .       positive        positive         positive     positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac1e99-edfe-4041-819e-1d366fbcfd68",
   "metadata": {},
   "source": [
    "## Analyzing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6654619-712c-4a08-b43b-6fdb6caaa871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lf/m3hzxk7j1ns1bt50twyl8hmr0000gn/T/ipykernel_74769/1163933663.py:17: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(y=list(accuracies.keys()), x=list(accuracies.values()), palette=\"viridis\", edgecolor='black', ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGGCAYAAABmPbWyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpOUlEQVR4nO3dd1QU19sH8O/C0pcOAiqIUkTsGDsWbNixazQqURONsZeoUSNYotGo0fiLMTY0IdFoNLF3RbEQQVECqCgoEhEVkd6Z9w9eRlaKA4KUfD/n7Dk7M3fuPHN3F569c+euTBAEAURERERULJWKDoCIiIioKmDSRERERCQBkyYiIiIiCZg0EREREUnApImIiIhIAiZNRERERBIwaSIiIiKSgEkTERERkQRMmoiIiIgkYNJE9B48fPgQMplMfFy4cKGiQyqSl5eXUqxvevr0Kdzd3VGzZk3I5XKlc7pw4YLSvg8fPnz/J/AW7u7uYnydO3eu6HCoiurcubP4PnJ3d6/ocCqlsv6sVYY2Z9JEVErR0dHw9PREx44dYWZmBnV1dZiZmaFFixaYPn06rl69WtEhljlBEDBkyBDs2rUL0dHRyM7OruiQlFTHhGjixIlKiahMJsP9+/crOiyqBN78giOTyTBv3rxCyy5evLhAWS8vr/cbcDUgr+gAiKqi77//HnPnzkV6errS+mfPnuHZs2e4ceMGNm7ciLi4OBgYGFRMkKXUsmVLrFmzptBtjx49wuXLl8Xlfv36oUOHDpDJZLCxsQEApX2NjIzKN9hSGDFiBBo1agQAsLS0rOBoipeWlobff/+9wPpdu3Zh2bJlFRARVXbbtm2Dh4cHtLS0xHUZGRnYunVrBUZVfTBpIiqhlStX4ssvvxSX5XI5+vbti+bNmwMAwsLCcOLECbx48aKiQnwnDRs2RMOGDQvdFhkZqbS8fv16MVnKM2fOnHKLrSz07NkTPXv2rOgwJDl48CBevXpVYP3u3buxdOnSQi+fVjWJiYnQ1dWt6DCqjZcvX+LXX3/F+PHjxXW///47YmJiKjCq6oOX54hKIDg4GIsXLxaXa9SogevXr+PgwYP46quv8NVXX+Hnn39GVFQUNm7cCDU1tbfWef/+fUyfPh3Ozs6wtLSEjo4ONDQ0ULt2bfTv3x9HjhwpdD8vLy907twZJiYmUFNTg6GhIerXr4/hw4fjhx9+UCr76NEjTJw4EXZ2dtDS0oKmpiZq1aqF9u3bY9asWQgNDVWqt7AxTTKZDJ06dVKq19bWVqnc28Y0CYKAvXv3om/fvrCwsIC6ujqMjY3RsmXLApcVvv76a7i5ucHOzg5GRkbiObZu3Rpff/01kpOTC8S8a9cucZ2Pj0+h48jedgnv33//xZw5c9CoUSMoFApoamrCxsYG48ePR1BQUIHyb9b35MkTjB8/HmZmZtDU1ETTpk3xxx9/FPIKvl3+yyf29vbi88jISJw7d67I/SIjIzFnzhw0bdoUenp60NTUhLW1NYYMGQJfX1+lslJfk7e9tkVd9nnz/ZSUlIQ5c+agTp06kMvlWLt2LQDgzJkzGDduHJo3bw5zc3NoaGhAW1sbdnZ2GDduXKFtLzX+ixcvisdXUVHBgwcPlOrIzs6GqampWGbjxo1Ftm1RHjx4gGHDhsHY2Bg6Ojro0KGD0muUlJQEfX198Rg7d+4sUMfAgQPF7YMGDSpxDCoquf/Sv//+e6X1ecuqqqpvreP69esYPXo0rK2toaGhAV1dXTRt2hRffvklnj9/Xug+Fy9eROfOnaGjowMjIyMMHTq0QBsXJjo6GvPnz0eTJk2gq6sLTU1N2NvbY9asWXj69Olb968QAhFJNnHiRAGA+Pjjjz8k7RcREaG03/nz58Vt+/btU9pW2MPT01OpviVLlhRb3szMTCwbExMjmJqaFlt+8+bNYvmdO3cqbcvzthgFQRDOnz+vtC4iIkLcPyUlRejZs+db68ijo6NTbNnGjRsLiYmJhcZc2COvzceOHSuu69Spk9IxfXx8BAMDgyLrUFNTE7y8vJT2yV9fvXr1BHNz8wL7yWQy4eTJk5LeK3mioqIEFRUVsY4dO3YIjRo1Epc/+uijQvc7dOiQoFAoijyHJUuWlOo1Ke61FQTl98fOnTvF9W++Nu3bty80ns8//7zYONTV1YXTp08rHbMk8Tdp0kRct2DBAqV6Tp06pXSc58+fv/X16dSpk7hP27ZtBSMjowLHVlVVVfobMXXqVKV98ktISBA0NTXF7YcOHXprDG+2rZubm/j84sWLgiAIgp+fn7huwIABRb5OgiAI69evV3rPvfkwMzMTbty4obTPkSNHBLlcXqCskZGR0LZt2yI/a76+voW2Wd6jRo0aws2bN4ts87Fjx761fcoDL88RlUD+b46GhoYYMGDAO9eppqYGJycntGjRAqamptDT00NSUhIuX76M8+fPAwCWLVuG8ePHo1atWgCAzZs3i/t37doVLi4uSE5OxuPHj+Hr64vU1FRx+x9//CF+QzQ0NMTHH38MY2NjPHnyBHfu3MGlS5ckxblmzRo8ePAAP/74o7juyy+/hKGhoaT9Z82ahRMnTojL1tbWcHNzg66uLm7fvo2jR48qlbeyskKjRo1gZWUFQ0NDCIKAiIgI7N27F8nJyQgKCsIPP/yAL774QhyHtXfvXvj7+wMA6tWrh88++0ys783LiG969eoVBg4cKF4O09HRwbhx46ClpYWff/4Z0dHRyMzMxIQJE+Dk5ITGjRsXqCM8PBza2tqYOnUqcnJy8OOPPyI7OxuCIGDt2rXo0aOHpLYCci/B5eTkAADU1dUxcOBAPHnyBIsWLQIAHDhwAD/88IPSpa2HDx9i+PDh4usvk8kwYMAANG3aFE+fPsWpU6eUjlHS16QsXL58Ge3bt0fXrl2RmJiI2rVrAwAUCgVcXFzQsGFDGBkZQUtLC7GxsTh69ChCQ0ORkZGBadOmISQkpFTxT5kyBZ9++imA3N6vZcuWiT0v+/btE8v169cPJiYmJTqnq1evombNmpg3bx4SExOxfft2pKenIzs7GxMmTEC3bt2gp6eHKVOmYNOmTRAEAVevXkVISAgcHR0BAIcPH0ZaWhoAwMzMDL169SpRDAAwadIkHD16FFlZWdi0aRM6dOgg9jLJZDJ8/vnn+PPPPwvd18fHB7NmzYIgCACAunXrYsSIEXj58iV27tyJjIwMxMTEYODAgbh79y40NDSQkpKCcePGISsrC0Du37Jx48bB0NAQv/zyS5E3w8THx2PgwIF4+fIlgNzP6rBhw6Cmpobff/8dd+/exbNnzzBo0CCEhoZCQ0OjxG1RbiokVSOqorS1tcVvOq1bt5a8X3E9TXnu3r0r7NmzR/j++++Fb7/9VlizZo3S8Xbv3i2W1dPTE9dHR0cXqOvBgwfi83Xr1ollJ06cWKBsUlKS8PTpU3G5qJ4mQXh7b0NR22NjY5W+jbZo0UJISkoqMuY8r169Eo4dOyb8+OOPwtq1a4U1a9YIHTt2FOvp0qWLUvniepHeVmb9+vVKsefvGXrw4IGgpqYmbpswYUKh9QEQjhw5Im6bMWOG0jfvkqhfv75SD4IgCEJYWJjSsbZt26a0z8yZM5W279mzR2l7VlaW8OjRI0EQSv6alFVP04gRI4ScnJxCzzk7O1vw8/MTvLy8hO+++05Ys2aNMGvWLKX9IyMjSxV/cnKyYGhoKJb/66+/BEEQhMzMTMHExKTQ1684+Xs91NTUlNrD29tbKebt27eL23r06CGunzlzprg+fy/RnDlzJMXwZtsGBQUJQ4YMEQAIcrlcuHHjhqChoSEAEHr37l3g71D+1yn/8XV1dZV623bv3q203y+//CIIgiD89ttvRb4fIyIilD4z+T9rGzZsUOpRevXqlbgtLi5OqcfN29u70DavqJ4mJk1EJVAeSVNERITQrl27Irup8x5ff/21uE+fPn3E9cbGxkLv3r2F6dOnCz/99JMQFhamdGw/Pz9BJpMJQO5lIicnJ+Gjjz4Sli1bJhw/flxIS0tTKl8eSdOxY8eU1v/+++/Ftld2drYwd+5cQV1dvdg2sbe3V9rvXZKmoUOHKv0hf5OLi4u43dHRsdD6atWqpbTP5s2bxW0ymazYc87vypUrSuf522+/idtatGghrnd2dlbar1WrVoXGWJiSviZllTS9ecklz6lTpwQrK6u3fg6uXLlSqvgFQRBmz54tlu/bt6943Lx1FhYWQlZW1lvrEQTlf+BvJu9ZWVlKCcNnn30mbjt8+LDSZzc9Pb3Apbl//vlHUgyFJU0+Pj5K78e85ydOnCg2acp/CX/YsGHFns/kyZMLtCcAISUlRWm//J+Z/J+1YcOGvfV1znt8/vnnhbZ5RSVNHAhOVAJ5l8cA4N69e2JX9rsYMGAArly58tZy+ac32Lx5M9q0aQMAiI2NxbFjx7BhwwZ8+umnsLOzw/Dhw8VLO61atcK6deugUCggCAJu3LiBX375BYsXL0avXr1Qu3btcp9sM68bPo+1tXWx5Tdu3Ig1a9YgIyOj2HJvTvnwLuLi4sTnNWrUKLDdzMys0LL51alTR2k5/2WFkrxX8g+k1tbWRr9+/cTlESNGiM99fX2V5mzK385va+OSviZvyn8+JXkd8g9oz/PkyRMMGDCgwN2Zhck7Vmni//zzz8XB0sePH8eTJ0+UpnQYPXq0pMHSb3rz/aKqqgpjY2NxOf/7pXfv3qhXrx6A3M/uwYMHcejQIfHSXKtWrYq8e1WKjh07okmTJgByb2oActv8bZeGi3v/F3U++e/s1NXVVZrmAFD+zOT35mtXnKIGn1cUJk1EJdClSxfxeVxcHP766693qu/u3bu4deuWuDxz5kzExMQgJycHgiDA1NS00P0sLS1x9epVhIWFwdvbGx4eHhg0aBDk8txhir///jt2794tlp8xYwZiYmJw9uxZbNy4EVOnToWdnR0A4MWLF+U+u+6b8zW9babwvXv3is8bNWqE27dvIyMjA4IgYO7cueURotLYrGfPnhXYnv+W7aLGcb15t2RppgR4c26mlJQUKBQK8a6qN88//x2D+dv5bW1c0tckL9nIk3/cXFhYWLH75qetrV1g3eHDh5GSkgIgt828vb2RkJAAQRAQHBxcaD0ljR/IHafTu3dvALl3zG3dulVpjE9pPwdvvl+ys7MRGxsrLuefq01FRQWTJ08Wl7dt26Y0purjjz8uVQz5TZkypcDy296Lxb3/3zyfvLL5zysxMVHpPQGgyGkO8h/LysoKa9asKfLx0UcfFRv3+8akiagEpkyZovTP47PPPsPt27cLlMvIyMCmTZuUbosvTP4/RADw0UcfoUaNGpDJZDh37lyR37Ju3bqFnJwc2NraYuTIkViyZAn++OMP8R8CAAQEBADI/RYfExMDbW1tdOnSBVOnTsXGjRuVEpNHjx4ViKUstW7dWkzogNxB5W/+gX306JH4PH8sLi4uaNy4MdTU1JCamopDhw4VeZz8SUveP2Gp2rVrJz5/9uyZ0qDp8PBwpVv185cta0XNzVSU3bt3i70+7du3F9eHhIQo/TMGgJycHDx+/BhAyV+TNydp9fPzU9r3XeR/vfX19TFixAhxgPuePXsK3aek8efJn1CsWrVKnE+tTZs2aNCgQaniv3TpklLStnfvXmRmZorLH3zwgVL5cePGicnj2bNncfz4cQCApqamUk9iaY0aNUpMTHR1dSUlg/nf02/OM/frr78qnU9e2TfP69dffxWfP3z4sMD0FoUdKyYmBn369MGcOXOUHjNmzICtrS2cnZ3fGvv7xLvniEqgUaNG8PT0FOdqevr0KVq0aIH+/fujWbNmAHIv2+X90XnbtyRbW1uoqKiIl9I++ugjjBgxAtHR0cX+xMHw4cMRHx8PFxcX1KpVC0ZGRnjw4AGOHTsmlsn7J3fx4kWMGjUKzs7OaNCgAWrWrIns7GwcOHBALKuurl6ga70sGRkZYfz48diyZQuA3LlgGjZsiAEDBkBPTw8hISH466+/xEsv9evXF3svtm7dCplMBj09Pezbtw93794t8jj5L58GBARg+vTpsLS0hLq6OqZNm1ZsjGPHjsWyZcvESweDBg1Sunsu75+GXC7H1KlTS98Yb5H/dVcoFOjTp0+BMtHR0bh48SKA13M2de3aFVOnTsXmzZvFSz3Dhw/Hnj170KRJE8TGxuLMmTMYNmwYPDw8SvyaODg4QKFQICkpCUDupa7jx4/j4cOHuH79+judc/369cXnr169Qq9evdChQwcEBAQUebdXSePP06NHD9jb2+PevXtiOwHv1sOTmZmJ9u3bY/To0eLdc3kMDAwwdOhQpfKGhoYYNWoUtm7dCkEQxMvQAwcOLJNfENDW1sbx48cRHR0NMzMzSZOHzpgxQ+w5T0hIQKtWrTBixAjExcVhx44dYjlLS0sMHjwYANC/f3+YmpqKX+4mT56M69evi3fP5U+08nN3d8fy5csRGxuL9PR0tGnTBsOGDUPdunWRmpqKkJAQXLhwAS9fvkRERITkO3TfiwoZSUVUxa1bt+6tg5QBCHFxcYIgFD8QfNKkSYXu27VrV6WBnPnn18l/Z1VhDyMjI3Gg7pt3uBT2mDVrllh3eQwEF4TcOXVcXV2LjSPPpUuXCp37RaFQCIMGDRKX69Spo3T8mzdvFjrPjI6OjlimuMHi586dE/T19YuMTy6XK90J9bb6imvLwrw5N9OkSZMKLffy5UvxrihAec6mks7TJPU1EQRBWLBgQaFl8t8RBhQ/ELwwGRkZQuPGjQut+827E/N/dkoaf578d28BELS0tJTu4JIi/6BkJycnQVdXt8CxVVRUhH379hW6/61btwqUP3XqVIliKGwgeHGKGwguCILw7bffFjtPk6mpqeDv76+0z19//SWoqqoWKKurqys4OTkV+dm4dOlSsfM0FfY3hAPBiaqomTNnIjw8HEuWLEH79u1hamoKNTU1mJqawsnJCVOnTsXly5clfWv8/vvvsXTpUtSpUwdqamqwsrLC3LlzcfjwYaXLD/mtXLkSkyZNQosWLWBubg41NTVoa2vDwcEBkydPRkBAgDgw1tnZGStWrECfPn1gY2MDXV1dyOVymJqaomvXrvDy8sK3335bhq1TOC0tLRw/fhy//fYbevfuDTMzM6ipqUFfXx/NmjXD7NmzxbLOzs44efIk2rVrBw0NDejr66N37964cuVKofMj5WnWrBl+++03ODk5QVNTs8Qxuri4ICgoCDNmzECDBg2gpaUFDQ0NWFtbw93dHf7+/hg3blypzl+Kn3/+Wex1BFDksQwNDeHm5iYuHzhwAAkJCQBy5xn6559/MGvWLDRq1Ag6OjpQV1dHrVq14Obmhq5du4r7leQ1AYDly5crvVdtbGywYsWKImetl0pNTQ3nzp2Du7s7jI2NoaGhgUaNGuGnn36Ch4dHkfuVNP487u7uUCgU4vLgwYOhr69f6vgbN26Mv//+GwMHDoShoSG0tLTQvn17nDx5EkOGDCl0nyZNmqBjx47ispWVldJrUxFmz56NK1euYOTIkWIPrba2Nho3box58+YhKCgILVq0UNqnf//+OHPmDDp27AgtLS0YGBjAzc0Nfn5+xX5WnZ2dERwcjAULFqB58+bQ1dWFuro6rKys0L59eyxevFjp71hlIROEMrj9h4iIqAqpX78+7t27ByB3XFH+mzzel4kTJ+Knn34CACxevBhLly597zFQyXBMExER/ScEBgbi+fPnOHz4sJgwNWjQAC4uLu8thocPHyI8PBzBwcHinY9qamr45JNP3lsMVHpMmoiI6D9hxowZ8PHxEZdlMhnWrVtXqqkhSsvLywuenp5K6+bMmQNLS8v3FgOVHsc0ERHRf4q2tjZatmyJv/76Cz179qyQGORyOWxtbbF69WosX768QmKgkuOYJiIiIiIJ2NNEREREJAGTJiIiIiIJmDRRtSUIgvj7VURERO+KSRNVW4mJidDX10diYmJFh0JERNUAkyYiIiIiCZg0EREREUnApImIiIhIAiZNRERERBIwaSIiIiKSgEkTERERkQT8wV6q9gIDA6FQKCo6DCKqZkxMTGBlZVXRYdB7xN+eo2orISEB+vr6FR0GEVVTmppauHv3DhOn/xD2NFG116hxX+gbWFR0GERUjSQlvsCtwIN48eIFk6b/ECZNVO3pKIyhr8+kiYiI3g0HghMRERFJwKSJiIiISAImTUREREQSMGkiIiIikoBJExEREZEETJqIiIiIJGDSRERERCQBkyYiIiIiCZg0EREREUnApImIiIhIAiZNRERERBIwaSIiIiKSgEkTERERkQRMmoiIiIgkYNJEREREJAGTJiIiIiIJmDQRERERScCkiYiIiEgCJk1EREREEjBpIiIiIpJAXtEBEBFR9aKpqY6hQ5zh3L4hatTQR3p6Ju7cjcK+fZcQHBIpuR5LS1MMGdweTZrUhaGBAunpmXj27BWu+d2F96/nC93H3MwQ/9s0GZqa6gCAO3ceY/bcbeL2GjUM0KvnB3B0tIK5mQH09LSRnJyGJ9Evcfy4Py74BEEQhHdrAKq2mDQREVGZ0dBQwzerPoatTU1xnbq6Glp+YA+n5rb4du0fuHjpn7fW065tA8ydMxjq6mriOjU1ORQKLWhqqheZNE2f5iYmTIVxqF8bw4Z2UFqnrq4GQ0NdNHSsgxZOtvh23YG3xkf/TUyaqjF3d3e8evUKf/75Z0WHUigvLy/MmDEDr169kryPTCbDwYMHMWDAgHKLi4hK78MRncSE6eKlf7D5x6Ooa22GrxaPhKamOqZ83g83bj5AUlJqkXWYmRlg9qxBUFdXQ1JSKn7aehzX/cOQmZmFWrVMUN++dqH79endEk2a1EVqajq0tDSKrP/uvSgcOnQNN24+QFZWNvr0bgX3sd0AAC4uTXHg4BWERzx9h1ag6opjmt7C3d0dMplMfBgbG6Nnz564fft2RYcGb29vNG3aFNra2rCwsMDHH3+M2NjYig6LiP7DundrLj7fsfMUEhJScOt2BC75BgMAdHQ00bFDo2Lr6N+vjdhbtH3nKZw9dwsJCSlITc3A/ftPcPTY3wX2MTXVh/vY7sjKysbPv5wrsu7r/vcwa/ZWXPAJQkJCClJS0rFv/yU8inwmlqld26RE50z/HUyaJOjZsyeio6MRHR2Ns2fPQi6Xo2/fvhUak6+vL8aMGYPx48cjODgY+/btw/Xr1zFhwoQKjYuI/rvMzQxhYKAAAKSkpOH583hx28OHMeLz+vUL7ynK07y5jfi8poURNv/vcxz8YxF2ec3G5M/6QKHQKrDPtKn9oa2tgX37LyE8vOheotTUjELXa6i/vvCSP26i/Jg0SaChoQFzc3OYm5ujWbNmmDdvHh4/foznz5+LZebNmwd7e3toa2ujXr16WLx4MTIzM8Xtt27dgouLC3R1daGnp4cWLVrA399f3H7lyhV07NgRWlpasLS0xLRp05CcnFxkTNeuXYO1tTWmTZuGunXrwtnZGRMnTlSqM4+npydq1KgBPT09TJw4ERkZhf/RAHIvmRkYGODIkSOoX78+tLW1MWTIECQnJ2PXrl2wtraGoaEhpk6diuzsbHG/uLg4jBkzBoaGhtDW1kavXr0QFhZWoG4rKytoa2tj4MCBhfaKHT58GC1atICmpibq1asHT09PZGVlFRkvEVUeBgY64vOk5DSlbSkp6eJzw3zlCmNWw0B8PnRIB1hZ1YC6uhpMjPXQp3crrP5mHDQ0Xo916tHDCU7NbRER8RR79l4scdz9+rWGubkRAOD+/ScIvfO4xHXQfwOTphJKSkqCt7c3bG1tYWxsLK7X1dWFl5cXQkJCsGHDBmzduhXr168Xt48aNQq1a9fG9evXERAQgPnz50NNLfdDHxQUBFdXVwwaNAi3b9/G3r174evriylTphQZR7t27RAVFYVjx45BEATExMRg//796NOnj1K5s2fPIjQ0FOfPn8dvv/2GgwcPwtPTs9hzTElJwcaNG7Fnzx6cOHECFy5cwKBBg3Ds2DEcO3YMP//8M3766Sfs379f3Mfd3R3+/v44dOgQrl69CkEQ0Lt3bzFx9PPzw7hx4zB58mQEBgbCxcUFy5cvVzruyZMn8dFHH2HatGkICQnBli1b4OXlhRUrVrzlVcmVnp6OhIQEpQcRVQwZZG+uEL3t3jRV1df/mh48iMYY97UY474W4eHRAIA6VjXEy4DGRroY/3EPZGVl47sNfyIrK7vQOovSr29rfDK+J4DcHqYVK/eWaH/6b2HSJMGRI0egUCigUCigq6uLQ4cOYe/evVBRed18ixYtQrt27WBtbY1+/fph9uzZ+P3338XtkZGR6NatGxwcHGBnZ4ehQ4eiadOmAIA1a9Zg5MiRmDFjBuzs7NCuXTts3LgRu3fvRlpaWoF4gNykydvbG8OHD4e6ujrMzc1hYGCA77//Xqmcuro6duzYgYYNG6JPnz5YunQpNm7ciJycnCLPNzMzE5s3b0bz5s3RsWNHDBkyBL6+vti+fTscHR3Rt29fuLi44Pz53LtXwsLCcOjQIWzbtg0dOnRA06ZN4e3tjX///VcchL5hwwa4urpi/vz5sLe3x7Rp0+Dq6qp03BUrVmD+/PkYO3Ys6tWrh+7du2PZsmXYsmWLpNdp5cqV0NfXFx+WlpaS9iOisvHq1evecR0dTaVtOtqa+colFVtPfEKK+PzM2UDExiYgNjYBp88EiuttbXMHmw8d2gEKhRau+d0BZDLY2tZErXxjkjQ11WFrWxP6+gV7tz52745JE3tDVVUFUVEvMG/BDjx79krSudJ/E5MmCVxcXBAYGIjAwED4+fmhR48e6NWrFx49eiSW2b9/P5ydnWFubg6FQoHFixcjMvL1fCSzZs3ChAkT0K1bN6xatQoPHjwQtwUEBMDLy0tMzBQKBVxdXZGTk4OIiIhCYwoJCcG0adPw1VdfISAgACdOnEBERAQmTZqkVC5voHietm3bIikpCY8fF939rK2tDRub12MKzMzMYG1tDYVCobTu2bPcgZOhoaGQy+Vo3bq1uN3Y2Bj169dHaGioWKZt27ZKx3lzOSAgAEuXLlVqh08++QTR0dFISUnB2yxYsADx8fHio7hzJKKy9zQmDnFxuQmRtrYGTE31xW3W1jXE53fv/ltsPWFhhW+X5eutSk/P7cXW0sodMO7cviE2rJ+IDesnYurn/fId1wwb1k9E506NxXVyuSrmzhmMIYOdAQDBIY8w54ttiIl5JeEs6b+MSZMEOjo6sLW1ha2tLVq1aoXt27cjOTkZW7duBZA7vmjEiBHo1asXjhw5gps3b2LhwoVKY4c8PDwQHByMPn364Ny5c3B0dMTBgwcBADk5OZg4caKYmAUGBuLWrVsICwtTSl7yW7lyJdq3b4+5c+eiSZMmcHV1xQ8//IAdO3YgOjr6reckk8mK3JZ32TB/2cLW5fVWFTURnCAI4nGkTBaXk5MDT09PpXYICgpCWFgYNDU137q/hoYG9PT0lB5E9H6dPnNTfD7u4x7Q09NG0yZ14dy+IQAgOTlNnKdp5owBOHrYE0cPe6JxI+vXdZx+XUe3rs1gbKwHY2M9dO3STFx/8+b9UsWnra2BZZ6j0blTEwDAJd9/sHDRbiQmFj0FAlEeztNUCjKZDCoqKkhNzf2QXb58GXXq1MHChQvFMvl7ofLY29vD3t4eM2fOxIcffoidO3di4MCBcHJyQnBwMGxtbSXHkJKSArlc+eVTVVUFoJyg3Lp1C6mpqdDSyr3b5Nq1a1AoFKhdu/i7V0rC0dERWVlZ8PPzQ7t27QAAsbGxuHfvHho0aCCWuXbtmtJ+by47OTnh7t27JWoHIqpc9uz1gZOTDWxtaqJjh0ZK0wtkZ+dg0/8OFztHEwD4/X0XZ87eRLeuzWFjY4HdXrOVtl+5EoJrfncBAOu/+xPrv/tTaXvjRtZYtfJjAAVnBG/XtgGaNKkrLndwboQOzspTIHj/eh6//nZB8jnTfweTJgnS09Px9GnuLaxxcXHYtGkTkpKS0K9fbhewra0tIiMjsWfPHrRs2RJHjx4Ve5EAIDU1FXPnzsWQIUNQt25dREVF4fr16xg8eDCA3Dvv2rRpg88//xyffPIJdHR0EBoaitOnTxcYo5SnX79++OSTT7B582a4uroiOjoaM2bMQKtWrVCz5uuZeDMyMjB+/HgsWrQIjx49wpIlSzBlyhSl8Vjvys7ODm5ubvjkk0+wZcsW6OrqYv78+ahVqxbc3NwAANOmTUO7du2wevVqDBgwAKdOncKJEyeU6vnqq6/Qt29fWFpaYujQoVBRUcHt27cRFBRUYNA4EVVO6emZmL9gJ4YMdkYH54aoUcNA/BmV3/ddQnBwwS+Uhfluw1+4e/dfuPZwQm3L3DFKUVEvcOZsII4eLThPE9H7wKRJghMnTsDCwgJA7l1yDg4O2LdvHzp37gwAcHNzw8yZMzFlyhSkp6ejT58+WLx4MTw8PADk9gDFxsZizJgxiImJgYmJCQYNGiTexdakSRP4+Phg4cKF6NChAwRBgI2NDYYPH15kTO7u7khMTMSmTZswe/ZsGBgYoEuXLvjmm2+UynXt2hV2dnbo2LEj0tPTMWLECDGusrRz505Mnz4dffv2RUZGBjp27Ihjx46Jl/XatGmDbdu2YcmSJfDw8EC3bt2waNEiLFu2TKzD1dUVR44cwdKlS7F69WqoqanBwcGBc08RVTGpqRn4+ZdzxU4yCRTeS5RHEAQcO34dx45fL/Hxg/55iD79lhS67czZQJw5G1jiOokAQCbwlwmpmkpISIC+vj5atx0LY+M6FR0OEVUj8fHRuHxpKwICAuDk5FTR4dB7woHgRERERBIwaSIiIiKSgEkTERERkQRMmoiIiIgkYNJEREREJAGTJiIiIiIJmDQRERERScCkiYiIiEgCJk1EREREEjBpIiIiIpKASRMRERGRBEyaiIiIiCRg0kREREQkAZMmIiIiIgmYNBERERFJwKSJiIiISAImTUREREQSMGkiIiIikoBJExEREZEETJqIiIiIJGDSRERERCQBkyYiIiIiCeQVHQBReUtOioVcrl7RYRBRNZKU+KKiQ6AKwKSJqr1/go5UdAhEVA1pamrBxMSkosOg94hJE1V7Pj4+UCgUFR0GEVUzJiYmsLKyqugw6D2SCYIgVHQQROUhISEB+vr6iI+Ph56eXkWHQ0REVRwHghMRERFJwKSJiIiISAImTUREREQSMGkiIiIikoBJExEREZEETJqIiIiIJGDSRERERCQBkyYiIiIiCZg0EREREUnApImIiIhIAiZNRERERBLwB3up2gsMDOQP9hIRVRMV+UPJ/MFeqrbyfrCXiIiqD00tLdy9c6dCEif2NFG1Z92tP3Rq1KzoMIiI6B2lvnyO8BN/4MWLF0yaiMqDpqEJdMyYNBER0bvhQHAiIiIiCZg0EREREUnApImIiIhIAiZNRERERBIwaSIiIiKSgEkTERERkQRMmoiIiIgkYNJEREREJAGTJiIiIiIJmDQRERERScCkiYiIiEgCJk1EREREEjBpIiIiIpKASRMRERGRBEyaiIiIiCRg0kREREQkAZMmIiIiIgmYNBERERFJwKSJiIiISAImTUREREQSyCs6ACIiIno3WupqGNO1Pbo2dYS5oT7SMjMR/CgKu85cRmDEY0l1tLavhxGdWsGhtgX0tLWQmZWNqNg4nL8dil/OX0V6ZpZYdvGI/ujbqmmRdQ1YthHRcfFK6/S0tfCRS1t0bGgPCyMD5AgCYhMSEfTwX6w5cBwp6RmlO/n3iEkTERFRFaaproYfp4yFQ20LcZ2GmhztGtihdX0bLPnlT5wODC62DpcmDvh6zBCoqMjEdXJVVdjVNINdTTM0rWuFaVu8Sx2jlakxNk0aBTNDfaX12qbGsDQ1xuZj55g0UcXq3LkzmjVrhu+++66iQymUh4cH/vzzTwQGBkoq//DhQ9StWxc3b95Es2bNyjU2IqKqYlz3DmLCdPpmML49cAK2NWvg23HDoaWhjvlDe8Pv3gMkpKQVWUf/1s3FhOno9Vv49sAJ2FjUwP8+Gw0NNTla16+HOjWM8ehZrNJ+T16+wsDl3xcbn4pMhpXuQ8SEaedpXxy8GoBXySmoYaCHtg42SM3IfJcmeG/+02Oa3N3dIZPJxIexsTF69uyJ27dvV6q48h4NGzZUKvfHH3/A0dERGhoacHR0xMGDBysoYiIiqij9WjUTn286chavklPgH/YQZ2+FAAAUWpro1qxhEXvnysnJEZ+fvhmMlPQMBD2MQuTz10mSpppaqeJzbmgPW4saAIDjAUH48fh5xLxKQHpmFh4/f4nfL11HYmrRCV1l8p9OmgCgZ8+eiI6ORnR0NM6ePQu5XI6+fftWaEwbNmwQY4qOjsbjx49hZGSEoUOHimWuXr2K4cOHY/To0bh16xZGjx6NYcOGwc/PrwIjJyKi96mmkQGMdHUAAMlp6XiabxzR/ehn4vNGdWoVW8/vvteRmZUNAOjevCG0NdTR2Lo2rEyNAQAxcfEIf/q8wH6mero4uXQ2Lq/5EoeXTIfHqAHiPnla29cVn2dlZWPrVHec+/oLnF4+B6s/HoZ65qYlPOuK859PmjQ0NGBubg5zc3M0a9YM8+bNw+PHj/H8+es3x7x582Bvbw9tbW3Uq1cPixcvRmbm667EW7duwcXFBbq6utDT00OLFi3g7+8vbr9y5Qo6duwILS0tWFpaYtq0aUhOTi4yJn19fTEmc3Nz+Pv7Iy4uDh9//LFY5rvvvkP37t2xYMECODg4YMGCBejatWuBS3FZWVmYMmUKDAwMYGxsjEWLFkEQhCKP7eHhgWbNmmHHjh2wsrKCQqHAZ599huzsbKxevRrm5uaoUaMGVqxYobRfZGQk3NzcoFAooKenh2HDhiEmJkapzKpVq2BmZgZdXV2MHz8eaWkFv1ns3LkTDRo0gKamJhwcHPDDDz8UGSsR0X9dXsIEoEBvTVJaeqHlCuN3NxxTt/yCl4nJ6NOyKc6vnIdt0z6Ghpoct8IjMf2nX5GZnV1gPzW5KgwU2pCrqqKGvh56tWgMr5njUb+WuVjGwshAfN6vdTM0qWsJHU0N6GlroVPj+tg27eMqkzj955Om/JKSkuDt7Q1bW1sYG7/OlHV1deHl5YWQkBBs2LABW7duxfr168Xto0aNQu3atXH9+nUEBARg/vz5UPv/bsygoCC4urpi0KBBuH37Nvbu3QtfX19MmTJFclzbt29Ht27dUKdOHXHd1atX0aNHD6Vyrq6uuHLlitK6Xbt2QS6Xw8/PDxs3bsT69euxbdu2Yo/34MEDHD9+HCdOnMBvv/2GHTt2oE+fPoiKioKPjw+++eYbLFq0CNeuXQMACIKAAQMG4OXLl/Dx8cHp06fx4MEDDB8+XKzz999/x5IlS7BixQr4+/vDwsKiQEK0detWLFy4ECtWrEBoaCi+/vprLF68GLt27ZLcVkRE/1WyYpaL+a4MAGhsXRvfuA8tNLkyM9RHs3pWSuv87z/Egl370W/pBnT44muMWbsVdx5HAwB0NDXwed8uYlm56utUIyU9A+O+244uC77Bkb8DxfKfuHZ66/lVBv/5geBHjhyBQqEAACQnJ8PCwgJHjhyBisrrF3nRokXic2tra8yePRt79+7FF198ASC3l2Xu3LlwcHAAANjZ2Ynl16xZg5EjR2LGjBnito0bN6JTp07YvHkzNDU1i40vOjoax48fx6+//qq0/unTpzAzM1NaZ2ZmhqdPnyqts7S0xPr16yGTyVC/fn0EBQVh/fr1+OSTT4o8Zk5ODnbs2AFdXV04OjrCxcUFd+/exbFjx6CiooL69evjm2++wYULF9CmTRucOXMGt2/fRkREBCwtLQEAP//8Mxo2bIjr16+jZcuW+O677zBu3DhMmDABALB8+XKcOXNGqbdp2bJlWLt2LQYNGgQAqFu3LkJCQrBlyxaMHTu22HYCgPT0dKSnv/5mlZCQ8NZ9iIiqspeJr69aKLSU/58o8v1/yV+uMHMG9oS+jjYA4KcTPvj1wlXoaWth6UcD0ayeFeYP7YNXySk4f/sOAOC4v/LY37v/PsXagyewdVruFZHG1pbitrikFPH53/fCERz5BACw5+Lf6Pv/47Ecar/umarM/vM9TS4uLggMDERgYCD8/PzQo0cP9OrVC48ePRLL7N+/H87OzjA3N4dCocDixYsRGRkpbp81axYmTJiAbt26YdWqVXjw4IG4LSAgAF5eXlAoFOLD1dUVOTk5iIiIeGt8Xl5eMDAwwIABAwpsk8mUv1cIglBgXZs2bZTWtW3bFmFhYcgupJs1j7W1NXR1dcVlMzMzODo6KiWSZmZmePYs93p5aGgoLC0txYQJABwdHWFgYIDQ0FCxTNu2bZWOk3/5+fPnePz4McaPH6/UVsuXL1dqz+KsXLkS+vr64iN/PERE1dGTl6/wMjEJQG6PjXm+W/pt/n/wNQAER/5bbD11810e2+d7HakZmYh5laA0VUEbBxsAgOzNLq1C5B8GEvr4yVvLp+WbA6oy+88nTTo6OrC1tYWtrS1atWqF7du3Izk5GVu3bgUAXLt2DSNGjECvXr1w5MgR3Lx5EwsXLkRGxuv5JDw8PBAcHIw+ffrg3LlzSney5eTkYOLEiWJiFhgYiFu3biEsLAw2NjbFxiYIAnbs2IHRo0dDXV1daZu5uXmBXqVnz54V6H0qDbU37pCQyWSFrsu726KwZK249YXJq2vr1q1KbfXPP/+IlwHfZsGCBYiPjxcfjx9Lm9CNiKgqO/z3LfH5lL5doa+jhQ/srNG1aQMAQFJqGs78f/KzeER/+K1bDL91i+Fk83rIx7NXrweQD3VuCS11NdQw0EP3fHfdJf7/lAXmBvrYMWMcerVoDBM9BdRUVVG/ljlmDXQVy9548Lrj4dTNYKT9/5QCLe3qwtGqJnQ01DGiYyuxjN9daV+OK9p//vLcm2QyGVRUVJCamgoAuHz5MurUqYOFCxeKZfL3QuWxt7eHvb09Zs6ciQ8//BA7d+7EwIED4eTkhODgYNja2pY4Fh8fH9y/fx/jx48vsK1t27Y4ffo0Zs6cKa47deoU2rVrp1TuzYTj2rVrsLOzg6qqaonjKYqjoyMiIyPx+PFjsXcnJCQE8fHxaNAg90PboEEDXLt2DWPGjCk0NjMzM9SqVQvh4eEYNWpUqeLQ0NCAhobGO5wJEVHVs+P0JbSuXw8OtS3QvXlDdG/+OtHJzsnBqn3Hip2jCQC2n/aFx0g3AMCnPTvh057KY4wSU9Pw57Ub4nJDq1poOKrwO/JeJiZj46EzSsvfHjiOL4f1g46mBnbOUP6f9vh5LHae8ZV2shXsP580paeniz02cXFx2LRpE5KSktCvXz8AgK2tLSIjI7Fnzx60bNkSR48eVZoPKTU1FXPnzsWQIUNQt25dREVF4fr16xg8eDCA3Dvv2rRpg88//xyffPIJdHR0EBoaitOnT+P774ufEGz79u1o3bo1GjVqVGDb9OnT0bFjR3zzzTdwc3PDX3/9hTNnzsDXV/mN9/jxY8yaNQsTJ07EjRs38P3332Pt2rXv1GZv6tatG5o0aYJRo0bhu+++Q1ZWFiZPnoxOnTrhgw8+EOMdO3YsPvjgAzg7O8Pb2xvBwcGoV6+eWI+HhwemTZsGPT099OrVC+np6eKdg7NmzSrTmImIqou0jEx89r/dGN2lHbo1dYS5kT7SMjLxz6N/sevsZQSGR761juP+t/EyIQlDnFvC0coCBjrayM4R8Dw+AQH3H2H3ucuIehEHAIhNTMLagyfQpr4N6pqZwEhXAciApy/jcfXOfew+d6XAGKrDf9/C07gEjO7SFo5WtaCppoanr+Jx8Z+72Hnat8rM0/SfT5pOnDgBC4vcmVR1dXXh4OCAffv2oXPnzgAANzc3zJw5E1OmTEF6ejr69OmDxYsXw8PDAwCgqqqK2NhYjBkzBjExMTAxMcGgQYPg6ekJAGjSpAl8fHywcOFCdOjQAYIgwMbGRunOssLEx8fjjz/+wIYNGwrd3q5dO+zZsweLFi3C4sWLYWNjg71796J169ZK5caMGYPU1FS0atUKqqqqmDp1Kj799NN3aLGCZDIZ/vzzT0ydOhUdO3aEiooKevbsqZQUDh8+HA8ePMC8efOQlpaGwYMH47PPPsPJkyfFMhMmTIC2tjbWrFmDL774Ajo6OmjcuLE4iJ6IiAqXkp6BLccvYMvxC8WWW7bnEJbtOVToNr974fC7F/7WY2VkZeP3S9fx+6XrJYrxelgEroe9fSxvZSYTipu0h6gKS0hIgL6+PhyGjoNebeuKDoeIiN5RcswTBP/6IwICAuDk5PTej/+fHwhOREREJAWTJiIiIiIJmDQRERERScCkiYiIiEgCJk1EREREEjBpIiIiIpKASRMRERGRBEyaiIiIiCRg0kREREQkAZMmIiIiIgmYNBERERFJUKIf7N29e3eJKh8zZkyJyhMRERFVViVKmtzd3SWXlclkTJqIiIio2ihR0hQREVFecRARERFVaiVKmurUqVNecRARERFVaiVKmgoTHx+Pa9eu4cWLF+jduzcMDQ3LIi4iIiKiSuWd7p5btmwZatasiV69emHMmDHi5buuXbti1apVZRIgERERUWVQ6qTphx9+gKenJ8aPH4+jR49CEARxW9++fXH06NEyCZCIiIioMij15blNmzZh1qxZWL16NbKzs5W22dnZISws7J2DIyIiIqosSt3TFB4eDldX10K36erq4tWrV6WtmoiIiKjSKXXSpK+vj5iYmEK3PXz4EDVq1Ch1UERERESVTamTpq5du2L16tVITk4W18lkMmRlZWHz5s1F9kIRERERVUWlHtO0dOlStGzZEo6Ojhg4cCBkMhk2bdqEmzdvIjIyEr///ntZxklERERUoUqdNNna2uLy5cuYNWsWfvjhBwiCgN27d8PFxQXe3t6wsrIqyziJSi0t7gVU1dQrOgwiInpHqS+fV+jxZUL+uQJKKT09HbGxsTA0NISWllZZxEX0zhISEqCvr1/RYRARURnS1NLC3Tt3KqRzpkySJqLKKC9p8vHxgUKhqOhwiIioDJiYmFTY1awSJU1Lly6VXrFMhsWLF5cqKKKykJc0xcfHQ09Pr6LDISKiKq5ESZOKivLNdjKZDG/uLpPJxOdvTnpJ9D4xaSIiorJUoikHcnJyxMfdu3dRt25drFixAhEREUhNTUVERASWLVuGunXr4s6dO+UVMxEREdF7V+oxTb1790abNm3w1VdfFdjm6emJa9eu4fjx4+8cIFFpsaeJiIjKUqknt7x06RLat29f6Lb27dvD19e31EERERERVTalTpo0NDTg7+9f6DZ/f3+oq3NeHCIiIqo+Sj255cCBA+Hp6QmFQoGRI0fC0NAQcXFx8Pb2xtKlSzFq1KiyjJOIiIioQpV6TFNiYiLc3Nxw4cIFyGQyyOVyZGVlQRAEdOzYEYcPH4aurm5Zx0skGcc0ERFRWXrnyS1PnDiB8+fP4+XLlzA2NoaLiwt69OihNPUAUUVg0kRERGWJM4JTtcWkiYiIylKpxzTlOXv2LM6ePYvY2FiYmJigW7ducHFxKYvYiIiIiCqNUvc0ZWRkYPDgwTh27BgEQRDHNMlkMvTp0wd//PEH1NTUyjpeIsnY00RERGWp1D1NS5cuxcmTJ7Fq1Sq4u7vD1NQUz58/x65du7Bw4UIsXboUy5YtK8tYiUolMDCQP9hLRFRNVJkf7M3PxsYGo0ePhoeHR4FtHh4e2L17N8LDw981PqJSy+tpIiKi6kNTSwt379ypkMSp1D1NUVFR6NChQ6HbOnTogJUrV5Y6KKKyZDWqN3SsLCo6DCIiekepT1/g4c6/8OLFi6qVNJmamiIoKAhdu3YtsC0oKAimpqbvFBhRWdE0M4Y2kyYiInpHpf4Zlf79++Orr77CgQMHlNb/9ddf8PDwgJub2zsHR0RERFRZlLqnacWKFbh8+TKGDh0KHR0dmJubIyYmBklJSWjcuDFWrFhRlnESERERVahSJ02Ghob4+++/4eXlhXPnzuHly5dwcnJC165dMWbMGGhoaJRlnEREREQV6p0mt9TQ0MDEiRMxceLEsoqHiIiIqFIqUdLUpUsXyWVlMhnOnj1b4oCIiIiIKqMSJU0XLlyAnp4eLC0tyyseIiIiokqpRElTvXr1EB4eDn19fYwbNw7Dhw+Hjo5OecVGREREVGmUaMqB+/fv4/z586hXrx6mTp0KCwsLTJgwAVeuXCmv+IiIiIgqhRLP09SpUyfs3r0b0dHRWL16NYKCguDs7IwGDRpgzZo1iImJKY84iYiIiCpUqSe31NPTw6RJk+Dn54fbt2+ja9eu+PLLLzF58uSyjI+IiIioUih10pQnNDQUu3btwv79+yEIAurXr18WcRERERFVKqWapykpKQm//fYbduzYAT8/P9jY2GDatGlwd3dHzZo1yzpGIiIiogpXoqTp4sWL2L59O/744w8IgoAhQ4Zg1apV6NSpU3nFR0RERFQplChp6ty5M/T09DBq1Ch8+OGH0NPTAwDcuHGj0PJOTk7vHiERERFRJVDiy3MJCQnYtm0btm3bVmQZQRAgk8mQnZ39TsERERERVRYlSpp27txZXnEQERERVWolSprGjh1bXnEQERERVWrvPOUAERER0X8BkyYiIiIiCZg0EREREUlQqsktiYiIqPLQkqvDvXkHdLNpBHOFPtKyMvHPsyjsvHERgU8fSaqjdW0bjGzSDg4mNaGvoYXMnGw8jn+JcxHB+PnWZaRnZYpll7gMRL/6RU8r1M97LaITX0kqCwA/+Z/DT/7nJcVZkZg0ERERVWGacjVsdRsPB9PXv8ihIVdDeyt7tKlti8Vn9+PUg6Bi6+hS1xGregyHiuz1BSi5qirsTcxhb2KO5hZ18PmRXeV2DskZ6eVWd1li0lSNWVtbY8aMGZgxY0ZFh1Iod3d3vHr1Cn/++aek8hcuXICLiwvi4uJgYGBQrrEREVUVE1p0FhOmU/eDsNr3COyMzbGu5yhoqanjy479cS3qPhLSU4usw61BCzFhOnL3Jlb7HoGtkRk29/sYGnI1tK5tizoGJnj06oXSfk8S49Dfe12x8XmePwjP8weV1umqa+Lo6DnQVtNAelYmjofdKs2pv3fVdkyTu7s7ZDKZ+DA2NkbPnj1x+/btig5NdPnyZcjlcjRr1qzAtj/++AOOjo7Q0NCAo6MjDh5UfsN5eHgonZ9MJoO5ufl7ipyIiCqL/g6vL31tvHYSr9JScP3fcJx+8A8AQKGhie42jYqtI0cQxOen7gchJTMDt2MeIzI+VlyvKVcrs5gHObaEtpoGAOB42C28TE0us7rLU7VNmgCgZ8+eiI6ORnR0NM6ePQu5XI6+fftWdFgAgPj4eIwZMwZdu3YtsO3q1asYPnw4Ro8ejVu3bmH06NEYNmwY/Pz8lMo1bNhQPL/o6GgEBRXf/UpERNVLLV1DGGkpAABJGWl4mhQvbnvwMkZ83tjMsth69gZdQ2Z2FgCgh21jaKupo4mZJaz0jQEAT5PiEf7yWYH9TLV1cWbsfFz7xAPHRs/F0i5DUEffpNhjqaqoYFij1gCAHCEH3revSDjTyqFaJ00aGhowNzeHubk5mjVrhnnz5uHx48d4/vy5WGbevHmwt7eHtrY26tWrh8WLFyMz8/Vgt1u3bsHFxQW6urrQ09NDixYt4O/vL26/cuUKOnbsCC0tLVhaWmLatGlITn57xjxx4kSMHDkSbdu2LbDtu+++Q/fu3bFgwQI4ODhgwYIF6Nq1K7777julcnK5XDw/c3NzmJqaFqgrMTERI0eOhEKhQM2aNfH9998XG5e7uzsGDBiAr7/+GmZmZjAwMICnpyeysrIwd+5cGBkZoXbt2tixY4fSfkFBQejSpQu0tLRgbGyMTz/9FElJSeL27OxszJo1CwYGBjA2NsYXX3wBId83GyD353dWr16NevXqQUtLC02bNsX+/fvf1pRERP9ZRtoK8XlSeprStqSM18t5iVVRrkXdx+dHduFlahL61m+Oi+MXY8fAT6EhV0Ng9CNMPboLmTkFfxpNTVUOAy0dyFVVUUNHD73tm2L34Emob2JR5LFcbRrDTKEPALgSGYaIuOdFlq1sqnXSlF9SUhK8vb1ha2sLY2Njcb2uri68vLwQEhKCDRs2YOvWrVi/fr24fdSoUahduzauX7+OgIAAzJ8/H2pquV2UQUFBcHV1xaBBg3D79m3s3bsXvr6+mDJlSrGx7Ny5Ew8ePMCSJUsK3X716lX06NFDaZ2rqyuuXFHOxsPCwlCzZk3UrVsXI0aMQHh4eIG61qxZgyZNmuDGjRtYsGABZs6cidOnTxcb37lz5/DkyRNcvHgR69atg4eHB/r27QtDQ0P4+flh0qRJmDRpEh4/fgwASElJQc+ePWFoaIjr169j3759OHPmjFI7rF27Fjt27MD27dvh6+uLly9fFrjkuGjRIuzcuRObN29GcHAwZs6ciY8++gg+Pj7FxpsnPT0dCQkJSg8iov8MmezNFeIzAQKK08TMEqtdPyw0uTJX6MPJwlppnf+/EZh3ag/6/LwG7bZ6YtT+HxD6/F8AgI66Bqa27lGgnjwjm7QTn/9y63KxcVU21Xog+JEjR6BQ5L4BkpOTYWFhgSNHjkBF5XWuuGjRIvG5tbU1Zs+ejb179+KLL74AAERGRmLu3LlwcHAAANjZ2Ynl16xZg5EjR4oDre3s7LBx40Z06tQJmzdvhqamZoGYwsLCMH/+fFy6dAlyeeHN//TpU5iZmSmtMzMzw9OnT8Xl1q1bY/fu3bC3t0dMTAyWL1+Odu3aITg4WCkpbN++PebPnw8AsLe3x+XLl7F+/Xp07969yHYzMjLCxo0boaKigvr162P16tVISUnBl19+CQBYsGABVq1ahcuXL2PEiBHw9vZGamoqdu/eDR0dHQDApk2b0K9fP3zzzTcwMzPDd999hwULFmDw4MEAgB9//BEnT54Uj5mcnIx169bh3LlzYu9bvXr14Ovriy1btqBTp05Fxptn5cqV8PT0fGs5IqLq4mXK6x59XXXl/zkKdY3X5VKTUJy5zn1goKkNANhy/Rx+uXUZeppaWN51CJpbWGNBx/6IS03GuYgQAMDRe4FK+999EY1vLx/D9gGfAACamBd+OfCDmnXFQet3nj+B/5MICWdZeVTrniYXFxcEBgYiMDAQfn5+6NGjB3r16oVHj17PWbF//344OzvD3NwcCoUCixcvRmRkpLh91qxZmDBhArp164ZVq1bhwYMH4raAgAB4eXlBoVCID1dXV+Tk5CAiouAbITs7GyNHjoSnpyfs7e2LjV32xjcGQRCU1vXq1QuDBw9G48aN0a1bNxw9ehQAsGuX8i2hb17+a9u2LUJDQ4s9dsOGDZUSSzMzMzRu3FhcVlVVhbGxMZ49y72+HRoaiqZNm4oJE5CbrOXk5ODu3buIj49HdHS0UixyuRwffPCBuBwSEoK0tDR0795dqT13796t1ObFWbBgAeLj48VHXk8YEVF19W9iHGL/P3HSUdeA+f9f9gIAW+PXX77/iYkqtp56hjXE57//cw2pWRmISYrH6fv/iOvbWuV2GsjwZo9WQTlC4T1bo5q2F5//crtq9TIB1Txp0tHRga2tLWxtbdGqVSts374dycnJ2Lp1KwDg2rVrGDFiBHr16oUjR47g5s2bWLhwITIyMsQ6PDw8EBwcjD59+uDcuXNKd7Ll5ORg4sSJYmIWGBiIW7duISwsDDY2NgXiSUxMhL+/P6ZMmQK5XA65XI6lS5fi1q1bkMvlOHfuHADA3NxcqVcJAJ49e1ag9+nNc23cuDHCwsLe2i5vJmRvyrv8mL98YetycnIAFEzoSnKsPHl1HT16VKk9Q0JCJI9r0tDQgJ6entKDiKi6O3Tnhvh8WhtX6Gtqo2WteuhWL/eOuaT0NPFOuiUuA+E/aRn8Jy1Di5rW4n4xya+HMwxr1AZacnWY6eihu+3ru+4S/3/KAnNdfewaNBG97ZrCRFsXaiqqqG9igdnteotlbzx5WCDOOvomaP//idfTpHgxpqqkWl+ee5NMJoOKigpSU3Nf+MuXL6NOnTpYuHChWCZ/L1Qee3t72NvbY+bMmfjwww+xc+dODBw4EE5OTggODoatra2k4+vp6RW4w+2HH37AuXPnsH//ftStWxdAbm/Q6dOnMXPmTLHcqVOn0K5dOxQlPT0doaGh6NChg9L6a9euFVjOu9RYVhwdHbFr1y4kJyeLvU2XL1+GiooK7O3toa+vDwsLC1y7dg0dO3YEAGRlZSEgIABOTk5iHRoaGoiMjJR0KY6IiHJtv3EBbS1t4WBaEz1sG6OH7esrA9k5Ofj64qFi52gCgO0BF+DZJXf4xMSWXTCxZRel7YnpqTgQ8vomqIY1amNp1yGF1vUyNQkbrp4ssH5U03biXFB7gq4i+/+/LFcl1TppSk9PF3ts4uLisGnTJiQlJaFfv34AAFtbW0RGRmLPnj1o2bIljh49qjQ4OTU1FXPnzsWQIUNQt25dREVF4fr16+K4nHnz5qFNmzb4/PPP8cknn0BHRwehoaE4ffp0oXepqaiooFEj5bkyatSoAU1NTaX106dPR8eOHfHNN9/Azc0Nf/31F86cOQNfX1+xzJw5c9CvXz9YWVnh2bNnWL58ORISEjB27Fil+i9fvozVq1djwIABOH36NPbt2ydeyisro0aNwpIlSzB27Fh4eHjg+fPnmDp1KkaPHi32jk2fPh2rVq2CnZ0dGjRogHXr1uHVq1diHbq6upgzZw5mzpyJnJwcODs7IyEhAVeuXIFCoShwXkRElCstKxOfHtqOsc1yf0bFQtcAaVmZCIp5DK+bF3Ez+u0/o3L0XiBepCRieKM2cDStBQNNbWQLOXienAj/J+HwunkJUQkvAQCxKUlY43sUbS1tUdewBoy1dACZDE8TX+HK4zDsunkJsW+ModLX1EZvu6YAcu/qOxjqXyCGqqBaJ00nTpyAhUXubY+6urpwcHDAvn370LlzZwCAm5sbZs6ciSlTpiA9PR19+vTB4sWL4eHhASB37E5sbCzGjBmDmJgYmJiYYNCgQeJg4yZNmsDHxwcLFy5Ehw4dIAgCbGxsMHz48HeKu127dtizZw8WLVqExYsXw8bGBnv37kXr1q3FMlFRUfjwww/x4sULmJqaok2bNrh27Rrq1KmjVNfs2bMREBAAT09P6OrqYu3atXB1dX2n+N6kra2NkydPYvr06WjZsiW0tbUxePBgrFv3epbY2bNnIzo6Gu7u7lBRUcG4ceMwcOBAxMe/nlNk2bJlqFGjBlauXInw8HAYGBjAyclJHIBORESFS8nMwObrZ7H5+tliyxU2O3cev6gH8It6+xjSjOws7P3nGvb+c+2tZfPEp6XAefsyyeUrK5nw5mQ5RNVEQkIC9PX1YT9rNHTt6rx9ByIiqtRSIqMRunK70vCO96laDwQnIiIiKitMmoiIiIgkYNJEREREJAGTJiIiIiIJmDQRERERScCkiYiIiEgCJk1EREREEjBpIiIiIpKASRMRERGRBEyaiIiIiCRg0kREREQkAZMmIiIiIgmYNBERERFJwKSJiIiISAImTUREREQSMGkiIiIikoBJExEREZEETJqIiIiIJGDSRERERCQBkyYiIiIiCZg0EREREUnApImIiIhIAiZNRERERBLIKzoAovKWFhMLVQ31ig6DiIjeUerTFxV6fCZNVO1Feh+r6BCIiKiMaGppwcTEpEKOzaSJqj0fHx8oFIqKDoOIiMqAiYkJrKysKuTYMkEQhAo5MlE5S0hIgL6+PuLj46Gnp1fR4RARURXHgeBEREREEjBpIiIiIpKASRMRERGRBEyaiIiIiCRg0kREREQkAZMmIiIiIgmYNBERERFJwKSJiIiISAImTUREREQSMGkiIiIikoBJExEREZEE/MFeqvYCAwP5g71ERJVcRf4Qr1T8wV6qtvJ+sJeIiCo/LW0t3Am9U6kTJ/Y0UbXXb247WNgbV3QYRERUhBeP4nFg+UW8ePGCSRNRRTK21ENNe5OKDoOIiKo4DgQnIiIikoBJExEREZEETJqIiIiIJGDSRERERCQBkyYiIiIiCZg0EREREUnApImIiIhIAiZNRERERBIwaSIiIiKSgEkTERERkQRMmoiIiIgkYNJEREREJAGTJiIiIiIJmDQRERERScCkiYiIiEgCJk1EREREEjBpIiIiIpKASRMRERGRBEyaiIiIiCSQV3QAREREVDQ1FQ04W/WGo0lLGGgaIzM7HVGJ4fCNPIrIhDBJddQzbIg2tbrDQlEHWnIdZAvZeJn6DKEv/HEl6iSycjLEsq1qdkMDkxYw1jKDlpoOACApIx6PE+7jStQJPE2KLPI4zpa90bXuEHH5SNhuBERfKN2JV0JMmoiIiCopNRV1fNx0Pix064jr5CpqsDNqAhvDRjhw5ycEP/+72DoamLTA0AafQSZ7fXFJFXKYKyxhrrCElb49fglaK26rb9wM1gb1leow0DSBgaYJGpi0wI7ArxGd9KjAcUy0LNCpjltpT7VKqNSX5zp37owZM2ZUdBgVoizO3d3dHQMGDCiTeMqDl5cXDAwMSrSPTCbDn3/+WS7xEBFVNh2t+osJ0z/P/saaq9Ox+/YaZGSnQ0Wmgr52Y6Ap1ym2jubmHcWEKTDmMlZenoztgSuQlZMJALAxbAhjLXOxfOiLAPwStBbfXp2B5Zc+xdabyxCX9hxAbsLWpEa7Qo4iQ//6H0OuooaM7LQyOPPKqcKTJnd3d8hksgKP+/fv48CBA1i2bFm5HdvDw6PQY+d/PHz4sNyO/668vb3RtGlTaGtrw8LCAh9//DFiY2MrOiwiIiojzc2dxednIvYhJTMREa9CEfz8OgBAU66NRqYti61DEHLE58HP/kZGdhqiEh4gNuWpuF5NVV187h99Hg/igpGcmYBsIQtPEiNw58UNcXu2kFXgGG1r9YClni2iEh4gNF/Z6qbCkyYA6NmzJ6Kjo5UedevWhZGREXR1dcvtuHPmzFE6Zu3atbF06VKldZaWluV2/Hfh6+uLMWPGYPz48QgODsa+fftw/fp1TJgwoaJDIyKiMmCgaQoddT0AQHpWKuLTX38pfpYcJT6vpWdTbD1/PzmD7JzcRKdhjVZQV9VEbT0bGGvn9i7Fp7/E8+Qnhe6rKpOjlm49OJg4AQDSslJw8+klpTKGmjXgYj0AWTmZ+OveTqUkrbqpFEmThoYGzM3NlR6qqqoFLlFZW1vj66+/xrhx46CrqwsrKyv89NNPSnX9+++/GD58OAwNDWFsbAw3N7cie4sUCkWBY+rq6orLbdq0wffff6+0T7NmzeDh4SEuy2QybNu2DQMHDoS2tjbs7Oxw6NAhpX1CQkLQu3dvKBQKmJmZYfTo0Xjx4oW4PTk5GWPGjIFCoYCFhQXWrl2Lt7l27Rqsra0xbdo01K1bF87Ozpg4cSL8/f0LlPX09ESNGjWgp6eHiRMnIiMjo5Aac+VdMjty5Ajq168PbW1tDBkyBMnJydi1axesra1haGiIqVOnIjs7W9wvLi4OY8aMgaGhIbS1tdGrVy+EhYUVqNvKygra2toYOHBgob1ihw8fRosWLaCpqYl69erB09MTWVkFv9UQEVV3CjU98XlaVorStvTs1ELLFeZBXDB+DvoWyRkJaGbWHgva/4DxzRZCrqKGyPgw/BK0rkDvkbGWOZZ03IFFHX7ChOaLYKhpirjU59h5axViU58qlXWr/zHUVDVw4dFfeJFSePJVXVSKpKkk1q5diw8++AA3b97E5MmT8dlnn+HOnTsAgJSUFLi4uEChUODixYvw9fWFQqFAz549i00U3pWnpyeGDRuG27dvo3fv3hg1ahRevnwJAIiOjkanTp3QrFkz+Pv748SJE4iJicGwYcPE/efOnYvz58/j4MGDOHXqFC5cuICAgIBij9muXTtERUXh2LFjEAQBMTEx2L9/P/r06aNU7uzZswgNDcX58+fx22+/4eDBg/D09Cy27pSUFGzcuBF79uzBiRMncOHCBQwaNAjHjh3DsWPH8PPPP+Onn37C/v37xX3c3d3h7++PQ4cO4erVqxAEAb1790ZmZu41cz8/P4wbNw6TJ09GYGAgXFxcsHz5cqXjnjx5Eh999BGmTZuGkJAQbNmyBV5eXlixYsXbXwQioupMJityk/CWXWvr2WCY4xSx1yo/fQ0j1NG3lxSCoZYpRjeeDVPtWuK6VjW7oo5+ffybGIErj49LqqcqqxRJ05EjR6BQKMTH0KFDiyzbu3dvTJ48Gba2tpg3bx5MTExw4cIFAMCePXugoqKCbdu2oXHjxmjQoAF27tyJyMhIsUx5cHd3x4cffghbW1t8/fXXSE5Oxt9/597NsHnzZjg5OeHrr7+Gg4MDmjdvjh07duD8+fO4d+8ekpKSsH37dnz77bfo3r07GjdujF27din14hSmXbt28Pb2xvDhw6Gurg5zc3MYGBgU6BlTV1fHjh070LBhQ/Tp0wdLly7Fxo0bkZNTdPdpZmYmNm/ejObNm6Njx44YMmQIfH19sX37djg6OqJv375wcXHB+fPnAQBhYWE4dOgQtm3bhg4dOqBp06bw9vbGv//+Kw7a3rBhA1xdXTF//nzY29tj2rRpcHV1VTruihUrMH/+fIwdOxb16tVD9+7dsWzZMmzZskXS65Ceno6EhASlBxFRVZWU+fpvmKaqttK2/MvJGfHF1tPLZhS01RQAgAsP/8TXvp9hvd8cPIq/B31NY/S1G4MGJi2U9olNfQrPi+OwwncittzwwKP4uwAAhbo+ulgPFMt1rTsYAHD9yTmYK+rAQmENrf8/FpCblFkorCFD0UlfVVIpphxwcXHB5s2bxWUdnaLvBGjSpIn4XCaTwdzcHM+ePQMABAQE4P79+wXGQaWlpeHBgwdlHHXhMeno6EBXV1cppvPnz0OhUBTY78GDB0hNTUVGRgbatm0rrjcyMkL9+vULlM8vJCQE06ZNw1dffQVXV1dER0dj7ty5mDRpErZv3y6Wyxsonqdt27ZISkrC48ePUadOncKqhra2NmxsXl8jNzMzg7W1tdI5mJmZiecYGhoKuVyO1q1bi9uNjY1Rv359hIaGimUGDnz9QcuL5cSJE+JyQEAArl+/rtSzlJ2djbS0NKSkpCidR2FWrlz51l40IqKq4lXacyRlxEOhrg8NuSb0NYzFcU01dF739vybGF5sPfnL/v3kLDJz0pGZno7g53+LvUy2ho0Q+qLgFY6snEw8TYrEtajTqKOf+38pbywUAKiragIABtQfX+ixO1j1RQervlh1+XOlS4pVVaVImnR0dGBrayuprJqamtKyTCYTe01ycnLQokULeHt7F9jP1NS0xHGpqKhAEJQ7PvMuN5Ukpn79+uGbb74psJ+FhUWBcT9SrVy5Eu3bt8fcuXMB5CZuOjo66NChA5YvXw4LC4ti95cV09Vb2PkUd45vtlEeQRDE4xRVJr+cnBx4enpi0KBBBbZpamq+df8FCxZg1qxZ4nJCQkKlHchPRCRF4FNfOFvlDrvoVncojt3/BeYKSzj+/x1zaVkp+Of/76Rzsx+HZv9/t53XrW/E3qH49Jcw1jIDkHs57UrUSWipaaOhaSvxOKn/P2bKTMcSjWu0wZ3YG4hNiUFGdhqMtc3RulY3sezL1GflfNaVV6VImsqKk5MT9u7dKw56flempqaIjo4WlxMSEhAREVHimP744w9YW1tDLi/Y3La2tlBTU8O1a9dgZWUFIHdQ9b1799CpU6ci601JSSlQn6qqKgDlBOXWrVtITU2FlpYWgNwB5AqFArVr1y7ReRTH0dERWVlZ8PPzQ7t2ufN3xMbG4t69e2jQoIFY5tq1a0r7vbns5OSEu3fvSk6g36ShoQENDY1S7UtEVBldjDwMG8NGsNCtg0Y1WqFRjdeJTo6QgyNhu5GWlVx8HY8OY6BD7p3Vna0HoLP1AKXtaVkpCIj2AZA7hUF7y15ob9mr0LrSslJw4eGf4rLnxXEFyuRP3qrbjOCVYkxTWRk1ahRMTEzg5uaGS5cuISIiAj4+Ppg+fTqioqLeXsEbunTpgp9//hmXLl3CP//8g7Fjx4qJiVSff/45Xr58iQ8//BB///03wsPDcerUKYwbNw7Z2dlQKBQYP3485s6di7Nnz+Kff/6Bu7s7VFSKf2n69euHAwcOYPPmzQgPD8fly5cxbdo0tGrVCjVr1hTLZWRkYPz48QgJCcHx48exZMkSTJky5a31l4SdnR3c3NzwySefwNfXF7du3cJHH32EWrVqwc0td3bYadOm4cSJE1i9ejXu3buHTZs2KV2aA4CvvvoKu3fvhoeHB4KDgxEaGoq9e/di0aJFZRYrEVFVkpmTAa/b3+Bi5GHEpjxFVk4mUjOTEfYyCLtur37rbOAAcPvZFfwctBZ3Y28iMf0VsnOykJWTiZepz3Aj+iJ+urEUcWm5vUdxabnrYpIeIyUzCTlCNtKz0hCT9BjXok7jx4AleJpc9M+oVHfVqqdJW1sbFy9exLx58zBo0CAkJiaiVq1a6Nq1a6l6nhYsWIDw8HD07dsX+vr6WLZsWYl7mmrWrInLly9j3rx5cHV1RXp6OurUqYOePXuKicuaNWuQlJSE/v37Q1dXF7Nnz0Z8fPED+9zd3ZGYmIhNmzZh9uzZMDAwQJcuXQpcBuzatSvs7OzQsWNHpKenY8SIEUpTJpSVnTt3Yvr06ejbty8yMjLQsWNHHDt2TLys16ZNG2zbtg1LliyBh4cHunXrhkWLFilNXurq6oojR45g6dKlWL16NdTU1ODg4MC5p4joPy0jOw3nHx7E+YcHiy33170d+OvejkK3hccFIzwu+K3HSkiPw+Ewr9KEKSmOqk4mSBlsQlQFJSQkQF9fH+4be8K6afFjvIiIqOI8ufcCP31yGAEBAXBycqrocIpUrS7PEREREZUXJk1EREREEjBpIiIiIpKASRMRERGRBEyaiIiIiCRg0kREREQkAZMmIiIiIgmYNBERERFJwKSJiIiISAImTUREREQSMGkiIiIikoBJExEREZEETJqIiIiIJGDSRERERCQBkyYiIiIiCZg0EREREUnApImIiIhIAiZNRERERBIwaSIiIiKSgEkTERERkQRMmoiIiIgkYNJEREREJAGTJiIiIiIJ5BUdAFF5i32cAHUttYoOg4iIivDiUXxFhyCJTBAEoaKDICoPCQkJ0NfXr+gwiIhIAi1tLdwJvQMrK6uKDqVI7Gmias/HxwcKhaKiwyAiomKYmJhU6oQJYE8TVWN5PU3x8fHQ09Or6HCIiKiK40BwIiIiIgmYNBERERFJwKSJiIiISAImTUREREQS8O45qrby7nFISEio4EiIiKgq0NXVhUwmK3I7kyaqtmJjYwEAlpaWFRwJERFVBW+725pJE1VbRkZGAIDIyEhOclnGEhISYGlpicePH3M6h3LA9i0/bNvyUx3aVldXt9jtTJqo2lJRyR2yp6+vX2U/wJWdnp4e27YcsX3LD9u2/FTntuVAcCIiIiIJmDQRERERScCkiaotDQ0NLFmyBBoaGhUdSrXDti1fbN/yw7YtP/+FtuVvzxERERFJwJ4mIiIiIgmYNBERERFJwKSJiIiISAImTVSl/fDDD6hbty40NTXRokULXLp0qdjyPj4+aNGiBTQ1NVGvXj38+OOP7ynSqqckbXvgwAF0794dpqam0NPTQ9u2bXHy5Mn3GG3VUtL3bZ7Lly9DLpejWbNm5RtgFVfS9k1PT8fChQtRp04daGhowMbGBjt27HhP0VYtJW1bb29vNG3aFNra2rCwsMDHH38s/lpDlSQQVVF79uwR1NTUhK1btwohISHC9OnTBR0dHeHRo0eFlg8PDxe0tbWF6dOnCyEhIcLWrVsFNTU1Yf/+/e858sqvpG07ffp04ZtvvhH+/vtv4d69e8KCBQsENTU14caNG+858sqvpG2b59WrV0K9evWEHj16CE2bNn0/wVZBpWnf/v37C61btxZOnz4tRERECH5+fsLly5ffY9RVQ0nb9tKlS4KKioqwYcMGITw8XLh06ZLQsGFDYcCAAe858rLDpImqrFatWgmTJk1SWufg4CDMnz+/0PJffPGF4ODgoLRu4sSJQps2bcotxqqqpG1bGEdHR8HT07OsQ6vyStu2w4cPFxYtWiQsWbKESVMxStq+x48fF/T19YXY2Nj3EV6VVtK2XbNmjVCvXj2ldRs3bhRq165dbjGWN16eoyopIyMDAQEB6NGjh9L6Hj164MqVK4Xuc/Xq1QLlXV1d4e/vj8zMzHKLtaopTdu+KScnB4mJieLv/1Gu0rbtzp078eDBAyxZsqS8Q6zSStO+hw4dwgcffIDVq1ejVq1asLe3x5w5c5Camvo+Qq4yStO27dq1Q1RUFI4dOwZBEBATE4P9+/ejT58+7yPkcsHfnqMq6cWLF8jOzoaZmZnSejMzMzx9+rTQfZ4+fVpo+aysLLx48QIWFhblFm9VUpq2fdPatWuRnJyMYcOGlUeIVVZp2jYsLAzz58/HpUuXIJfzT3ZxStO+4eHh8PX1haamJg4ePIgXL15g8uTJePnyJcc15VOatm3Xrh28vb0xfPhwpKWlISsrC/3798f333//PkIuF+xpoipNJpMpLQuCUGDd28oXtp5K3rZ5fvvtN3h4eGDv3r2oUaNGeYVXpUlt2+zsbIwcORKenp6wt7d/X+FVeSV57+bk5EAmk8Hb2xutWrVC7969sW7dOnh5ebG3qRAladuQkBBMmzYNX331FQICAnDixAlERERg0qRJ7yPUcsGvLVQlmZiYQFVVtcA3nGfPnhX4JpTH3Ny80PJyuRzGxsblFmtVU5q2zbN3716MHz8e+/btQ7du3cozzCqppG2bmJgIf39/3Lx5E1OmTAGQ+09eEATI5XKcOnUKXbp0eS+xVwWlee9aWFigVq1a0NfXF9c1aNAAgiAgKioKdnZ25RpzVVGatl25ciXat2+PuXPnAgCaNGkCHR0ddOjQAcuXL6+SvfvsaaIqSV1dHS1atMDp06eV1p8+fRrt2rUrdJ+2bdsWKH/q1Cl88MEHUFNTK7dYq5rStC2Q28Pk7u6OX3/9tUqPWShPJW1bPT09BAUFITAwUHxMmjQJ9evXR2BgIFq3bv2+Qq8SSvPebd++PZ48eYKkpCRx3b1796CiooLatWuXa7xVSWnaNiUlBSoqymmGqqoqgNe9/FVORY1AJ3pXebe/bt++XQgJCRFmzJgh6OjoCA8fPhQEQRDmz58vjB49WiyfN+XAzJkzhZCQEGH79u2ccqAIJW3bX3/9VZDL5cL//vc/ITo6Wny8evWqok6h0ipp276Jd88Vr6Ttm5iYKNSuXVsYMmSIEBwcLPj4+Ah2dnbChAkTKuoUKq2Stu3OnTsFuVwu/PDDD8KDBw8EX19f4YMPPhBatWpVUafwzpg0UZX2v//9T6hTp46grq4uODk5CT4+PuK2sWPHCp06dVIqf+HCBaF58+aCurq6YG1tLWzevPk9R1x1lKRtO3XqJAAo8Bg7duz7D7wKKOn7Nj8mTW9X0vYNDQ0VunXrJmhpaQm1a9cWZs2aJaSkpLznqKuGkrbtxo0bBUdHR0FLS0uwsLAQRo0aJURFRb3nqMuOTBCqah8ZERER0fvDMU1EREREEjBpIiIiIpKASRMRERGRBEyaiIiIiCRg0kREREQkAZMmIiIiIgmYNBERERFJwKSJiIiISAImTURE78nGjRshk8nQqFGjig6FiEqBSRMR0XuyY8cOAEBwcDD8/PwqOBoiKikmTURE74G/vz9u3bqFPn36AAC2b99ewREVLiUlpaJDIKq0mDQREb0HeUnSqlWr0K5dO+zZs6dAgvLvv//i008/haWlJdTV1VGzZk0MGTIEMTExYplXr15h9uzZqFevHjQ0NFCjRg307t0bd+7cAQBcuHABMpkMFy5cUKr74cOHkMlk8PLyEte5u7tDoVAgKCgIPXr0gK6uLrp27QoAOH36NNzc3FC7dm1oamrC1tYWEydOxIsXLwqc2507d/Dhhx/CzMwMGhoasLKywpgxY5Ceno6HDx9CLpdj5cqVBfa7ePEiZDIZ9u3bV6o2JXrf5BUdABFRdZeamorffvsNLVu2RKNGjTBu3DhMmDAB+/btw9ixYwHkJkwtW7ZEZmYmvvzySzRp0gSxsbE4efIk4uLiYGZmhsTERDg7O+Phw4eYN28eWrdujaSkJFy8eBHR0dFwcHAocWwZGRno378/Jk6ciPnz5yMrKwsA8ODBA7Rt2xYTJkyAvr4+Hj58iHXr1sHZ2RlBQUFQU1MDANy6dQvOzs4wMTHB0qVLYWdnh+joaBw6dAgZGRmwtrZG//798eOPP+KLL76AqqqqeOxNmzahZs2aGDhwYBm0MtF7IBARUbnavXu3AED48ccfBUEQhMTEREGhUAgdOnQQy4wbN05QU1MTQkJCiqxn6dKlAgDh9OnTRZY5f/68AEA4f/680vqIiAgBgLBz505x3dixYwUAwo4dO4qNPycnR8jMzBQePXokABD++usvcVuXLl0EAwMD4dmzZ2+N6eDBg+K6f//9V5DL5YKnp2exxyaqTHh5joionG3fvh1aWloYMWIEAEChUGDo0KG4dOkSwsLCAADHjx+Hi4sLGjRoUGQ9x48fh729Pbp161am8Q0ePLjAumfPnmHSpEmwtLSEXC6Hmpoa6tSpAwAIDQ0FkDv+ycfHB8OGDYOpqWmR9Xfu3BlNmzbF//73P3Hdjz/+CJlMhk8//bRMz4WoPDFpIiIqR/fv38fFixfRp08fCIKAV69e4dWrVxgyZAiA13fUPX/+HLVr1y62LillSkpbWxt6enpK63JyctCjRw8cOHAAX3zxBc6ePYu///4b165dA5B7uREA4uLikJ2dLSmmadOm4ezZs7h79y4yMzOxdetWDBkyBObm5mV6PkTliUkTEVE52rFjBwRBwP79+2FoaCg+8u6i27VrF7Kzs2FqaoqoqKhi65JSRlNTEwCQnp6utL6wAdwAIJPJCqz7559/cOvWLaxZswZTp05F586d0bJlSxgbGyuVMzIygqqq6ltjAoCRI0fC2NgY//vf/7Bv3z48ffoUn3/++Vv3I6pMmDQREZWT7Oxs7Nq1CzY2Njh//nyBx+zZsxEdHY3jx4+jV69eOH/+PO7evVtkfb169cK9e/dw7ty5IstYW1sDAG7fvq20/tChQ5LjzkukNDQ0lNZv2bJFaVlLSwudOnXCvn37ikzK8mhqauLTTz/Frl27sG7dOjRr1gzt27eXHBNRZcC754iIysnx48fx5MkTfPPNN+jcuXOB7Y0aNcKmTZuwfft2bNq0CcePH0fHjh3x5ZdfonHjxnj16hVOnDiBWbNmwcHBATNmzMDevXvh5uaG+fPno1WrVkhNTYWPjw/69u0LFxcXmJubo1u3bli5ciUMDQ1Rp04dnD17FgcOHJAct4ODA2xsbDB//nwIggAjIyMcPnwYp0+fLlA274661q1bY/78+bC1tUVMTAwOHTqELVu2QFdXVyw7efJkrF69GgEBAdi2bVup2pSoQlXwQHQiomprwIABgrq6erF3lo0YMUKQy+XC06dPhcePHwvjxo0TzM3NBTU1NaFmzZrCsGHDhJiYGLF8XFycMH36dMHKykpQU1MTatSoIfTp00e4c+eOWCY6OloYMmSIYGRkJOjr6wsfffSR4O/vX+jdczo6OoXGFRISInTv3l3Q1dUVDA0NhaFDhwqRkZECAGHJkiUFyg4dOlQwNjYW1NXVBSsrK8Hd3V1IS0srUG/nzp0FIyMjISUlRWIrElUeMkEQhIpO3IiIqPp79uwZ6tSpg6lTp2L16tUVHQ5RifHyHBERlauoqCiEh4djzZo1UFFRwfTp0ys6JKJS4UBwIiIqV9u2bUPnzp0RHBwMb29v1KpVq6JDIioVXp4jIiIikoA9TUREREQSMGkiIiIikoBJExEREZEETJqIiIiIJGDSRERERCQBkyYiIiIiCZg0EREREUnApImIiIhIAiZNRERERBL8H2eluIgzz1FkAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rename dictionary\n",
    "rename_dict = {\n",
    "    'answer_base_8B': 'Base 8b model',\n",
    "    'answer_base_70B': 'Base 70b model',\n",
    "    'answer_base_405B': 'Base 405b model',\n",
    "    'answer_ft_8B': 'Fine Tuned 8b model',\n",
    "}\n",
    "\n",
    "# Calculate accuracy for each model with renamed keys\n",
    "accuracies = {}\n",
    "for name in rename_dict:\n",
    "    accuracy = test_df.apply(lambda row: row[name] in row['sentiment'], axis=1).mean()\n",
    "    accuracies[rename_dict[name]] = accuracy\n",
    "\n",
    "# Horizontal bar chart\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.barplot(y=list(accuracies.keys()), x=list(accuracies.values()), palette=\"viridis\", edgecolor='black', ax=ax)\n",
    "\n",
    "# Add labels to bars\n",
    "for i, bar in enumerate(ax.patches):\n",
    "    ax.text(bar.get_width() - 0.02, \n",
    "            bar.get_y() + bar.get_height() / 2, \n",
    "            f\"{list(accuracies.values())[i]:.3f}\", \n",
    "            ha='right', va='center', color='white', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Set plot aesthetics\n",
    "ax.set_xlim(0, max(accuracies.values()) + 0.05)\n",
    "ax.set_xlabel('Accuracy', fontsize=12)\n",
    "ax.set_ylabel('Model', fontsize=12)\n",
    "ax.set_title('Classification Accuracy by Model', fontsize=14, fontweight='bold')\n",
    "sns.despine()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb880d9-13ad-4ef8-a2f6-ece194d4ba4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0fe329-269e-44e9-aefb-f2542b05f5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
